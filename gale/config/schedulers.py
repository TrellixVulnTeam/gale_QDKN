# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/02a_config.schedulers.ipynb (unless otherwise specified).

__all__ = ['SchedulerParams', 'FlatCosSchedulerConfig', 'WarmupCosineLRConfig', 'WarmupLinearLRConfig',
           'WarmupConstantLRConfig', 'CosineAnnealingWarmRestartsConfig', 'ReduceLROnPlateauConfig', 'OneCycleLRConfig',
           'MultiStepLRConfig', 'StepLRConfig']

# Cell
from dataclasses import dataclass
from typing import *

from hydra.utils import instantiate
from omegaconf import MISSING, DictConfig, OmegaConf

from .utility import get_class_path
from ..core.nn.optim.lr_schedulers import *

# Cell
@dataclass
class SchedulerParams:
    """
    Base Scheduler params with no values.
    """

    _target_: str = MISSING

# Cell
@dataclass
class FlatCosSchedulerConfig(SchedulerParams):
    """
    Default configuration for `FlatCos` scheduler
    """

    _target_: str = get_class_path(FlatCosScheduler)
    pct_start: float = MISSING
    max_iters: int = MISSING

# Cell
@dataclass
class WarmupCosineLRConfig(SchedulerParams):
    """
    Default configuration for `WarmupCosineLR` scheduler
    """

    _target_: str = get_class_path(WarmupCosineLR)
    max_iters: int = MISSING
    pct_start: Optional[float] = None
    warmup_steps: Optional[int] = None

# Cell
@dataclass
class WarmupLinearLRConfig(WarmupCosineLRConfig):
    """
    Default configuration for `WarmupLinearLR` scheduler
    """

    _target_: str = get_class_path(WarmupLinearLR)

# Cell
@dataclass
class WarmupConstantLRConfig(WarmupCosineLRConfig):
    """
    Default configuration for `WarmupConstantLR` scheduler
    """

    _target_: str = get_class_path(WarmupConstantLR)

# Cell
@dataclass
class CosineAnnealingWarmRestartsConfig(SchedulerParams):
    """
    Default configuration for `CosineAnnealingWarmRestarts` scheduler
    """

    _target_: str = get_class_path(CosineAnnealingWarmRestarts)
    T_0: int = MISSING
    T_mult: int = 1
    eta_min: int = 0

# Cell
@dataclass
class ReduceLROnPlateauConfig(SchedulerParams):
    """
    Default configuration for `ReduceLROnPlateau` scheduler
    """

    _target_: str = get_class_path(ReduceLROnPlateau)
    mode: str = MISSING
    factor: float = 0.1
    patience: int = MISSING
    threshold: float = 0.0001
    threshold_mode: str = "rel"
    min_lr: float = 0
    eps: float = 1e-08
    verbose: bool = False

# Cell
@dataclass
class OneCycleLRConfig(SchedulerParams):
    """
    Default configuration for `OneCycleLR` scheduler
    """

    _target_: str = get_class_path(OneCycleLR)
    max_lr: Any = MISSING
    total_steps: Any = None
    epochs: Any = None
    steps_per_epoch: Any = None
    pct_start: Any = 0.3
    anneal_strategy: Any = "cos"
    cycle_momentum: Any = True
    base_momentum: Any = 0.85
    max_momentum: Any = 0.95
    div_factor: Any = 25.0
    final_div_factor: Any = 10000.0
    last_epoch: Any = -1

# Cell
@dataclass
class MultiStepLRConfig(SchedulerParams):
    """
    Default configuration for `MultiStepLR` scheduler
    """

    _target_: str = get_class_path(MultiStepLR)
    milestones: List[int] = MISSING
    gamma: float = 0.1

# Cell
@dataclass
class StepLRConfig(SchedulerParams):
    """
    Default configuration for `StepLR` scheduler
    """

    _target_: str = get_class_path(StepLR)
    step_size: int = MISSING
    gamma: float = 0.1