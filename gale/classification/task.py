# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/06_classification.task.ipynb (unless otherwise specified).

__all__ = ['Mixup', 'predict_context', 'ClassificationTask', 'get_grid', 'show_batch']

# Cell
import functools
import logging
from typing import *

import numpy as np
import pytorch_lightning as pl
import torch
import torch.nn.functional as F
import torchmetrics
from fastcore.all import *
from omegaconf import DictConfig, ListConfig, OmegaConf
from pytorch_lightning.trainer.states import RunningStage
from timm.data.mixup import Mixup, mixup_target
from torch import nn

from .augment import *
from .core import *
from .data import *
from .model import build_model
from ..core_classes import BasicModule, DefaultTask
from ..losses import build_loss
from ..torch_utils import trainable_params
from ..utils.display import *

_logger = logging.getLogger(__name__)

# Cell
# hide
# fmt: off
class Mixup(Mixup):
    """
    CPU friendly Mixup from timm
    """
    def __call__(self, x, target):
        assert len(x) % 2 == 0, 'Batch size should be even when using this'
        if self.mode == 'elem':
            lam = self._mix_elem(x)
        elif self.mode == 'pair':
            lam = self._mix_pair(x)
        else:
            lam = self._mix_batch(x)
        target = mixup_target(target, self.num_classes, lam, self.label_smoothing, device=x.device)
        return x, target
# fmt: on

# Cell
def predict_context(func: Callable) -> Callable:
    """
    This decorator is used as context manager
    to put model in eval mode before running predict and reset to train after.
    """

    @functools.wraps(func)
    def wrapper(self, *args, **kwargs) -> Any:
        grad_enabled = torch.is_grad_enabled()
        is_training = self.training
        self.eval()
        torch.set_grad_enabled(False)

        result = func(self, *args, **kwargs)

        if is_training:
            self.train()
        torch.set_grad_enabled(grad_enabled)
        return result

    return wrapper

# Cell
class ClassificationTask(DefaultTask):
    is_restored = True
    """
    A General PyTorch Lightning Task for Image Classification

    Arguments:
    1. cfg: gale default config.
    2. trainer (Optional): Pytorch Lightning Trainer instance
    2. metrics (Optional): A List of `torchmetrics` used during training.
    """

    def __init__(
        self,
        cfg: DictConfig,
        trainer: pl.Trainer = None,
        metrics: Union[torchmetrics.Metric, Mapping, Sequence, None] = None,
    ):
        super(ClassificationTask, self).__init__(
            cfg=cfg, trainer=trainer, metrics=metrics
        )
        # Train Loss is used for the Training Dataset
        self.train_loss = noop
        # Eval Loss is used for Validation / Test Datasets
        self.eval_loss = noop
        self.setup()

    def setup(self, stage: Optional[str] = None):
        """
        Sets up the model and all the modelitites of the `pl.LightningModule`.
        This is called during task initialization.
        """
        # that means model has not been build manually
        # so we need to build it
        if self._model is noop:
            self.setup_model()

        # if the trainer is passed, that means we are in training
        # so we need to setup the train_dataloaders, valid_dataloaders (Optional)
        # test_dataloaders (Optional) and the optimziation for ht emodel
        if not self.is_restored:
            if self._train_dl is noop:
                self.setup_training_data()
            if self._validation_dl is noop:
                self.setup_validation_data()
            if self._test_dl is noop:
                self.setup_test_data()
            if self._optimizer is noop and self._scheduler is noop:
                optim = self.process_optim_config(self._cfg.optimization)
                self.setup_optimization(optim)

            # setup mixup/cutmix for the model
            mixup_args = self._cfg.training.mixup.init_args
            self.mixup_off_epoch = self._cfg.training.mixup.off_epoch
            self.mixup_fn = Mixup(**mixup_args)

            # build up the loss functions
            self.train_loss = build_loss(self._cfg.training.train_loss_fn)
            self.eval_loss = build_loss(self._cfg.training.eval_loss_fn)

            shapes = (
                self._cfg.input.channels,
                self._cfg.input.height,
                self._cfg.input.width,
            )
            self.example_input_array = torch.randn(1, *shapes)

            if self._cfg.input.mean == "imagenet":
                mean, std = imagenet_stats
            elif self._cfg.input.mean == "cifar":
                mean, std = cifar_stats
            elif self._cfg.input.mean == "mnist":
                mean, std = mnist_stats
            else:
                mean, std = np.array(self._cfg.input.mean), np.array(
                    self._cfg.input.std
                )

            self.mean = torch.tensor(np.array(mean)).float()
            self.std = torch.tensor(np.array(std)).float()

    def forward(self, x):
        """
        Forward method: we pass in the input through the meta_arch
        to get the predictions for the current image batch
        """
        return self._model(x)

    def shared_step(self, batch: Any, batch_idx: int, stage: str) -> Dict:
        """
        Common steps for training, validation and test stages. Shared step
        returns a dictionary containing the `loss` and `logs`, which are the metric
        values computed at `stage`. This also applies `mixup/cutmix` to the training data
        if specified in config.
        """
        stages = ["train", "validation", "test"]
        assert stage in stages

        # Check wether Mixup Threshold is reached and stop mixup
        # makes no sense to check in other stages; so check in
        # the training stage
        if stage == "train":
            if self.mixup_off_epoch and self.current_epoch >= self.mixup_off_epoch:
                self.mixup_fn.mixup_enabled = False

        # Unpack Batch
        x, y = batch

        # Apply mixup in the training stage
        if stage == "train":
            # NOTE: This converts the targets into 1 hot vectores
            x, y_mix = self.mixup_fn(x, y)

        # calculate the logits
        y_hat = self(x)

        # Comput Loss
        if stage == "train":
            loss = self.train_loss(y_hat, y_mix)
        else:
            loss = self.eval_loss(y_hat, y)

        # compute probas
        y_hat = F.softmax(y_hat)

        logs = {}
        logs["loss"] = loss

        for name, metric in self.metrics.items():
            if isinstance(metric, torchmetrics.metric.Metric):
                metric(y_hat, y)
                logs[name] = metric
            else:
                logs[name] = metric(y_hat, y)

        output = dict(loss=loss, logs=logs)
        return output

    def setup_model(self, args: DictConfig = None):
        """
        Builds up the meta architecture. You can also additionally pass in args to configure
        from a config other than the orignal one.
        """
        conf = ifnone(args, self._cfg)
        meta_arch = build_model(conf)
        self._model = meta_arch

    @property
    def param_dicts(self):
        """Returns the paramters for model optimization"""
        return (
            self._model.build_param_dicts()
            if self._model is not noop
            else trainable_params(self)
        )

    def setup_training_data(self, name: str = None, dls_conf: DictConfig = None):
        """
        Builds the training dataset from name and the dataloader from `dls_conf`, if
        None then parsers the values from the passed config while creating the instance
        """
        name = ifnone(name, self._cfg.datasets.train)
        conf = ifnone(dls_conf, self._cfg.dataloader.train)
        self._train_dl = build_classification_loader_from_config(name, conf)

    def setup_validation_data(
        self, name: Union[List, str] = None, dls_conf: DictConfig = None
    ):
        """Same as `setup_training_data` but sets up validation dataset and dataloaders"""
        name = ifnone(name, self._cfg.datasets.valid)
        conf = ifnone(dls_conf, self._cfg.dataloader.valid)

        # if name is still none , that means no validation data
        if name is None:
            self._validation_dl = None
        else:
            if isinstance(name, list) or isinstance(name, ListConfig):
                names = list(name)
                dls = [build_classification_loader_from_config(n, conf) for n in names]
            elif isinstance(name, str):
                dls = build_classification_loader_from_config(name, conf)
            else:
                _logger.warning(
                    "Validation dataset name format not understood. Must either be str or List."
                )
                dls = None
            self._validation_dl = dls

    def setup_test_data(
        self, name: Union[List, str] = None, dls_conf: DictConfig = None
    ):
        """Same as `setup_training_data` but sets up test dataset and dataloaders"""
        name = ifnone(name, self._cfg.datasets.test)
        conf = ifnone(dls_conf, self._cfg.dataloader.test)

        # if name is still none , that means no validation data
        if name is None:
            self._test_dl = None
        else:
            if isinstance(name, list) or isinstance(name, ListConfig):
                names = list(name)
                dls = [build_classification_loader_from_config(n, conf) for n in names]
            elif isinstance(name, str):
                dls = build_classification_loader_from_config(name, conf)
            else:
                _logger.warning(
                    "Test dataset name format not understood. Must either be str or List"
                )
                dls = None
            self._test_dl = dls

    def test_dataloader(self):
        self.setup_test_data()
        if self._test_dl is None or self._test_dl is noop:
            return None
        else:
            return self._test_dl

    @property
    def model(self):
        return self._model

    @model.setter
    def model(self, m: BasicModule):
        assert isinstance(m, BasicModule)
        self._model = m

    def predict_step(self, batch: Any, batch_idx: int, dataloader_idx: int = 0) -> Any:
        if isinstance(batch, tuple):
            batch = batch[0]
        return self(batch)

    @predict_context
    def generate_preds(self, batch: Tuple) -> Tuple[L, L, L]:
        """
        Generate predictions for batch. Returns the Images, Targets & Predictions for the
        Batch.
        """
        running_stage = RunningStage.PREDICTING
        x = self.transfer_batch_to_device(batch, self.device)
        x, y = batch

        preds = self.predict_step(x, 0)
        _, preds = torch.max(preds, 1)

        x = denormalize(x, self.mean, self.std)

        ims = L(i for i in x.data.cpu())
        targs = L(t for t in y.data.cpu().numpy())
        preds = L(p for p in preds.data.cpu().numpy())
        return ims, targs, preds

# Cell
@delegates(subplots)
def get_grid(
    n,
    nrows=None,
    ncols=None,
    add_vert=0,
    figsize=None,
    double=False,
    title=None,
    return_fig=False,
    flatten=True,
    **kwargs
):
    "Return a grid of `n` axes, `rows` by `cols`"
    if nrows:
        ncols = ncols or int(np.ceil(n / nrows))
    elif ncols:
        nrows = nrows or int(np.ceil(n / ncols))
    else:
        nrows = int(math.sqrt(n))
        ncols = int(np.ceil(n / nrows))
    if double:
        ncols *= 2
        n *= 2
    fig, axs = subplots(nrows, ncols, figsize=figsize, **kwargs)
    if flatten:
        axs = [
            ax if i < n else ax.set_axis_off() for i, ax in enumerate(axs.flatten())
        ][:n]
    if title is not None:
        fig.suptitle(title, weight="bold", size=14)
    return (fig, axs) if return_fig else axs

# Cell
@patch
def show_results(
    self: ClassificationTask,
    dataloader: torch.utils.data.DataLoader = None,
    ctxs=None,
    max_n: int = 10,
    nrows: int = None,
    ncols: int = None,
    figsize: Tuple = None,
    **kwargs,
):
    """
    Displays the results for `max_n` items of a batch in `Dataloader` if given or else
    uses test or validationd dataloader
    """

    dls = ifnone(self._test_dl, self._validation_dl)

    dls = ifnone(dataloader, dls)

    if dls is None:
        _logger.warning("No Dataloader, skipping show_results")
        return

    batch = next(iter(dls))
    batch = batch[:max_n]

    samples, targs, preds = self.generate_preds(batch)

    if ctxs is None:
        ctxs = get_grid(
            min(len(samples), max_n),
            nrows=nrows,
            ncols=ncols,
            add_vert=1,
            figsize=figsize,
        )

    ctxs = [
        show_image(s, ctx=c, **kwargs) for s, c, _ in zip(samples, ctxs, range(max_n))
    ]
    ctxs = [
        show_title(f"actual: {t}", ctx=c, **kwargs)
        for t, c, _ in zip(targs, ctxs, range(max_n))
    ]
    ctxs = [
        show_title(
            f"predicted: {p}", ctx=c, color="green" if p == t else "red", **kwargs
        )
        for p, t, c, _ in zip(preds, targs, ctxs, range(max_n))
    ]
    return ctxs

# Cell
@patch_to(ClassificationTask)
@use_kwargs_dict(keep=True, n=8, nrows=2, ncols=4, figsize=None, imsize=3)
def show_batch(self: ClassificationTask, prefix: str = "train", **kwargs):
    """Displays a batch from a dataloader defined by prefix"""
    if self._train_dl is noop:
        self.setup()

    if prefix == "train":
        loader = [self._train_dl]

    elif prefix == "validation":
        loader = self._validation_dl

    elif prefix == "test":
        loader = self._test_dl
    else:
        raise ValueError("Unkonwn stage must be train, validation or test")

    if loader is None:
        _logger.warning(f"No Dataset and DataLoader provied for {prefix} stage")
        _logger.info("Skipping show batch")
        return
    else:
        # DataLoaders can either be List or DataLoader
        try:
            loader = loader[0]
        except:
            pass

    inputs, classes = next(iter(loader))

    if prefix == "train":
        inputs, _ = self.mixup_fn(inputs, classes)

    batch = (inputs, classes)
    show_image_batch(batch, mean=self.mean, std=self.std, **kwargs)