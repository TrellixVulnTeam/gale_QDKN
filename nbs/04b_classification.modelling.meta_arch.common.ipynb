{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# skip\n",
    "!git clone https://github.com/benihime91/gale # install gale on colab\n",
    "!pip install -e \"gale[dev]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp classification.modelling.meta_arch.common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# hide\\n%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\\n%matplotlib inline\";\n",
       "                var nbb_formatted_code = \"# hide\\n%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\\n%matplotlib inline\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# hide\\nimport warnings\\n\\nfrom nbdev.export import *\\nfrom nbdev.showdoc import *\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_formatted_code = \"# hide\\nimport warnings\\n\\nfrom nbdev.export import *\\nfrom nbdev.showdoc import *\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "import warnings\n",
    "\n",
    "from nbdev.export import *\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Architectures : Generalized Image Classifier \n",
    "> Default Model Architecture for Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# export\\nimport logging\\nfrom typing import *\\n\\nimport torch\\nfrom omegaconf import DictConfig, OmegaConf\\nfrom pytorch_lightning.core.memory import get_human_readable_count\\nfrom torch.nn import Module\\n\\nfrom gale.classification.modelling.backbones import ImageClassificationBackbone\\nfrom gale.classification.modelling.build import build_backbone, build_head\\nfrom gale.classification.modelling.heads import ImageClassificationHead\\nfrom gale.core.classes import GaleModule\\nfrom gale.core.nn.shape_spec import ShapeSpec\\n\\n_logger = logging.getLogger(__name__)\";\n",
       "                var nbb_formatted_code = \"# export\\nimport logging\\nfrom typing import *\\n\\nimport torch\\nfrom omegaconf import DictConfig, OmegaConf\\nfrom pytorch_lightning.core.memory import get_human_readable_count\\nfrom torch.nn import Module\\n\\nfrom gale.classification.modelling.backbones import ImageClassificationBackbone\\nfrom gale.classification.modelling.build import build_backbone, build_head\\nfrom gale.classification.modelling.heads import ImageClassificationHead\\nfrom gale.core.classes import GaleModule\\nfrom gale.core.nn.shape_spec import ShapeSpec\\n\\n_logger = logging.getLogger(__name__)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "import logging\n",
    "from typing import *\n",
    "\n",
    "import torch\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from pytorch_lightning.core.memory import get_human_readable_count\n",
    "from torch.nn import Module\n",
    "\n",
    "from gale.classification.modelling.backbones import ImageClassificationBackbone\n",
    "from gale.classification.modelling.build import build_backbone, build_head\n",
    "from gale.classification.modelling.heads import ImageClassificationHead\n",
    "from gale.core.classes import GaleModule\n",
    "from gale.core.nn.shape_spec import ShapeSpec\n",
    "\n",
    "_logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# export\\nclass GeneralizedImageClassifier(GaleModule):\\n    \\\"\\\"\\\"\\n    A General Image Classifier. Any models that contains the following 2 components:\\n    1. Feature extractor (aka backbone)\\n    2. Image Classification head (Pooling + Classifier)\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        backbone: ImageClassificationBackbone,\\n        head: ImageClassificationHead,\\n    ):\\n        \\\"\\\"\\\"\\n        Arguments:\\n        1. `backbone`: a `ImageClassificationBackbone` module, must follow gale's backbone interface\\n        2. `head`: a head containg the classifier. and the pooling layer, must be an instance of\\n        `ImageClassificationHead`.\\n        \\\"\\\"\\\"\\n        super(GeneralizedImageClassifier, self).__init__()\\n        self.backbone = backbone\\n        assert isinstance(backbone, ImageClassificationBackbone)\\n        self.head = head\\n        assert isinstance(head, ImageClassificationHead)\\n\\n    def forward(self, batched_inputs: torch.Tensor) -> torch.Tensor:\\n        \\\"\\\"\\\"\\n        Runs the batched_inputs through `backbone` followed by the `head`.\\n        Returns a Tensor which contains the logits for the batched_inputs.\\n        \\\"\\\"\\\"\\n        # forward pass through the backbone\\n        out = self.backbone(batched_inputs)\\n        # pass through the classification layer\\n        out = self.head(out)\\n        return out\\n\\n    @classmethod\\n    def from_config_dict(cls, cfg: DictConfig):\\n        \\\"\\\"\\\"\\n        Instantiate the Meta Architecture from gale config\\n        \\\"\\\"\\\"\\n        if not hasattr(cfg.model, \\\"backbone\\\"):\\n            raise ValueError(\\\"Configuration for model backbone not found\\\")\\n\\n        if not hasattr(cfg.model, \\\"head\\\"):\\n            raise ValueError(\\\"Configuration for model head not found\\\")\\n\\n        input_shape = ShapeSpec(cfg.input.channels, cfg.input.height, cfg.input.width)\\n        _logger.debug(f\\\"Inputs: {input_shape}\\\")\\n\\n        backbone = build_backbone(cfg, input_shape=input_shape)\\n        param_count = get_human_readable_count(\\n            sum([m.numel() for m in backbone.parameters()])\\n        )\\n        _logger.debug(\\n            \\\"Backbone {} created, param count: {}.\\\".format(\\n                cfg.model.backbone.name, param_count\\n            )\\n        )\\n\\n        head = build_head(cfg, backbone.output_shape())\\n        param_count = get_human_readable_count(\\n            sum([m.numel() for m in head.parameters()])\\n        )\\n        _logger.debug(\\n            \\\"Head {} created, param count: {}.\\\".format(cfg.model.head.name, param_count)\\n        )\\n\\n        kwds = {\\\"backbone\\\": backbone, \\\"head\\\": head}\\n\\n        instance = cls(**kwds)\\n        instance.input_shape = input_shape\\n\\n        param_count = get_human_readable_count(\\n            sum([m.numel() for m in instance.parameters()])\\n        )\\n        _logger.info(\\\"Model created, param count: {}.\\\".format(param_count))\\n\\n        return instance\\n\\n    def build_param_dicts(self):\\n        \\\"\\\"\\\"\\n        Builds up the Paramters dicts for optimization\\n        \\\"\\\"\\\"\\n        backbone_params = self.backbone.build_param_dicts()\\n        head_params = self.head.build_param_dicts()\\n        parameters = backbone_params + head_params\\n\\n        # filter and remove any empty paramter groups if any\\n        pgs_filterd = []\\n\\n        for group in parameters:\\n            if group[\\\"params\\\"] == []:\\n                pass\\n            else:\\n                pgs_filterd += [group]\\n        return pgs_filterd\\n\\n    def get_lrs(self) -> List:\\n        \\\"\\\"\\\"\\n        Returns a List containining the Lrs' for\\n        each parameter group. This is required to build schedulers\\n        like `torch.optim.lr_scheduler.OneCycleScheduler` which needs\\n        the max lrs' for all the Param Groups.\\n        \\\"\\\"\\\"\\n        lrs = []\\n        for p in self.build_param_dicts():\\n            lrs.append(p[\\\"lr\\\"])\\n        return lrs\";\n",
       "                var nbb_formatted_code = \"# export\\nclass GeneralizedImageClassifier(GaleModule):\\n    \\\"\\\"\\\"\\n    A General Image Classifier. Any models that contains the following 2 components:\\n    1. Feature extractor (aka backbone)\\n    2. Image Classification head (Pooling + Classifier)\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        backbone: ImageClassificationBackbone,\\n        head: ImageClassificationHead,\\n    ):\\n        \\\"\\\"\\\"\\n        Arguments:\\n        1. `backbone`: a `ImageClassificationBackbone` module, must follow gale's backbone interface\\n        2. `head`: a head containg the classifier. and the pooling layer, must be an instance of\\n        `ImageClassificationHead`.\\n        \\\"\\\"\\\"\\n        super(GeneralizedImageClassifier, self).__init__()\\n        self.backbone = backbone\\n        assert isinstance(backbone, ImageClassificationBackbone)\\n        self.head = head\\n        assert isinstance(head, ImageClassificationHead)\\n\\n    def forward(self, batched_inputs: torch.Tensor) -> torch.Tensor:\\n        \\\"\\\"\\\"\\n        Runs the batched_inputs through `backbone` followed by the `head`.\\n        Returns a Tensor which contains the logits for the batched_inputs.\\n        \\\"\\\"\\\"\\n        # forward pass through the backbone\\n        out = self.backbone(batched_inputs)\\n        # pass through the classification layer\\n        out = self.head(out)\\n        return out\\n\\n    @classmethod\\n    def from_config_dict(cls, cfg: DictConfig):\\n        \\\"\\\"\\\"\\n        Instantiate the Meta Architecture from gale config\\n        \\\"\\\"\\\"\\n        if not hasattr(cfg.model, \\\"backbone\\\"):\\n            raise ValueError(\\\"Configuration for model backbone not found\\\")\\n\\n        if not hasattr(cfg.model, \\\"head\\\"):\\n            raise ValueError(\\\"Configuration for model head not found\\\")\\n\\n        input_shape = ShapeSpec(cfg.input.channels, cfg.input.height, cfg.input.width)\\n        _logger.debug(f\\\"Inputs: {input_shape}\\\")\\n\\n        backbone = build_backbone(cfg, input_shape=input_shape)\\n        param_count = get_human_readable_count(\\n            sum([m.numel() for m in backbone.parameters()])\\n        )\\n        _logger.debug(\\n            \\\"Backbone {} created, param count: {}.\\\".format(\\n                cfg.model.backbone.name, param_count\\n            )\\n        )\\n\\n        head = build_head(cfg, backbone.output_shape())\\n        param_count = get_human_readable_count(\\n            sum([m.numel() for m in head.parameters()])\\n        )\\n        _logger.debug(\\n            \\\"Head {} created, param count: {}.\\\".format(cfg.model.head.name, param_count)\\n        )\\n\\n        kwds = {\\\"backbone\\\": backbone, \\\"head\\\": head}\\n\\n        instance = cls(**kwds)\\n        instance.input_shape = input_shape\\n\\n        param_count = get_human_readable_count(\\n            sum([m.numel() for m in instance.parameters()])\\n        )\\n        _logger.info(\\\"Model created, param count: {}.\\\".format(param_count))\\n\\n        return instance\\n\\n    def build_param_dicts(self):\\n        \\\"\\\"\\\"\\n        Builds up the Paramters dicts for optimization\\n        \\\"\\\"\\\"\\n        backbone_params = self.backbone.build_param_dicts()\\n        head_params = self.head.build_param_dicts()\\n        parameters = backbone_params + head_params\\n\\n        # filter and remove any empty paramter groups if any\\n        pgs_filterd = []\\n\\n        for group in parameters:\\n            if group[\\\"params\\\"] == []:\\n                pass\\n            else:\\n                pgs_filterd += [group]\\n        return pgs_filterd\\n\\n    def get_lrs(self) -> List:\\n        \\\"\\\"\\\"\\n        Returns a List containining the Lrs' for\\n        each parameter group. This is required to build schedulers\\n        like `torch.optim.lr_scheduler.OneCycleScheduler` which needs\\n        the max lrs' for all the Param Groups.\\n        \\\"\\\"\\\"\\n        lrs = []\\n        for p in self.build_param_dicts():\\n            lrs.append(p[\\\"lr\\\"])\\n        return lrs\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class GeneralizedImageClassifier(GaleModule):\n",
    "    \"\"\"\n",
    "    A General Image Classifier. Any models that contains the following 2 components:\n",
    "    1. Feature extractor (aka backbone)\n",
    "    2. Image Classification head (Pooling + Classifier)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone: ImageClassificationBackbone,\n",
    "        head: ImageClassificationHead,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        1. `backbone`: a `ImageClassificationBackbone` module, must follow gale's backbone interface\n",
    "        2. `head`: a head containg the classifier. and the pooling layer, must be an instance of\n",
    "        `ImageClassificationHead`.\n",
    "        \"\"\"\n",
    "        super(GeneralizedImageClassifier, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        assert isinstance(backbone, ImageClassificationBackbone)\n",
    "        self.head = head\n",
    "        assert isinstance(head, ImageClassificationHead)\n",
    "\n",
    "    def forward(self, batched_inputs: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Runs the batched_inputs through `backbone` followed by the `head`.\n",
    "        Returns a Tensor which contains the logits for the batched_inputs.\n",
    "        \"\"\"\n",
    "        # forward pass through the backbone\n",
    "        out = self.backbone(batched_inputs)\n",
    "        # pass through the classification layer\n",
    "        out = self.head(out)\n",
    "        return out\n",
    "\n",
    "    @classmethod\n",
    "    def from_config_dict(cls, cfg: DictConfig):\n",
    "        \"\"\"\n",
    "        Instantiate the Meta Architecture from gale config\n",
    "        \"\"\"\n",
    "        if not hasattr(cfg.model, \"backbone\"):\n",
    "            raise ValueError(\"Configuration for model backbone not found\")\n",
    "\n",
    "        if not hasattr(cfg.model, \"head\"):\n",
    "            raise ValueError(\"Configuration for model head not found\")\n",
    "\n",
    "        input_shape = ShapeSpec(cfg.input.channels, cfg.input.height, cfg.input.width)\n",
    "        _logger.debug(f\"Inputs: {input_shape}\")\n",
    "\n",
    "        backbone = build_backbone(cfg, input_shape=input_shape)\n",
    "        param_count = get_human_readable_count(\n",
    "            sum([m.numel() for m in backbone.parameters()])\n",
    "        )\n",
    "        _logger.debug(\n",
    "            \"Backbone {} created, param count: {}.\".format(\n",
    "                cfg.model.backbone.name, param_count\n",
    "            )\n",
    "        )\n",
    "\n",
    "        head = build_head(cfg, backbone.output_shape())\n",
    "        param_count = get_human_readable_count(\n",
    "            sum([m.numel() for m in head.parameters()])\n",
    "        )\n",
    "        _logger.debug(\n",
    "            \"Head {} created, param count: {}.\".format(cfg.model.head.name, param_count)\n",
    "        )\n",
    "\n",
    "        kwds = {\"backbone\": backbone, \"head\": head}\n",
    "\n",
    "        instance = cls(**kwds)\n",
    "        instance.input_shape = input_shape\n",
    "\n",
    "        param_count = get_human_readable_count(\n",
    "            sum([m.numel() for m in instance.parameters()])\n",
    "        )\n",
    "        _logger.info(\"Model created, param count: {}.\".format(param_count))\n",
    "\n",
    "        return instance\n",
    "\n",
    "    def build_param_dicts(self):\n",
    "        \"\"\"\n",
    "        Builds up the Paramters dicts for optimization\n",
    "        \"\"\"\n",
    "        backbone_params = self.backbone.build_param_dicts()\n",
    "        head_params = self.head.build_param_dicts()\n",
    "        parameters = backbone_params + head_params\n",
    "\n",
    "        # filter and remove any empty paramter groups if any\n",
    "        pgs_filterd = []\n",
    "\n",
    "        for group in parameters:\n",
    "            if group[\"params\"] == []:\n",
    "                pass\n",
    "            else:\n",
    "                pgs_filterd += [group]\n",
    "        return pgs_filterd\n",
    "\n",
    "    def get_lrs(self) -> List:\n",
    "        \"\"\"\n",
    "        Returns a List containining the Lrs' for\n",
    "        each parameter group. This is required to build schedulers\n",
    "        like `torch.optim.lr_scheduler.OneCycleScheduler` which needs\n",
    "        the max lrs' for all the Param Groups.\n",
    "        \"\"\"\n",
    "        lrs = []\n",
    "        for p in self.build_param_dicts():\n",
    "            lrs.append(p[\"lr\"])\n",
    "        return lrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model architecture will work for most common computer vision fietuning use case. We take a `backbone` and `classifier`. We run the input through the backbone to extract the feature_maps which are then used by the classifier to given predictions on the Input. The paramters dicts for optimization are generated by the `backbone` and the `head` itself.\n",
    "\n",
    "> Note: For advanced use cases you might want to create a model. A model muse inherit from `GaleModule` and be registered in `META_ARCH_REGISTRY`. Your model should also have the following methods to work in the Gale ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"GeneralizedImageClassifier.from_config_dict\" class=\"doc_header\"><code>GeneralizedImageClassifier.from_config_dict</code><a href=\"__main__.py#L37\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>GeneralizedImageClassifier.from_config_dict</code>(**`cfg`**:`DictConfig`)\n",
       "\n",
       "Instantiate the Meta Architecture from gale config"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"show_doc(GeneralizedImageClassifier.from_config_dict)\";\n",
       "                var nbb_formatted_code = \"show_doc(GeneralizedImageClassifier.from_config_dict)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(GeneralizedImageClassifier.from_config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"GeneralizedImageClassifier.forward\" class=\"doc_header\"><code>GeneralizedImageClassifier.forward</code><a href=\"__main__.py#L26\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>GeneralizedImageClassifier.forward</code>(**`batched_inputs`**:`Tensor`)\n",
       "\n",
       "Runs the batched_inputs through `backbone` followed by the `head`.\n",
       "Returns a Tensor which contains the logits for the batched_inputs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"show_doc(GeneralizedImageClassifier.forward)\";\n",
       "                var nbb_formatted_code = \"show_doc(GeneralizedImageClassifier.forward)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(GeneralizedImageClassifier.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"GeneralizedImageClassifier.build_param_dicts\" class=\"doc_header\"><code>GeneralizedImageClassifier.build_param_dicts</code><a href=\"__main__.py#L81\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>GeneralizedImageClassifier.build_param_dicts</code>()\n",
       "\n",
       "Builds up the Paramters dicts for optimization"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"show_doc(GeneralizedImageClassifier.build_param_dicts)\";\n",
       "                var nbb_formatted_code = \"show_doc(GeneralizedImageClassifier.build_param_dicts)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(GeneralizedImageClassifier.build_param_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Meta_Arch`'s can also be instatiated via a appropriate config file. Let's see how .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"from dataclasses import dataclass, field\\nfrom omegaconf import MISSING, OmegaConf\\nfrom gale.classification.modelling.backbones import ResNetBackbone\\nfrom gale.classification.modelling.heads import FastaiHead\";\n",
       "                var nbb_formatted_code = \"from dataclasses import dataclass, field\\nfrom omegaconf import MISSING, OmegaConf\\nfrom gale.classification.modelling.backbones import ResNetBackbone\\nfrom gale.classification.modelling.heads import FastaiHead\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from omegaconf import MISSING, OmegaConf\n",
    "from gale.classification.modelling.backbones import ResNetBackbone\n",
    "from gale.classification.modelling.heads import FastaiHead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a meta_arch we first need to create the configurations for the `Backbone` and the `Head` of the model. These \n",
    "must be registerd in `IMAGE_CLASSIFICATION_BACKBONES` and `IMAGE_CLASSIFICATION_HEADS` Registy respectively. The instances are automatically instiated by the `GeneralizedImageClassifier` meta_arch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"@dataclass\\nclass C_Backbone:\\n    model_name: str = \\\"resnet18\\\"\\n    pretrained: bool = True\\n    act: Any = None\\n    lr: Any = 1e-05\\n    wd: Any = 1e-05\\n    freeze_at: int = 4\\n\\n\\n@dataclass\\nclass C_Head:\\n    num_classes: int = 2\\n    drop_rate: Any = 0.3\\n    lr: Any = 2e-03\\n    wd: Any = 1e-05\\n    filter_wd: Any = False\";\n",
       "                var nbb_formatted_code = \"@dataclass\\nclass C_Backbone:\\n    model_name: str = \\\"resnet18\\\"\\n    pretrained: bool = True\\n    act: Any = None\\n    lr: Any = 1e-05\\n    wd: Any = 1e-05\\n    freeze_at: int = 4\\n\\n\\n@dataclass\\nclass C_Head:\\n    num_classes: int = 2\\n    drop_rate: Any = 0.3\\n    lr: Any = 2e-03\\n    wd: Any = 1e-05\\n    filter_wd: Any = False\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@dataclass\n",
    "class C_Backbone:\n",
    "    model_name: str = \"resnet18\"\n",
    "    pretrained: bool = True\n",
    "    act: Any = None\n",
    "    lr: Any = 1e-05\n",
    "    wd: Any = 1e-05\n",
    "    freeze_at: int = 4\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class C_Head:\n",
    "    num_classes: int = 2\n",
    "    drop_rate: Any = 0.3\n",
    "    lr: Any = 2e-03\n",
    "    wd: Any = 1e-05\n",
    "    filter_wd: Any = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a few more things and the config must be composed in a gale config style. We need the definitions of the input like channels, height and weight. So let's compose these -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"b_args = OmegaConf.structured(C_Backbone())\\nh_args = OmegaConf.structured(C_Head())\\n\\n# Backbone config\\nb = OmegaConf.create()\\nb.name = \\\"ResNetBackbone\\\"\\nb.init_args = b_args\\n\\n# Head config\\nh = OmegaConf.create()\\nh.name = \\\"FullyConnectedHead\\\"\\nh.init_args = h_args\\n\\ni = OmegaConf.create()\\ni.channels = 3\\ni.height = 224\\ni.width = 224\\n\\nm = OmegaConf.create()\\nm.backbone = b\\nm.head = h\";\n",
       "                var nbb_formatted_code = \"b_args = OmegaConf.structured(C_Backbone())\\nh_args = OmegaConf.structured(C_Head())\\n\\n# Backbone config\\nb = OmegaConf.create()\\nb.name = \\\"ResNetBackbone\\\"\\nb.init_args = b_args\\n\\n# Head config\\nh = OmegaConf.create()\\nh.name = \\\"FullyConnectedHead\\\"\\nh.init_args = h_args\\n\\ni = OmegaConf.create()\\ni.channels = 3\\ni.height = 224\\ni.width = 224\\n\\nm = OmegaConf.create()\\nm.backbone = b\\nm.head = h\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b_args = OmegaConf.structured(C_Backbone())\n",
    "h_args = OmegaConf.structured(C_Head())\n",
    "\n",
    "# Backbone config\n",
    "b = OmegaConf.create()\n",
    "b.name = \"ResNetBackbone\"\n",
    "b.init_args = b_args\n",
    "\n",
    "# Head config\n",
    "h = OmegaConf.create()\n",
    "h.name = \"FullyConnectedHead\"\n",
    "h.init_args = h_args\n",
    "\n",
    "i = OmegaConf.create()\n",
    "i.channels = 3\n",
    "i.height = 224\n",
    "i.width = 224\n",
    "\n",
    "m = OmegaConf.create()\n",
    "m.backbone = b\n",
    "m.head = h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"conf = OmegaConf.create(dict(input=i, model=m))\\n# print(OmegaConf.to_yaml(conf))\";\n",
       "                var nbb_formatted_code = \"conf = OmegaConf.create(dict(input=i, model=m))\\n# print(OmegaConf.to_yaml(conf))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf = OmegaConf.create(dict(input=i, model=m))\n",
    "# print(OmegaConf.to_yaml(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"m = GeneralizedImageClassifier.from_config_dict(conf)\\nshape = (m.input_shape.channels, m.input_shape.height, m.input_shape.width)\\ninp = torch.randn(2, *shape)\\no = m(inp)\";\n",
       "                var nbb_formatted_code = \"m = GeneralizedImageClassifier.from_config_dict(conf)\\nshape = (m.input_shape.channels, m.input_shape.height, m.input_shape.width)\\ninp = torch.randn(2, *shape)\\no = m(inp)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = GeneralizedImageClassifier.from_config_dict(conf)\n",
    "shape = (m.input_shape.channels, m.input_shape.height, m.input_shape.width)\n",
    "inp = torch.randn(2, *shape)\n",
    "o = m(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/ayushman/Desktop/gale/nbs/data/hymenoptera_data.zip\n",
      "Extracting /Users/ayushman/Desktop/gale/nbs/data/hymenoptera_data.zip to /Users/ayushman/Desktop/gale/nbs/data\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"# hide\\nimport pytorch_lightning as pl\\nimport torchmetrics\\nimport torchvision.transforms as T\\nfrom fastcore.all import Path\\nfrom nbdev.export import Config\\nfrom torch import optim\\nfrom torch.utils.data import DataLoader\\nfrom torchvision.datasets import ImageFolder\\n\\nfrom gale.collections.callbacks import NotebookProgressCallback\\nfrom gale.collections.download import download_and_extract_archive\\nfrom gale.core.nn.optim.lr_schedulers import WarmupStepLR\\nfrom gale.core.utils.visualize import show_images\\n\\nURL = \\\"https://download.pytorch.org/tutorial/hymenoptera_data.zip\\\"\\ndata_path = Path(Config().path(\\\"nbs_path\\\")) / \\\"data\\\"\\n\\n# download a toy dataset\\ndownload_and_extract_archive(url=URL, download_root=data_path)\";\n",
       "                var nbb_formatted_code = \"# hide\\nimport pytorch_lightning as pl\\nimport torchmetrics\\nimport torchvision.transforms as T\\nfrom fastcore.all import Path\\nfrom nbdev.export import Config\\nfrom torch import optim\\nfrom torch.utils.data import DataLoader\\nfrom torchvision.datasets import ImageFolder\\n\\nfrom gale.collections.callbacks import NotebookProgressCallback\\nfrom gale.collections.download import download_and_extract_archive\\nfrom gale.core.nn.optim.lr_schedulers import WarmupStepLR\\nfrom gale.core.utils.visualize import show_images\\n\\nURL = \\\"https://download.pytorch.org/tutorial/hymenoptera_data.zip\\\"\\ndata_path = Path(Config().path(\\\"nbs_path\\\")) / \\\"data\\\"\\n\\n# download a toy dataset\\ndownload_and_extract_archive(url=URL, download_root=data_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import torchvision.transforms as T\n",
    "from fastcore.all import Path\n",
    "from nbdev.export import Config\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from gale.collections.callbacks import NotebookProgressCallback\n",
    "from gale.collections.download import download_and_extract_archive\n",
    "from gale.core.nn.optim.lr_schedulers import WarmupStepLR\n",
    "from gale.core.utils.visualize import show_images\n",
    "\n",
    "URL = \"https://download.pytorch.org/tutorial/hymenoptera_data.zip\"\n",
    "data_path = Path(Config().path(\"nbs_path\")) / \"data\"\n",
    "\n",
    "# download a toy dataset\n",
    "download_and_extract_archive(url=URL, download_root=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"# hide\\n# fmt:off\\n# Data augmentation and normalization for training\\n# Just normalization for validation\\ndata_transforms = {\\n    'train': T.Compose([\\n        T.RandomResizedCrop(224),\\n        T.RandomHorizontalFlip(),\\n        T.ToTensor(),\\n        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\\n    ]),\\n    'val': T.Compose([\\n        T.Resize(256),\\n        T.CenterCrop(224),\\n        T.ToTensor(),\\n        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\\n    ]),\\n}\\n\\ntraining_data = ImageFolder(data_path / \\\"hymenoptera_data/train\\\", transform=data_transforms[\\\"train\\\"])\\nvalidation_data = ImageFolder(data_path / \\\"hymenoptera_data/val\\\", transform=data_transforms[\\\"val\\\"])\\n\\ntrain_dl = DataLoader(training_data, batch_size=32, shuffle=True)\\nvalid_dl = DataLoader(validation_data, batch_size=32, shuffle=False)\";\n",
       "                var nbb_formatted_code = \"# hide\\n# fmt:off\\n# Data augmentation and normalization for training\\n# Just normalization for validation\\ndata_transforms = {\\n    'train': T.Compose([\\n        T.RandomResizedCrop(224),\\n        T.RandomHorizontalFlip(),\\n        T.ToTensor(),\\n        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\\n    ]),\\n    'val': T.Compose([\\n        T.Resize(256),\\n        T.CenterCrop(224),\\n        T.ToTensor(),\\n        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\\n    ]),\\n}\\n\\ntraining_data = ImageFolder(data_path / \\\"hymenoptera_data/train\\\", transform=data_transforms[\\\"train\\\"])\\nvalidation_data = ImageFolder(data_path / \\\"hymenoptera_data/val\\\", transform=data_transforms[\\\"val\\\"])\\n\\ntrain_dl = DataLoader(training_data, batch_size=32, shuffle=True)\\nvalid_dl = DataLoader(validation_data, batch_size=32, shuffle=False)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "# fmt:off\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': T.Compose([\n",
    "        T.RandomResizedCrop(224),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': T.Compose([\n",
    "        T.Resize(256),\n",
    "        T.CenterCrop(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "training_data = ImageFolder(data_path / \"hymenoptera_data/train\", transform=data_transforms[\"train\"])\n",
    "validation_data = ImageFolder(data_path / \"hymenoptera_data/val\", transform=data_transforms[\"val\"])\n",
    "\n",
    "train_dl = DataLoader(training_data, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(validation_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"# fmt:off\\nclass Learner(pl.LightningModule):\\n    def __init__(self, model: GeneralizedImageClassifier):\\n        super().__init__()\\n        self.model = model\\n        self.train_metric = torchmetrics.Accuracy()\\n        self.valid_metric = torchmetrics.Accuracy()\\n        self.loss_fn = torch.nn.CrossEntropyLoss()\\n\\n    def forward(self, xb):\\n        return self.model(xb)\\n\\n    def training_step(self, batch: Any, batch_idx: int):\\n        x, y = batch\\n        y_hat = self(x)\\n        loss = self.loss_fn(y_hat, y)\\n        acc = self.train_metric(torch.nn.functional.softmax(y_hat), y)\\n        self.log_dict(dict(loss=loss, acc=acc))\\n        return loss\\n\\n    def validation_step(self, batch: Any, batch_idx: int):\\n        x, y = batch\\n        y_hat = self(x)\\n        loss = self.loss_fn(y_hat, y)\\n        acc = self.valid_metric(torch.nn.functional.softmax(y_hat), y)\\n        self.log_dict(dict(val_loss=loss, val_acc=acc))\\n\\n    def configure_optimizers(self):\\n        paramters = self.model.build_param_dicts()\\n        opt = optim.AdamW(paramters)\\n        sch = WarmupStepLR(opt, num_decays=3, warmup_epochs=3, decay_rate=0.1, epochs=self.trainer.max_epochs)\\n        return [opt], [sch]\";\n",
       "                var nbb_formatted_code = \"# fmt:off\\nclass Learner(pl.LightningModule):\\n    def __init__(self, model: GeneralizedImageClassifier):\\n        super().__init__()\\n        self.model = model\\n        self.train_metric = torchmetrics.Accuracy()\\n        self.valid_metric = torchmetrics.Accuracy()\\n        self.loss_fn = torch.nn.CrossEntropyLoss()\\n\\n    def forward(self, xb):\\n        return self.model(xb)\\n\\n    def training_step(self, batch: Any, batch_idx: int):\\n        x, y = batch\\n        y_hat = self(x)\\n        loss = self.loss_fn(y_hat, y)\\n        acc = self.train_metric(torch.nn.functional.softmax(y_hat), y)\\n        self.log_dict(dict(loss=loss, acc=acc))\\n        return loss\\n\\n    def validation_step(self, batch: Any, batch_idx: int):\\n        x, y = batch\\n        y_hat = self(x)\\n        loss = self.loss_fn(y_hat, y)\\n        acc = self.valid_metric(torch.nn.functional.softmax(y_hat), y)\\n        self.log_dict(dict(val_loss=loss, val_acc=acc))\\n\\n    def configure_optimizers(self):\\n        paramters = self.model.build_param_dicts()\\n        opt = optim.AdamW(paramters)\\n        sch = WarmupStepLR(opt, num_decays=3, warmup_epochs=3, decay_rate=0.1, epochs=self.trainer.max_epochs)\\n        return [opt], [sch]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "# fmt:off\n",
    "class Learner(pl.LightningModule):\n",
    "    def __init__(self, model: GeneralizedImageClassifier):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.train_metric = torchmetrics.Accuracy()\n",
    "        self.valid_metric = torchmetrics.Accuracy()\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.model(xb)\n",
    "\n",
    "    def training_step(self, batch: Any, batch_idx: int):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        acc = self.train_metric(torch.nn.functional.softmax(y_hat), y)\n",
    "        self.log_dict(dict(loss=loss, acc=acc))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: Any, batch_idx: int):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        acc = self.valid_metric(torch.nn.functional.softmax(y_hat), y)\n",
    "        self.log_dict(dict(val_loss=loss, val_acc=acc))\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        paramters = self.model.build_param_dicts()\n",
    "        opt = optim.AdamW(paramters)\n",
    "        sch = WarmupStepLR(opt, num_decays=3, warmup_epochs=3, decay_rate=0.1, epochs=self.trainer.max_epochs)\n",
    "        return [opt], [sch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Missing logger folder: lightning_logs/my_model\n",
      "\n",
      "  | Name         | Type                       | Params\n",
      "------------------------------------------------------------\n",
      "0 | model        | GeneralizedImageClassifier | 11.2 M\n",
      "1 | train_metric | Accuracy                   | 0     \n",
      "2 | valid_metric | Accuracy                   | 0     \n",
      "3 | loss_fn      | CrossEntropyLoss           | 0     \n",
      "------------------------------------------------------------\n",
      "8.4 M     Trainable params\n",
      "2.8 M     Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.710    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            progress {\n",
       "                border: none;\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      Training\n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 08:01, Epoch 14 {'loss': '0.295', 'v_num': 0}]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>time</th>\n",
       "      <th>samples/s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.820101</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>1.074716</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>31.792200</td>\n",
       "      <td>0.408900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.683885</td>\n",
       "      <td>0.542484</td>\n",
       "      <td>0.769564</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>31.616300</td>\n",
       "      <td>0.411200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.455971</td>\n",
       "      <td>0.810458</td>\n",
       "      <td>0.380922</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>32.251600</td>\n",
       "      <td>0.403100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.267772</td>\n",
       "      <td>0.928105</td>\n",
       "      <td>0.317305</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>32.415400</td>\n",
       "      <td>0.401000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.264430</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.334841</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>32.588500</td>\n",
       "      <td>0.398900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.259231</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.260302</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>32.836700</td>\n",
       "      <td>0.395900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.256384</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.310489</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>33.339500</td>\n",
       "      <td>0.389900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.251130</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.432859</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>30.974400</td>\n",
       "      <td>0.419700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.253889</td>\n",
       "      <td>0.934641</td>\n",
       "      <td>0.270440</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>32.056600</td>\n",
       "      <td>0.405500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.252289</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.409051</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>31.858300</td>\n",
       "      <td>0.408100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.249282</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.340130</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>33.226700</td>\n",
       "      <td>0.391300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.247540</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.403820</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>32.663500</td>\n",
       "      <td>0.398000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.250407</td>\n",
       "      <td>0.934641</td>\n",
       "      <td>0.209085</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>34.663500</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.250662</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.285362</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>30.904500</td>\n",
       "      <td>0.420700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.247010</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.368675</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>29.077800</td>\n",
       "      <td>0.447100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"# hide\\n# fmt:off\\n# slow\\ncbs = [NotebookProgressCallback(), pl.callbacks.LearningRateMonitor(logging_interval=\\\"step\\\", log_momentum=True)]\\n\\nlogger = pl.loggers.TensorBoardLogger(save_dir=\\\"lightning_logs/\\\", name=\\\"my_model\\\", \\n                                      log_graph=True, default_hp_metric=False)\\n\\ntrainer = pl.Trainer(max_epochs=15, callbacks=cbs, log_every_n_steps=1, logger=logger)\\nmodel = GeneralizedImageClassifier.from_config_dict(conf)\\nlearn = Learner(model)\\n\\ntrainer.fit(learn, train_dataloader=train_dl, val_dataloaders=valid_dl)\";\n",
       "                var nbb_formatted_code = \"# hide\\n# fmt:off\\n# slow\\ncbs = [NotebookProgressCallback(), pl.callbacks.LearningRateMonitor(logging_interval=\\\"step\\\", log_momentum=True)]\\n\\nlogger = pl.loggers.TensorBoardLogger(save_dir=\\\"lightning_logs/\\\", name=\\\"my_model\\\", \\n                                      log_graph=True, default_hp_metric=False)\\n\\ntrainer = pl.Trainer(max_epochs=15, callbacks=cbs, log_every_n_steps=1, logger=logger)\\nmodel = GeneralizedImageClassifier.from_config_dict(conf)\\nlearn = Learner(model)\\n\\ntrainer.fit(learn, train_dataloader=train_dl, val_dataloaders=valid_dl)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "# fmt:off\n",
    "# slow\n",
    "cbs = [\n",
    "    NotebookProgressCallback(), \n",
    "    pl.callbacks.LearningRateMonitor(logging_interval=\"step\", log_momentum=True)\n",
    "]\n",
    "\n",
    "logger = pl.loggers.TensorBoardLogger(save_dir=\"lightning_logs/\", name=\"my_model\", \n",
    "                                      log_graph=True, default_hp_metric=False)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=15, callbacks=cbs, log_every_n_steps=1, logger=logger)\n",
    "model = GeneralizedImageClassifier.from_config_dict(conf)\n",
    "learn = Learner(model)\n",
    "\n",
    "trainer.fit(learn, train_dataloader=train_dl, val_dataloaders=valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.utils.logger.ipynb.\n",
      "Converted 00a_core.utils.visualize.ipynb.\n",
      "Converted 00b_core.utils.structures.ipynb.\n",
      "Converted 01_core.nn.utils.ipynb.\n",
      "Converted 01a_core.nn.losses.ipynb.\n",
      "Converted 02_core.nn.optim.optimizers.ipynb.\n",
      "Converted 02a_core.nn.optim.lr_schedulers.ipynb.\n",
      "Converted 03_core.classes.ipynb.\n",
      "Converted 04_classification.modelling.backbones.ipynb.\n",
      "Converted 04a_classification.modelling.heads.ipynb.\n",
      "Converted 04b_classification.modelling.meta_arch.common.ipynb.\n",
      "Converted 04b_classification.modelling.meta_arch.vit.ipynb.\n",
      "Converted 05_classification.data.common.ipynb.\n",
      "Converted 05a_classification.data.transforms.ipynb.\n",
      "Converted 05b_classification.data.build.ipynb.\n",
      "Converted 06_classification.task.ipynb.\n",
      "Converted 07_collections.pandas.ipynb.\n",
      "Converted 07a_collections.callbacks.notebook.ipynb.\n",
      "Converted 07b_collections.callbacks.ema.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"# hide\\nnotebook2script()\";\n",
       "                var nbb_formatted_code = \"# hide\\nnotebook2script()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gale",
   "language": "python",
   "name": "gale"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
