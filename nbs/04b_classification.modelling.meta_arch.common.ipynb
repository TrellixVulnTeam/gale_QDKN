{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# skip\n",
    "!git clone https://github.com/benihime91/gale # install gale on colab\n",
    "!pip install -e \"gale[dev]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp classification.modelling.meta_arch.common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# hide\\n%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\\n%matplotlib inline\";\n",
       "                var nbb_formatted_code = \"# hide\\n%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\\n%matplotlib inline\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# hide\\nimport warnings\\n\\nfrom nbdev.export import *\\nfrom nbdev.showdoc import *\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_formatted_code = \"# hide\\nimport warnings\\n\\nfrom nbdev.export import *\\nfrom nbdev.showdoc import *\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "import warnings\n",
    "\n",
    "from nbdev.export import *\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Architectures : Generalized Image Classifier \n",
    "> Default Model Architecture for Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# export\\nimport logging\\nfrom typing import *\\n\\nimport torch\\nfrom omegaconf import DictConfig, OmegaConf\\nfrom pytorch_lightning.core.memory import get_human_readable_count\\nfrom torch.nn import Module\\n\\nfrom gale.classification.modelling.backbones import ImageClassificationBackbone\\nfrom gale.classification.modelling.build import build_backbone, build_head\\nfrom gale.classification.modelling.heads import ImageClassificationHead\\nfrom gale.core.classes import GaleModule\\nfrom gale.core.nn.shape_spec import ShapeSpec\\n\\n_logger = logging.getLogger(__name__)\";\n",
       "                var nbb_formatted_code = \"# export\\nimport logging\\nfrom typing import *\\n\\nimport torch\\nfrom omegaconf import DictConfig, OmegaConf\\nfrom pytorch_lightning.core.memory import get_human_readable_count\\nfrom torch.nn import Module\\n\\nfrom gale.classification.modelling.backbones import ImageClassificationBackbone\\nfrom gale.classification.modelling.build import build_backbone, build_head\\nfrom gale.classification.modelling.heads import ImageClassificationHead\\nfrom gale.core.classes import GaleModule\\nfrom gale.core.nn.shape_spec import ShapeSpec\\n\\n_logger = logging.getLogger(__name__)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "import logging\n",
    "from typing import *\n",
    "\n",
    "import torch\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from pytorch_lightning.core.memory import get_human_readable_count\n",
    "from torch.nn import Module\n",
    "\n",
    "from gale.classification.modelling.backbones import ImageClassificationBackbone\n",
    "from gale.classification.modelling.build import build_backbone, build_head\n",
    "from gale.classification.modelling.heads import ImageClassificationHead\n",
    "from gale.core.classes import GaleModule\n",
    "from gale.core.nn.shape_spec import ShapeSpec\n",
    "\n",
    "_logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# export\\nclass GeneralizedImageClassifier(GaleModule):\\n    \\\"\\\"\\\"\\n    A General Image Classifier. Any models that contains the following 2 components:\\n    1. Feature extractor (aka backbone)\\n    2. Image Classification head (Pooling + Classifier)\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        backbone: ImageClassificationBackbone,\\n        head: ImageClassificationHead,\\n    ):\\n        \\\"\\\"\\\"\\n        Arguments:\\n        1. `backbone`: a `ImageClassificationBackbone` module, must follow gale's backbone interface\\n        2. `head`: a head containg the classifier. and the pooling layer, must be an instance of\\n        `ImageClassificationHead`.\\n        \\\"\\\"\\\"\\n        super(GeneralizedImageClassifier, self).__init__()\\n        self.backbone = backbone\\n        assert isinstance(backbone, ImageClassificationBackbone)\\n        self.head = head\\n        assert isinstance(head, ImageClassificationHead)\\n\\n    def forward(self, batched_inputs: torch.Tensor) -> torch.Tensor:\\n        \\\"\\\"\\\"\\n        Runs the batched_inputs through `backbone` followed by the `head`.\\n        Returns a Tensor which contains the logits for the batched_inputs.\\n        \\\"\\\"\\\"\\n        out = self.backbone(batched_inputs)\\n        out = self.head(out)\\n        return out\\n\\n    @classmethod\\n    def from_config_dict(cls, cfg: DictConfig):\\n        \\\"\\\"\\\"\\n        Instantiate the Meta Architecture from gale config\\n        \\\"\\\"\\\"\\n        # fmt: off\\n        \\n        if not hasattr(cfg.model, \\\"backbone\\\"):\\n            _logger.error(\\\"Configuration for model backbone not found\\\")\\n            raise ValueError\\n            \\n        if not hasattr(cfg.model, \\\"head\\\"):\\n            _logger.error(\\\"Configuration for model head not found\\\")\\n            raise ValueError\\n            \\n        input_shape = ShapeSpec(cfg.input.channels, cfg.input.height, cfg.input.width)\\n        _logger.debug(f\\\"Inputs: {input_shape}\\\")\\n        \\n        backbone = build_backbone(cfg, input_shape=input_shape)\\n        param_count = get_human_readable_count(sum([m.numel() for m in backbone.parameters()]))\\n        _logger.debug('Backbone {} created, param count: {}.'.format(cfg.model.backbone.name, param_count))\\n        \\n        head = build_head(cfg, backbone.output_shape())\\n        param_count = get_human_readable_count(sum([m.numel() for m in head.parameters()]))\\n        _logger.debug('Head {} created, param count: {}.'.format(cfg.model.head.name, param_count))\\n        \\n        kwds = {\\\"backbone\\\": backbone, \\\"head\\\": head}\\n        \\n        instance = cls(**kwds)\\n        instance._cfg = OmegaConf.to_container(cfg.model, resolve=True)\\n        instance.input_shape = input_shape\\n        param_count = get_human_readable_count(sum([m.numel() for m in instance.parameters()]))\\n        _logger.info(\\\"Model created, param count: {}.\\\".format(param_count))\\n        # fmt: on\\n        return instance\\n\\n    def build_param_dicts(self):\\n        \\\"\\\"\\\"\\n        Builds up the Paramters dicts for optimization.\\n        \\\"\\\"\\\"\\n        backbone_params = self.backbone.build_param_dicts()\\n        head_params = self.head.build_param_dicts()\\n        return backbone_params + head_params\\n\\n    def get_lrs(self) -> List:\\n        \\\"\\\"\\\"\\n        Returns a List containining the Lrs' for\\n        each parameter group. This is required to build schedulers\\n        like `torch.optim.lr_scheduler.OneCycleScheduler` which needs\\n        the max lrs' for all the Param Groups.\\n        \\\"\\\"\\\"\\n        lrs = []\\n\\n        for p in self.build_param_dicts():\\n            lrs.append(p[\\\"lr\\\"])\\n        return lrs\";\n",
       "                var nbb_formatted_code = \"# export\\nclass GeneralizedImageClassifier(GaleModule):\\n    \\\"\\\"\\\"\\n    A General Image Classifier. Any models that contains the following 2 components:\\n    1. Feature extractor (aka backbone)\\n    2. Image Classification head (Pooling + Classifier)\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        backbone: ImageClassificationBackbone,\\n        head: ImageClassificationHead,\\n    ):\\n        \\\"\\\"\\\"\\n        Arguments:\\n        1. `backbone`: a `ImageClassificationBackbone` module, must follow gale's backbone interface\\n        2. `head`: a head containg the classifier. and the pooling layer, must be an instance of\\n        `ImageClassificationHead`.\\n        \\\"\\\"\\\"\\n        super(GeneralizedImageClassifier, self).__init__()\\n        self.backbone = backbone\\n        assert isinstance(backbone, ImageClassificationBackbone)\\n        self.head = head\\n        assert isinstance(head, ImageClassificationHead)\\n\\n    def forward(self, batched_inputs: torch.Tensor) -> torch.Tensor:\\n        \\\"\\\"\\\"\\n        Runs the batched_inputs through `backbone` followed by the `head`.\\n        Returns a Tensor which contains the logits for the batched_inputs.\\n        \\\"\\\"\\\"\\n        out = self.backbone(batched_inputs)\\n        out = self.head(out)\\n        return out\\n\\n    @classmethod\\n    def from_config_dict(cls, cfg: DictConfig):\\n        \\\"\\\"\\\"\\n        Instantiate the Meta Architecture from gale config\\n        \\\"\\\"\\\"\\n        # fmt: off\\n        \\n        if not hasattr(cfg.model, \\\"backbone\\\"):\\n            _logger.error(\\\"Configuration for model backbone not found\\\")\\n            raise ValueError\\n            \\n        if not hasattr(cfg.model, \\\"head\\\"):\\n            _logger.error(\\\"Configuration for model head not found\\\")\\n            raise ValueError\\n            \\n        input_shape = ShapeSpec(cfg.input.channels, cfg.input.height, cfg.input.width)\\n        _logger.debug(f\\\"Inputs: {input_shape}\\\")\\n        \\n        backbone = build_backbone(cfg, input_shape=input_shape)\\n        param_count = get_human_readable_count(sum([m.numel() for m in backbone.parameters()]))\\n        _logger.debug('Backbone {} created, param count: {}.'.format(cfg.model.backbone.name, param_count))\\n        \\n        head = build_head(cfg, backbone.output_shape())\\n        param_count = get_human_readable_count(sum([m.numel() for m in head.parameters()]))\\n        _logger.debug('Head {} created, param count: {}.'.format(cfg.model.head.name, param_count))\\n        \\n        kwds = {\\\"backbone\\\": backbone, \\\"head\\\": head}\\n        \\n        instance = cls(**kwds)\\n        instance._cfg = OmegaConf.to_container(cfg.model, resolve=True)\\n        instance.input_shape = input_shape\\n        param_count = get_human_readable_count(sum([m.numel() for m in instance.parameters()]))\\n        _logger.info(\\\"Model created, param count: {}.\\\".format(param_count))\\n        # fmt: on\\n        return instance\\n\\n    def build_param_dicts(self):\\n        \\\"\\\"\\\"\\n        Builds up the Paramters dicts for optimization.\\n        \\\"\\\"\\\"\\n        backbone_params = self.backbone.build_param_dicts()\\n        head_params = self.head.build_param_dicts()\\n        return backbone_params + head_params\\n\\n    def get_lrs(self) -> List:\\n        \\\"\\\"\\\"\\n        Returns a List containining the Lrs' for\\n        each parameter group. This is required to build schedulers\\n        like `torch.optim.lr_scheduler.OneCycleScheduler` which needs\\n        the max lrs' for all the Param Groups.\\n        \\\"\\\"\\\"\\n        lrs = []\\n\\n        for p in self.build_param_dicts():\\n            lrs.append(p[\\\"lr\\\"])\\n        return lrs\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class GeneralizedImageClassifier(GaleModule):\n",
    "    \"\"\"\n",
    "    A General Image Classifier. Any models that contains the following 2 components:\n",
    "    1. Feature extractor (aka backbone)\n",
    "    2. Image Classification head (Pooling + Classifier)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone: ImageClassificationBackbone,\n",
    "        head: ImageClassificationHead,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        1. `backbone`: a `ImageClassificationBackbone` module, must follow gale's backbone interface\n",
    "        2. `head`: a head containg the classifier. and the pooling layer, must be an instance of\n",
    "        `ImageClassificationHead`.\n",
    "        \"\"\"\n",
    "        super(GeneralizedImageClassifier, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        assert isinstance(backbone, ImageClassificationBackbone)\n",
    "        self.head = head\n",
    "        assert isinstance(head, ImageClassificationHead)\n",
    "\n",
    "    def forward(self, batched_inputs: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Runs the batched_inputs through `backbone` followed by the `head`.\n",
    "        Returns a Tensor which contains the logits for the batched_inputs.\n",
    "        \"\"\"\n",
    "        out = self.backbone(batched_inputs)\n",
    "        out = self.head(out)\n",
    "        return out\n",
    "\n",
    "    @classmethod\n",
    "    def from_config_dict(cls, cfg: DictConfig):\n",
    "        \"\"\"\n",
    "        Instantiate the Meta Architecture from gale config\n",
    "        \"\"\"\n",
    "        # fmt: off\n",
    "        \n",
    "        if not hasattr(cfg.model, \"backbone\"):\n",
    "            _logger.error(\"Configuration for model backbone not found\")\n",
    "            raise ValueError\n",
    "            \n",
    "        if not hasattr(cfg.model, \"head\"):\n",
    "            _logger.error(\"Configuration for model head not found\")\n",
    "            raise ValueError\n",
    "            \n",
    "        input_shape = ShapeSpec(cfg.input.channels, cfg.input.height, cfg.input.width)\n",
    "        _logger.debug(f\"Inputs: {input_shape}\")\n",
    "        \n",
    "        backbone = build_backbone(cfg, input_shape=input_shape)\n",
    "        param_count = get_human_readable_count(sum([m.numel() for m in backbone.parameters()]))\n",
    "        _logger.debug('Backbone {} created, param count: {}.'.format(cfg.model.backbone.name, param_count))\n",
    "        \n",
    "        head = build_head(cfg, backbone.output_shape())\n",
    "        param_count = get_human_readable_count(sum([m.numel() for m in head.parameters()]))\n",
    "        _logger.debug('Head {} created, param count: {}.'.format(cfg.model.head.name, param_count))\n",
    "        \n",
    "        kwds = {\"backbone\": backbone, \"head\": head}\n",
    "        \n",
    "        instance = cls(**kwds)\n",
    "        instance._cfg = OmegaConf.to_container(cfg.model, resolve=True)\n",
    "        instance.input_shape = input_shape\n",
    "        param_count = get_human_readable_count(sum([m.numel() for m in instance.parameters()]))\n",
    "        _logger.info(\"Model created, param count: {}.\".format(param_count))\n",
    "        # fmt: on\n",
    "        return instance\n",
    "\n",
    "    def build_param_dicts(self):\n",
    "        \"\"\"\n",
    "        Builds up the Paramters dicts for optimization.\n",
    "        \"\"\"\n",
    "        backbone_params = self.backbone.build_param_dicts()\n",
    "        head_params = self.head.build_param_dicts()\n",
    "        return backbone_params + head_params\n",
    "\n",
    "    def get_lrs(self) -> List:\n",
    "        \"\"\"\n",
    "        Returns a List containining the Lrs' for\n",
    "        each parameter group. This is required to build schedulers\n",
    "        like `torch.optim.lr_scheduler.OneCycleScheduler` which needs\n",
    "        the max lrs' for all the Param Groups.\n",
    "        \"\"\"\n",
    "        lrs = []\n",
    "\n",
    "        for p in self.build_param_dicts():\n",
    "            lrs.append(p[\"lr\"])\n",
    "        return lrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model architecture will work for most common computer vision fietuning use case. We take a `backbone` and `classifier`. We run the input through the backbone to extract the feature_maps which are then used by the classifier to given predictions on the Input. The paramters dicts for optimization are generated by the `backbone` and the `head` itself.\n",
    "\n",
    "> Note: For advanced use cases you might want to create a model. A model muse inherit from `GaleModule` and be registered in `META_ARCH_REGISTRY`. Your model should also have the following methods to work in the Gale ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"GeneralizedImageClassifier.from_config_dict\" class=\"doc_header\"><code>GeneralizedImageClassifier.from_config_dict</code><a href=\"__main__.py#L35\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>GeneralizedImageClassifier.from_config_dict</code>(**`cfg`**:`DictConfig`)\n",
       "\n",
       "Instantiate the Meta Architecture from gale config"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"show_doc(GeneralizedImageClassifier.from_config_dict)\";\n",
       "                var nbb_formatted_code = \"show_doc(GeneralizedImageClassifier.from_config_dict)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(GeneralizedImageClassifier.from_config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"GeneralizedImageClassifier.forward\" class=\"doc_header\"><code>GeneralizedImageClassifier.forward</code><a href=\"__main__.py#L26\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>GeneralizedImageClassifier.forward</code>(**`batched_inputs`**:`Tensor`)\n",
       "\n",
       "Runs the batched_inputs through `backbone` followed by the `head`.\n",
       "Returns a Tensor which contains the logits for the batched_inputs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"show_doc(GeneralizedImageClassifier.forward)\";\n",
       "                var nbb_formatted_code = \"show_doc(GeneralizedImageClassifier.forward)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(GeneralizedImageClassifier.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"GeneralizedImageClassifier.build_param_dicts\" class=\"doc_header\"><code>GeneralizedImageClassifier.build_param_dicts</code><a href=\"__main__.py#L71\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>GeneralizedImageClassifier.build_param_dicts</code>()\n",
       "\n",
       "Builds up the Paramters dicts for optimization."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"show_doc(GeneralizedImageClassifier.build_param_dicts)\";\n",
       "                var nbb_formatted_code = \"show_doc(GeneralizedImageClassifier.build_param_dicts)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(GeneralizedImageClassifier.build_param_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Meta_Arch`'s can also be instatiated via a appropriate config file. Let's see how .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"from dataclasses import dataclass, field\\nfrom omegaconf import MISSING, OmegaConf\\nfrom gale.classification.modelling.backbones import ResNetBackbone\\nfrom gale.classification.modelling.heads import FastaiHead\";\n",
       "                var nbb_formatted_code = \"from dataclasses import dataclass, field\\nfrom omegaconf import MISSING, OmegaConf\\nfrom gale.classification.modelling.backbones import ResNetBackbone\\nfrom gale.classification.modelling.heads import FastaiHead\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from omegaconf import MISSING, OmegaConf\n",
    "from gale.classification.modelling.backbones import ResNetBackbone\n",
    "from gale.classification.modelling.heads import FastaiHead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a meta_arch we first need to create the configurations for the `Backbone` and the `Head` of the model. These \n",
    "must be registerd in `IMAGE_CLASSIFICATION_BACKBONES` and `IMAGE_CLASSIFICATION_HEADS` Registy respectively. The instances are automatically instiated by the `GeneralizedImageClassifier` meta_arch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"@dataclass\\nclass BackboneConf:\\n    model_name: str = \\\"resnetblur18\\\"\\n    act: Any = None\\n    lr: Any = 2e-04\\n    lr_div: Any = 10\\n    wd: Any = 1e-02\\n    freeze_at: int = 0\\n    pretrained: bool = False\\n    drop_block_rate: Any = None\\n    drop_path_rate: Any = None\\n    bn_tf: bool = False\\n\\n\\n@dataclass\\nclass HeadConf:\\n    num_classes: int = MISSING\\n    act: str = \\\"ReLU\\\"\\n    lin_ftrs: Any = None\\n    ps: Any = 0.5\\n    concat_pool: bool = True\\n    first_bn: bool = True\\n    bn_final: bool = False\\n    lr: float = 2e-03\\n    wd: float = 1e-02\\n    filter_wd: bool = False\";\n",
       "                var nbb_formatted_code = \"@dataclass\\nclass BackboneConf:\\n    model_name: str = \\\"resnetblur18\\\"\\n    act: Any = None\\n    lr: Any = 2e-04\\n    lr_div: Any = 10\\n    wd: Any = 1e-02\\n    freeze_at: int = 0\\n    pretrained: bool = False\\n    drop_block_rate: Any = None\\n    drop_path_rate: Any = None\\n    bn_tf: bool = False\\n\\n\\n@dataclass\\nclass HeadConf:\\n    num_classes: int = MISSING\\n    act: str = \\\"ReLU\\\"\\n    lin_ftrs: Any = None\\n    ps: Any = 0.5\\n    concat_pool: bool = True\\n    first_bn: bool = True\\n    bn_final: bool = False\\n    lr: float = 2e-03\\n    wd: float = 1e-02\\n    filter_wd: bool = False\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@dataclass\n",
    "class BackboneConf:\n",
    "    model_name: str = \"resnetblur18\"\n",
    "    act: Any = None\n",
    "    lr: Any = 2e-04\n",
    "    lr_div: Any = 10\n",
    "    wd: Any = 1e-02\n",
    "    freeze_at: int = 0\n",
    "    pretrained: bool = False\n",
    "    drop_block_rate: Any = None\n",
    "    drop_path_rate: Any = None\n",
    "    bn_tf: bool = False\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class HeadConf:\n",
    "    num_classes: int = MISSING\n",
    "    act: str = \"ReLU\"\n",
    "    lin_ftrs: Any = None\n",
    "    ps: Any = 0.5\n",
    "    concat_pool: bool = True\n",
    "    first_bn: bool = True\n",
    "    bn_final: bool = False\n",
    "    lr: float = 2e-03\n",
    "    wd: float = 1e-02\n",
    "    filter_wd: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a few more things and the config must be composed in a gale config style. We need the definitions of the input like channels, height and weight. So let's compose these -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"b_args = OmegaConf.structured(BackboneConf())\\nh_args = OmegaConf.structured(HeadConf(num_classes=10))\\n\\n# Backbone config\\nb = OmegaConf.create()\\nb.name = \\\"ResNetBackbone\\\"\\nb.init_args = b_args\\n\\n# Head config\\nh = OmegaConf.create()\\nh.name = \\\"FastaiHead\\\"\\nh.init_args = h_args\\n\\ni = OmegaConf.create()\\ni.channels = 3\\ni.height = 224\\ni.width = 224\\n\\nm = OmegaConf.create()\\nm.backbone = b\\nm.head = h\";\n",
       "                var nbb_formatted_code = \"b_args = OmegaConf.structured(BackboneConf())\\nh_args = OmegaConf.structured(HeadConf(num_classes=10))\\n\\n# Backbone config\\nb = OmegaConf.create()\\nb.name = \\\"ResNetBackbone\\\"\\nb.init_args = b_args\\n\\n# Head config\\nh = OmegaConf.create()\\nh.name = \\\"FastaiHead\\\"\\nh.init_args = h_args\\n\\ni = OmegaConf.create()\\ni.channels = 3\\ni.height = 224\\ni.width = 224\\n\\nm = OmegaConf.create()\\nm.backbone = b\\nm.head = h\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b_args = OmegaConf.structured(BackboneConf())\n",
    "h_args = OmegaConf.structured(HeadConf(num_classes=10))\n",
    "\n",
    "# Backbone config\n",
    "b = OmegaConf.create()\n",
    "b.name = \"ResNetBackbone\"\n",
    "b.init_args = b_args\n",
    "\n",
    "# Head config\n",
    "h = OmegaConf.create()\n",
    "h.name = \"FastaiHead\"\n",
    "h.init_args = h_args\n",
    "\n",
    "i = OmegaConf.create()\n",
    "i.channels = 3\n",
    "i.height = 224\n",
    "i.width = 224\n",
    "\n",
    "m = OmegaConf.create()\n",
    "m.backbone = b\n",
    "m.head = h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"conf = OmegaConf.create(dict(input=i, model=m))\";\n",
       "                var nbb_formatted_code = \"conf = OmegaConf.create(dict(input=i, model=m))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf = OmegaConf.create(dict(input=i, model=m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"m = GeneralizedImageClassifier.from_config_dict(conf)\\n\\nassert isinstance(m, GeneralizedImageClassifier)\\nassert isinstance(m.backbone, ResNetBackbone)\\nassert isinstance(m.head, FastaiHead)\";\n",
       "                var nbb_formatted_code = \"m = GeneralizedImageClassifier.from_config_dict(conf)\\n\\nassert isinstance(m, GeneralizedImageClassifier)\\nassert isinstance(m.backbone, ResNetBackbone)\\nassert isinstance(m.head, FastaiHead)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = GeneralizedImageClassifier.from_config_dict(conf)\n",
    "\n",
    "assert isinstance(m, GeneralizedImageClassifier)\n",
    "assert isinstance(m.backbone, ResNetBackbone)\n",
    "assert isinstance(m.head, FastaiHead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeneralizedImageClassifier(\n",
      "  (backbone): ResNetBackbone(\n",
      "    (stem): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): BlurPool2d(\n",
      "          (padding): ReflectionPad2d([1, 1, 1, 1])\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (stages): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (aa): BlurPool2d(\n",
      "            (padding): ReflectionPad2d([1, 1, 1, 1])\n",
      "          )\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (aa): BlurPool2d(\n",
      "            (padding): ReflectionPad2d([1, 1, 1, 1])\n",
      "          )\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (aa): BlurPool2d(\n",
      "            (padding): ReflectionPad2d([1, 1, 1, 1])\n",
      "          )\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): FastaiHead(\n",
      "    (layers): Sequential(\n",
      "      (0): SelectAdaptivePool2d (pool_type=catavgmax, flatten=True)\n",
      "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.25, inplace=False)\n",
      "      (3): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): Dropout(p=0.5, inplace=False)\n",
      "      (7): Linear(in_features=512, out_features=10, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# collapse-output\\nprint(m)\";\n",
       "                var nbb_formatted_code = \"# collapse-output\\nprint(m)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# collapse-output\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"shape = (m.input_shape.channels, m.input_shape.height, m.input_shape.width)\\ninp = torch.randn(2, *shape)\\no = m(inp)\";\n",
       "                var nbb_formatted_code = \"shape = (m.input_shape.channels, m.input_shape.height, m.input_shape.width)\\ninp = torch.randn(2, *shape)\\no = m(inp)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shape = (m.input_shape.channels, m.input_shape.height, m.input_shape.width)\n",
    "inp = torch.randn(2, *shape)\n",
    "o = m(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.utils.logger.ipynb.\n",
      "Converted 00a_core.utils.visualize.ipynb.\n",
      "Converted 00b_core.utils.structures.ipynb.\n",
      "Converted 01_core.nn.utils.ipynb.\n",
      "Converted 01a_core.nn.losses.ipynb.\n",
      "Converted 02_core.nn.optim.optimizers.ipynb.\n",
      "Converted 02a_core.nn.optim.lr_schedulers.ipynb.\n",
      "Converted 03_core.classes.ipynb.\n",
      "Converted 04_classification.modelling.backbones.ipynb.\n",
      "Converted 04a_classification.modelling.heads.ipynb.\n",
      "Converted 04b_classification.modelling.meta_arch.common.ipynb.\n",
      "Converted 04b_classification.modelling.meta_arch.vit.ipynb.\n",
      "Converted 05_classification.data.common.ipynb.\n",
      "Converted 05a_classification.data.transforms.ipynb.\n",
      "Converted 05b_classification.data.build.ipynb.\n",
      "Converted 06_classification.task.ipynb.\n",
      "Converted 07_collections.pandas.ipynb.\n",
      "Converted 07a_collections.callbacks.notebook.ipynb.\n",
      "Converted 07b_collections.callbacks.ema.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# hide\\nnotebook2script()\";\n",
       "                var nbb_formatted_code = \"# hide\\nnotebook2script()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gale",
   "language": "python",
   "name": "gale"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
