{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# skip\n",
    "!git clone https://github.com/benihime91/gale # install gale on colab\n",
    "!pip install -e \"gale[dev]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp classification.model.meta_arch.common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# hide\\n%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\\n%matplotlib inline\";\n",
       "                var nbb_formatted_code = \"# hide\\n%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\\n%matplotlib inline\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# hide\\nimport warnings\\n\\nfrom nbdev.export import *\\nfrom nbdev.showdoc import *\\nfrom timm.utils import *\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\nsetup_default_logging(default_level=20)\";\n",
       "                var nbb_formatted_code = \"# hide\\nimport warnings\\n\\nfrom nbdev.export import *\\nfrom nbdev.showdoc import *\\nfrom timm.utils import *\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\nsetup_default_logging(default_level=20)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "import warnings\n",
    "\n",
    "from nbdev.export import *\n",
    "from nbdev.showdoc import *\n",
    "from timm.utils import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "setup_default_logging(default_level=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Architectures : Generalized Image Classifier \n",
    "> Default Model Architecture for Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# export\\nimport logging\\nfrom collections import namedtuple\\nfrom typing import *\\n\\nimport torch\\nfrom omegaconf import DictConfig, OmegaConf\\nfrom pytorch_lightning.core.memory import get_human_readable_count\\nfrom torch.nn import Module\\n\\nfrom gale.classification.model.backbones import ImageClassificationBackbone\\nfrom gale.classification.model.build import build_backbone, build_head\\nfrom gale.classification.model.heads import ImageClassificationHead\\nfrom gale.core_classes import BasicModule\\nfrom gale.utils.shape_spec import ShapeSpec\\n\\n_logger = logging.getLogger(__name__)\";\n",
       "                var nbb_formatted_code = \"# export\\nimport logging\\nfrom collections import namedtuple\\nfrom typing import *\\n\\nimport torch\\nfrom omegaconf import DictConfig, OmegaConf\\nfrom pytorch_lightning.core.memory import get_human_readable_count\\nfrom torch.nn import Module\\n\\nfrom gale.classification.model.backbones import ImageClassificationBackbone\\nfrom gale.classification.model.build import build_backbone, build_head\\nfrom gale.classification.model.heads import ImageClassificationHead\\nfrom gale.core_classes import BasicModule\\nfrom gale.utils.shape_spec import ShapeSpec\\n\\n_logger = logging.getLogger(__name__)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "import logging\n",
    "from collections import namedtuple\n",
    "from typing import *\n",
    "\n",
    "import torch\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from pytorch_lightning.core.memory import get_human_readable_count\n",
    "from torch.nn import Module\n",
    "\n",
    "from gale.classification.model.backbones import ImageClassificationBackbone\n",
    "from gale.classification.model.build import build_backbone, build_head\n",
    "from gale.classification.model.heads import ImageClassificationHead\n",
    "from gale.core_classes import BasicModule\n",
    "from gale.utils.shape_spec import ShapeSpec\n",
    "\n",
    "_logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# export\\nclass GeneralizedImageClassifier(BasicModule):\\n    \\\"\\\"\\\"\\n    A General Image Classifier. Any models that contains the following 2 components:\\n    1. Feature extractor (aka backbone)\\n    2. Image Classification head (Pooling + Classifier)\\n    \\\"\\\"\\\"\\n\\n    _hypers = namedtuple(\\\"hypers\\\", field_names=[\\\"lr\\\", \\\"wd\\\"])\\n\\n    def __init__(\\n        self,\\n        backbone: ImageClassificationBackbone,\\n        head: ImageClassificationHead,\\n    ):\\n        \\\"\\\"\\\"\\n        Arguments:\\n        1. `backbone`: a `ImageClassificationBackbone` module, must follow gale's backbone interface\\n        2. `head`: a head containg the classifier. and the pooling layer, must be an instance of\\n        `ImageClassificationHead`.\\n        \\\"\\\"\\\"\\n        super(GeneralizedImageClassifier, self).__init__()\\n        self.backbone = backbone\\n        assert isinstance(backbone, ImageClassificationBackbone)\\n        self.head = head\\n        assert isinstance(head, ImageClassificationHead)\\n\\n    def forward(self, batched_inputs: torch.Tensor) -> torch.Tensor:\\n        \\\"\\\"\\\"\\n        Runs the batched_inputs through `backbone` followed by the `head`.\\n        Returns a Tensor which contains the logits for the batched_inputs.\\n        \\\"\\\"\\\"\\n        # forward pass through the backbone\\n        out = self.backbone(batched_inputs)\\n        # pass through the classification layer\\n        out = self.head(out)\\n        return out\\n\\n    @classmethod\\n    def from_config_dict(cls, cfg: DictConfig):\\n        \\\"\\\"\\\"\\n        Instantiate the Meta Architecture from gale config\\n        \\\"\\\"\\\"\\n        if not hasattr(cfg.model, \\\"backbone\\\"):\\n            raise ValueError(\\\"Configuration for model backbone not found\\\")\\n\\n        if not hasattr(cfg.model, \\\"head\\\"):\\n            raise ValueError(\\\"Configuration for model head not found\\\")\\n\\n        input_shape = ShapeSpec(cfg.input.channels, cfg.input.height, cfg.input.width)\\n        _logger.info(f\\\"Inputs: {input_shape}\\\")\\n\\n        backbone = build_backbone(cfg, input_shape=input_shape)\\n        param_count = get_human_readable_count(\\n            sum([m.numel() for m in backbone.parameters()])\\n        )\\n        _logger.info(\\n            \\\"Backbone {} created, param count: {}.\\\".format(\\n                cfg.model.backbone.name, param_count\\n            )\\n        )\\n\\n        head = build_head(cfg, backbone.output_shape())\\n        param_count = get_human_readable_count(\\n            sum([m.numel() for m in head.parameters()])\\n        )\\n        _logger.info(\\n            \\\"Head {} created, param count: {}.\\\".format(cfg.model.head.name, param_count)\\n        )\\n\\n        kwds = {\\\"backbone\\\": backbone, \\\"head\\\": head}\\n\\n        instance = cls(**kwds)\\n        instance.input_shape = input_shape\\n\\n        param_count = get_human_readable_count(\\n            sum([m.numel() for m in instance.parameters()])\\n        )\\n        _logger.info(\\\"Model created, param count: {}.\\\".format(param_count))\\n\\n        return instance\\n\\n    def build_param_dicts(self):\\n        \\\"\\\"\\\"\\n        Builds up the Paramters dicts for optimization\\n        \\\"\\\"\\\"\\n        backbone_params = self.backbone.build_param_dicts()\\n        head_params = self.head.build_param_dicts()\\n        return backbone_params + head_params\\n\\n    @property\\n    def hypers(self) -> Tuple:\\n        \\\"\\\"\\\"\\n        Returns list of parameters like `lr` and `wd`\\n        for each param group\\n        \\\"\\\"\\\"\\n        lrs = []\\n        wds = []\\n\\n        for p in self.build_param_dicts():\\n            lrs.append(p[\\\"lr\\\"])\\n            wds.append(p[\\\"weight_decay\\\"])\\n        return self._hypers(lrs, wds)\";\n",
       "                var nbb_formatted_code = \"# export\\nclass GeneralizedImageClassifier(BasicModule):\\n    \\\"\\\"\\\"\\n    A General Image Classifier. Any models that contains the following 2 components:\\n    1. Feature extractor (aka backbone)\\n    2. Image Classification head (Pooling + Classifier)\\n    \\\"\\\"\\\"\\n\\n    _hypers = namedtuple(\\\"hypers\\\", field_names=[\\\"lr\\\", \\\"wd\\\"])\\n\\n    def __init__(\\n        self,\\n        backbone: ImageClassificationBackbone,\\n        head: ImageClassificationHead,\\n    ):\\n        \\\"\\\"\\\"\\n        Arguments:\\n        1. `backbone`: a `ImageClassificationBackbone` module, must follow gale's backbone interface\\n        2. `head`: a head containg the classifier. and the pooling layer, must be an instance of\\n        `ImageClassificationHead`.\\n        \\\"\\\"\\\"\\n        super(GeneralizedImageClassifier, self).__init__()\\n        self.backbone = backbone\\n        assert isinstance(backbone, ImageClassificationBackbone)\\n        self.head = head\\n        assert isinstance(head, ImageClassificationHead)\\n\\n    def forward(self, batched_inputs: torch.Tensor) -> torch.Tensor:\\n        \\\"\\\"\\\"\\n        Runs the batched_inputs through `backbone` followed by the `head`.\\n        Returns a Tensor which contains the logits for the batched_inputs.\\n        \\\"\\\"\\\"\\n        # forward pass through the backbone\\n        out = self.backbone(batched_inputs)\\n        # pass through the classification layer\\n        out = self.head(out)\\n        return out\\n\\n    @classmethod\\n    def from_config_dict(cls, cfg: DictConfig):\\n        \\\"\\\"\\\"\\n        Instantiate the Meta Architecture from gale config\\n        \\\"\\\"\\\"\\n        if not hasattr(cfg.model, \\\"backbone\\\"):\\n            raise ValueError(\\\"Configuration for model backbone not found\\\")\\n\\n        if not hasattr(cfg.model, \\\"head\\\"):\\n            raise ValueError(\\\"Configuration for model head not found\\\")\\n\\n        input_shape = ShapeSpec(cfg.input.channels, cfg.input.height, cfg.input.width)\\n        _logger.info(f\\\"Inputs: {input_shape}\\\")\\n\\n        backbone = build_backbone(cfg, input_shape=input_shape)\\n        param_count = get_human_readable_count(\\n            sum([m.numel() for m in backbone.parameters()])\\n        )\\n        _logger.info(\\n            \\\"Backbone {} created, param count: {}.\\\".format(\\n                cfg.model.backbone.name, param_count\\n            )\\n        )\\n\\n        head = build_head(cfg, backbone.output_shape())\\n        param_count = get_human_readable_count(\\n            sum([m.numel() for m in head.parameters()])\\n        )\\n        _logger.info(\\n            \\\"Head {} created, param count: {}.\\\".format(cfg.model.head.name, param_count)\\n        )\\n\\n        kwds = {\\\"backbone\\\": backbone, \\\"head\\\": head}\\n\\n        instance = cls(**kwds)\\n        instance.input_shape = input_shape\\n\\n        param_count = get_human_readable_count(\\n            sum([m.numel() for m in instance.parameters()])\\n        )\\n        _logger.info(\\\"Model created, param count: {}.\\\".format(param_count))\\n\\n        return instance\\n\\n    def build_param_dicts(self):\\n        \\\"\\\"\\\"\\n        Builds up the Paramters dicts for optimization\\n        \\\"\\\"\\\"\\n        backbone_params = self.backbone.build_param_dicts()\\n        head_params = self.head.build_param_dicts()\\n        return backbone_params + head_params\\n\\n    @property\\n    def hypers(self) -> Tuple:\\n        \\\"\\\"\\\"\\n        Returns list of parameters like `lr` and `wd`\\n        for each param group\\n        \\\"\\\"\\\"\\n        lrs = []\\n        wds = []\\n\\n        for p in self.build_param_dicts():\\n            lrs.append(p[\\\"lr\\\"])\\n            wds.append(p[\\\"weight_decay\\\"])\\n        return self._hypers(lrs, wds)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class GeneralizedImageClassifier(BasicModule):\n",
    "    \"\"\"\n",
    "    A General Image Classifier. Any models that contains the following 2 components:\n",
    "    1. Feature extractor (aka backbone)\n",
    "    2. Image Classification head (Pooling + Classifier)\n",
    "    \"\"\"\n",
    "\n",
    "    _hypers = namedtuple(\"hypers\", field_names=[\"lr\", \"wd\"])\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone: ImageClassificationBackbone,\n",
    "        head: ImageClassificationHead,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        1. `backbone`: a `ImageClassificationBackbone` module, must follow gale's backbone interface\n",
    "        2. `head`: a head containg the classifier. and the pooling layer, must be an instance of\n",
    "        `ImageClassificationHead`.\n",
    "        \"\"\"\n",
    "        super(GeneralizedImageClassifier, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        assert isinstance(backbone, ImageClassificationBackbone)\n",
    "        self.head = head\n",
    "        assert isinstance(head, ImageClassificationHead)\n",
    "\n",
    "    def forward(self, batched_inputs: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Runs the batched_inputs through `backbone` followed by the `head`.\n",
    "        Returns a Tensor which contains the logits for the batched_inputs.\n",
    "        \"\"\"\n",
    "        # forward pass through the backbone\n",
    "        out = self.backbone(batched_inputs)\n",
    "        # pass through the classification layer\n",
    "        out = self.head(out)\n",
    "        return out\n",
    "\n",
    "    @classmethod\n",
    "    def from_config_dict(cls, cfg: DictConfig):\n",
    "        \"\"\"\n",
    "        Instantiate the Meta Architecture from gale config\n",
    "        \"\"\"\n",
    "        if not hasattr(cfg.model, \"backbone\"):\n",
    "            raise ValueError(\"Configuration for model backbone not found\")\n",
    "\n",
    "        if not hasattr(cfg.model, \"head\"):\n",
    "            raise ValueError(\"Configuration for model head not found\")\n",
    "\n",
    "        input_shape = ShapeSpec(cfg.input.channels, cfg.input.height, cfg.input.width)\n",
    "        _logger.debug(f\"Inputs: {input_shape}\")\n",
    "\n",
    "        backbone = build_backbone(cfg, input_shape=input_shape)\n",
    "        param_count = get_human_readable_count(\n",
    "            sum([m.numel() for m in backbone.parameters()])\n",
    "        )\n",
    "        _logger.debug(\n",
    "            \"Backbone {} created, param count: {}.\".format(\n",
    "                cfg.model.backbone.name, param_count\n",
    "            )\n",
    "        )\n",
    "\n",
    "        head = build_head(cfg, backbone.output_shape())\n",
    "        param_count = get_human_readable_count(\n",
    "            sum([m.numel() for m in head.parameters()])\n",
    "        )\n",
    "        _logger.debug(\n",
    "            \"Head {} created, param count: {}.\".format(cfg.model.head.name, param_count)\n",
    "        )\n",
    "\n",
    "        kwds = {\"backbone\": backbone, \"head\": head}\n",
    "\n",
    "        instance = cls(**kwds)\n",
    "        instance.input_shape = input_shape\n",
    "\n",
    "        param_count = get_human_readable_count(\n",
    "            sum([m.numel() for m in instance.parameters()])\n",
    "        )\n",
    "        _logger.info(\"Model created, param count: {}.\".format(param_count))\n",
    "\n",
    "        return instance\n",
    "\n",
    "    def build_param_dicts(self):\n",
    "        \"\"\"\n",
    "        Builds up the Paramters dicts for optimization\n",
    "        \"\"\"\n",
    "        backbone_params = self.backbone.build_param_dicts()\n",
    "        head_params = self.head.build_param_dicts()\n",
    "        return backbone_params + head_params\n",
    "\n",
    "    @property\n",
    "    def hypers(self) -> Tuple:\n",
    "        \"\"\"\n",
    "        Returns list of parameters like `lr` and `wd`\n",
    "        for each param group\n",
    "        \"\"\"\n",
    "        lrs = []\n",
    "        wds = []\n",
    "\n",
    "        for p in self.build_param_dicts():\n",
    "            lrs.append(p[\"lr\"])\n",
    "            wds.append(p[\"weight_decay\"])\n",
    "        return self._hypers(lrs, wds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model architecture will work for most common computer vision fietuning use case. We take a `backbone` and `classifier`. We run the input through the backbone to extract the feature_maps which are then used by the classifier to given predictions on the Input. The paramters dicts for optimization are generated by the `backbone` and the `head` itself.\n",
    "\n",
    "> Note: For advanced use cases you might want to create a model. A model muse inherit from `GaleModule` and be registered in `META_ARCH_REGISTRY`. Your model should also have the following methods to work in the Gale ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"GeneralizedImageClassifier.from_config_dict\" class=\"doc_header\"><code>GeneralizedImageClassifier.from_config_dict</code><a href=\"__main__.py#L39\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>GeneralizedImageClassifier.from_config_dict</code>(**`cfg`**:`DictConfig`)\n",
       "\n",
       "Instantiate the Meta Architecture from gale config"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"show_doc(GeneralizedImageClassifier.from_config_dict)\";\n",
       "                var nbb_formatted_code = \"show_doc(GeneralizedImageClassifier.from_config_dict)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(GeneralizedImageClassifier.from_config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"GeneralizedImageClassifier.forward\" class=\"doc_header\"><code>GeneralizedImageClassifier.forward</code><a href=\"__main__.py#L28\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>GeneralizedImageClassifier.forward</code>(**`batched_inputs`**:`Tensor`)\n",
       "\n",
       "Runs the batched_inputs through `backbone` followed by the `head`.\n",
       "Returns a Tensor which contains the logits for the batched_inputs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"show_doc(GeneralizedImageClassifier.forward)\";\n",
       "                var nbb_formatted_code = \"show_doc(GeneralizedImageClassifier.forward)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(GeneralizedImageClassifier.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"GeneralizedImageClassifier.build_param_dicts\" class=\"doc_header\"><code>GeneralizedImageClassifier.build_param_dicts</code><a href=\"__main__.py#L83\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>GeneralizedImageClassifier.build_param_dicts</code>()\n",
       "\n",
       "Builds up the Paramters dicts for optimization"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"show_doc(GeneralizedImageClassifier.build_param_dicts)\";\n",
       "                var nbb_formatted_code = \"show_doc(GeneralizedImageClassifier.build_param_dicts)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(GeneralizedImageClassifier.build_param_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Meta_Arch`'s can also be instatiated via a appropriate config file. Let's see how .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"from dataclasses import dataclass, field\\nfrom omegaconf import MISSING, OmegaConf\\nfrom gale.classification.model.backbones import ResNetBackbone, ResNetBackboneDataClass\\nfrom gale.classification.model.heads import FastaiHead, FastaiHeadDataClass\";\n",
       "                var nbb_formatted_code = \"from dataclasses import dataclass, field\\nfrom omegaconf import MISSING, OmegaConf\\nfrom gale.classification.model.backbones import ResNetBackbone, ResNetBackboneDataClass\\nfrom gale.classification.model.heads import FastaiHead, FastaiHeadDataClass\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from omegaconf import MISSING, OmegaConf\n",
    "from gale.classification.model.backbones import ResNetBackbone, ResNetBackboneDataClass\n",
    "from gale.classification.model.heads import FastaiHead, FastaiHeadDataClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a meta_arch we first need to create the configurations for the `Backbone` and the `Head` of the model. These \n",
    "must be registerd in `IMAGE_CLASSIFICATION_BACKBONES` and `IMAGE_CLASSIFICATION_HEADS` Registy respectively. The instances are automatically instiated by the `GeneralizedImageClassifier` meta_arch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"backbone = OmegaConf.create()\\nbackbone[\\\"name\\\"] = \\\"ResNetBackbone\\\"\\n\\ninit_args = ResNetBackboneDataClass(model_name=\\\"resnet18\\\", freeze_at=2)\\ninit_args = OmegaConf.structured(init_args)\\nbackbone[\\\"init_args\\\"] = init_args\";\n",
       "                var nbb_formatted_code = \"backbone = OmegaConf.create()\\nbackbone[\\\"name\\\"] = \\\"ResNetBackbone\\\"\\n\\ninit_args = ResNetBackboneDataClass(model_name=\\\"resnet18\\\", freeze_at=2)\\ninit_args = OmegaConf.structured(init_args)\\nbackbone[\\\"init_args\\\"] = init_args\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "backbone = OmegaConf.create()\n",
    "backbone[\"name\"] = \"ResNetBackbone\"\n",
    "\n",
    "init_args = ResNetBackboneDataClass(model_name=\"resnet18\", freeze_at=2)\n",
    "init_args = OmegaConf.structured(init_args)\n",
    "backbone[\"init_args\"] = init_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"head = OmegaConf.create()\\nhead.name = \\\"FastaiHead\\\"\\nhead.init_args = OmegaConf.structured(FastaiHeadDataClass(num_classes=2))\";\n",
       "                var nbb_formatted_code = \"head = OmegaConf.create()\\nhead.name = \\\"FastaiHead\\\"\\nhead.init_args = OmegaConf.structured(FastaiHeadDataClass(num_classes=2))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head = OmegaConf.create()\n",
    "head.name = \"FastaiHead\"\n",
    "head.init_args = OmegaConf.structured(FastaiHeadDataClass(num_classes=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a few more things and the config must be composed in a gale config style. We need the definitions of the input like channels, height and width. So let's compose these -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# Input config\\nINPUTS = OmegaConf.create()\\nINPUTS.channels = 3\\nINPUTS.height = 224\\nINPUTS.width = 224\\n\\n# Configuration for Model\\nMODEL = OmegaConf.create()\\nMODEL.meta_architecture = OmegaConf.create()\\nMODEL.meta_architecture.name = \\\"GeneralizedImageClassifier\\\"\\nMODEL.meta_architecture.init_args = None\\nMODEL.backbone = backbone\\nMODEL.head = head\";\n",
       "                var nbb_formatted_code = \"# Input config\\nINPUTS = OmegaConf.create()\\nINPUTS.channels = 3\\nINPUTS.height = 224\\nINPUTS.width = 224\\n\\n# Configuration for Model\\nMODEL = OmegaConf.create()\\nMODEL.meta_architecture = OmegaConf.create()\\nMODEL.meta_architecture.name = \\\"GeneralizedImageClassifier\\\"\\nMODEL.meta_architecture.init_args = None\\nMODEL.backbone = backbone\\nMODEL.head = head\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Input config\n",
    "INPUTS = OmegaConf.create()\n",
    "INPUTS.channels = 3\n",
    "INPUTS.height = 224\n",
    "INPUTS.width = 224\n",
    "\n",
    "# Configuration for Model\n",
    "MODEL = OmegaConf.create()\n",
    "MODEL.meta_architecture = OmegaConf.create()\n",
    "MODEL.meta_architecture.name = \"GeneralizedImageClassifier\"\n",
    "MODEL.meta_architecture.init_args = None\n",
    "MODEL.backbone = backbone\n",
    "MODEL.head = head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, these are the bare minimums that one would need to instantiate `GeneralizedImageClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "  channels: 3\n",
      "  height: 224\n",
      "  width: 224\n",
      "model:\n",
      "  meta_architecture:\n",
      "    name: GeneralizedImageClassifier\n",
      "    init_args: null\n",
      "  backbone:\n",
      "    name: ResNetBackbone\n",
      "    init_args:\n",
      "      model_name: resnet18\n",
      "      act: null\n",
      "      lr: 0.001\n",
      "      lr_div: 10\n",
      "      wd: 0.0\n",
      "      freeze_at: 2\n",
      "      pretrained: true\n",
      "      drop_block_rate: null\n",
      "      drop_path_rate: null\n",
      "      bn_tf: false\n",
      "  head:\n",
      "    name: FastaiHead\n",
      "    init_args:\n",
      "      num_classes: 2\n",
      "      act: ReLU\n",
      "      lin_ftrs: null\n",
      "      ps: 0.5\n",
      "      concat_pool: true\n",
      "      first_bn: true\n",
      "      bn_final: false\n",
      "      lr: 0.002\n",
      "      wd: 0.0\n",
      "      filter_wd: false\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"# collapse-output\\nconf = OmegaConf.create(dict(input=INPUTS, model=MODEL))\\nprint(OmegaConf.to_yaml(conf))\";\n",
       "                var nbb_formatted_code = \"# collapse-output\\nconf = OmegaConf.create(dict(input=INPUTS, model=MODEL))\\nprint(OmegaConf.to_yaml(conf))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# collapse-output\n",
    "conf = OmegaConf.create(dict(input=INPUTS, model=MODEL))\n",
    "print(OmegaConf.to_yaml(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inputs: ShapeSpec(channels=3, height=224, width=224)\n",
      "Loading pretrained weights from url (https://download.pytorch.org/models/resnet18-5c106cde.pth)\n",
      "Backbone ResNetBackbone created, param count: 11.2 M.\n",
      "Head FastaiHead created, param count: 528 K.\n",
      "Model created, param count: 11.7 M.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"m = GeneralizedImageClassifier.from_config_dict(conf)\";\n",
       "                var nbb_formatted_code = \"m = GeneralizedImageClassifier.from_config_dict(conf)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = GeneralizedImageClassifier.from_config_dict(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2598, -0.0377],\n",
       "        [ 1.5199,  1.1705]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"# hide\\nshape = (m.input_shape.channels, m.input_shape.height, m.input_shape.width)\\ninp = torch.randn(2, *shape)\\no = m(inp)\\no\";\n",
       "                var nbb_formatted_code = \"# hide\\nshape = (m.input_shape.channels, m.input_shape.height, m.input_shape.width)\\ninp = torch.randn(2, *shape)\\no = m(inp)\\no\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "shape = (m.input_shape.channels, m.input_shape.height, m.input_shape.width)\n",
    "inp = torch.randn(2, *shape)\n",
    "o = m(inp)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/ayushman/Desktop/gale/nbs/data/hymenoptera_data.zip\n",
      "Extracting /Users/ayushman/Desktop/gale/nbs/data/hymenoptera_data.zip to /Users/ayushman/Desktop/gale/nbs/data\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"# hide\\n# cuda\\nimport pytorch_lightning as pl\\nimport torchmetrics\\nimport torchvision.transforms as T\\nfrom fastcore.all import Path\\nfrom nbdev.export import Config\\nfrom torch import optim\\nfrom torch.utils.data import DataLoader\\nfrom torchvision.datasets import ImageFolder\\n\\nfrom gale.collections.callbacks.notebook import NotebookProgressCallback\\nfrom gale.collections.download import download_and_extract_archive\\nfrom gale.schedules import WarmupStepLR\\nfrom gale.utils.display import show_images\\n\\nURL = \\\"https://download.pytorch.org/tutorial/hymenoptera_data.zip\\\"\\ndata_path = Path(Config().path(\\\"nbs_path\\\")) / \\\"data\\\"\\n\\n# download a toy dataset\\ndownload_and_extract_archive(url=URL, download_root=data_path)\";\n",
       "                var nbb_formatted_code = \"# hide\\n# cuda\\nimport pytorch_lightning as pl\\nimport torchmetrics\\nimport torchvision.transforms as T\\nfrom fastcore.all import Path\\nfrom nbdev.export import Config\\nfrom torch import optim\\nfrom torch.utils.data import DataLoader\\nfrom torchvision.datasets import ImageFolder\\n\\nfrom gale.collections.callbacks.notebook import NotebookProgressCallback\\nfrom gale.collections.download import download_and_extract_archive\\nfrom gale.schedules import WarmupStepLR\\nfrom gale.utils.display import show_images\\n\\nURL = \\\"https://download.pytorch.org/tutorial/hymenoptera_data.zip\\\"\\ndata_path = Path(Config().path(\\\"nbs_path\\\")) / \\\"data\\\"\\n\\n# download a toy dataset\\ndownload_and_extract_archive(url=URL, download_root=data_path)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "# cuda\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import torchvision.transforms as T\n",
    "from fastcore.all import Path\n",
    "from nbdev.export import Config\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from gale.collections.callbacks.notebook import NotebookProgressCallback\n",
    "from gale.collections.download import download_and_extract_archive\n",
    "from gale.schedules import WarmupStepLR\n",
    "from gale.utils.display import show_images\n",
    "\n",
    "URL = \"https://download.pytorch.org/tutorial/hymenoptera_data.zip\"\n",
    "data_path = Path(Config().path(\"nbs_path\")) / \"data\"\n",
    "\n",
    "# download a toy dataset\n",
    "download_and_extract_archive(url=URL, download_root=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"# hide\\n# cuda\\ndata_transforms = {\\n    \\\"train\\\": T.Compose(\\n        [\\n            T.RandomResizedCrop(224),\\n            T.RandomHorizontalFlip(),\\n            T.ToTensor(),\\n            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\\n        ]\\n    ),\\n    \\\"val\\\": T.Compose(\\n        [\\n            T.Resize(256),\\n            T.CenterCrop(224),\\n            T.ToTensor(),\\n            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\\n        ]\\n    ),\\n}\\n\\ntraining_data = ImageFolder(\\n    data_path / \\\"hymenoptera_data/train\\\", transform=data_transforms[\\\"train\\\"]\\n)\\nvalidation_data = ImageFolder(\\n    data_path / \\\"hymenoptera_data/val\\\", transform=data_transforms[\\\"val\\\"]\\n)\\n\\ntrain_dl = DataLoader(training_data, batch_size=32, shuffle=True)\\nvalid_dl = DataLoader(validation_data, batch_size=32, shuffle=False)\";\n",
       "                var nbb_formatted_code = \"# hide\\n# cuda\\ndata_transforms = {\\n    \\\"train\\\": T.Compose(\\n        [\\n            T.RandomResizedCrop(224),\\n            T.RandomHorizontalFlip(),\\n            T.ToTensor(),\\n            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\\n        ]\\n    ),\\n    \\\"val\\\": T.Compose(\\n        [\\n            T.Resize(256),\\n            T.CenterCrop(224),\\n            T.ToTensor(),\\n            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\\n        ]\\n    ),\\n}\\n\\ntraining_data = ImageFolder(\\n    data_path / \\\"hymenoptera_data/train\\\", transform=data_transforms[\\\"train\\\"]\\n)\\nvalidation_data = ImageFolder(\\n    data_path / \\\"hymenoptera_data/val\\\", transform=data_transforms[\\\"val\\\"]\\n)\\n\\ntrain_dl = DataLoader(training_data, batch_size=32, shuffle=True)\\nvalid_dl = DataLoader(validation_data, batch_size=32, shuffle=False)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "# cuda\n",
    "data_transforms = {\n",
    "    \"train\": T.Compose(\n",
    "        [\n",
    "            T.RandomResizedCrop(224),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "    \"val\": T.Compose(\n",
    "        [\n",
    "            T.Resize(256),\n",
    "            T.CenterCrop(224),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "training_data = ImageFolder(\n",
    "    data_path / \"hymenoptera_data/train\", transform=data_transforms[\"train\"]\n",
    ")\n",
    "validation_data = ImageFolder(\n",
    "    data_path / \"hymenoptera_data/val\", transform=data_transforms[\"val\"]\n",
    ")\n",
    "\n",
    "train_dl = DataLoader(training_data, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(validation_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"# hide\\n# cuda\\nclass Learner(pl.LightningModule):\\n    def __init__(self, model: GeneralizedImageClassifier):\\n        super().__init__()\\n        self.model = model\\n        self.train_metric = torchmetrics.Accuracy()\\n        self.valid_metric = torchmetrics.Accuracy()\\n        self.loss_fn = torch.nn.CrossEntropyLoss()\\n\\n    def forward(self, xb):\\n        return self.model(xb)\\n\\n    def training_step(self, batch: Any, batch_idx: int):\\n        x, y = batch\\n        y_hat = self(x)\\n        loss = self.loss_fn(y_hat, y)\\n        acc = self.train_metric(torch.nn.functional.softmax(y_hat), y)\\n        self.log_dict(dict(loss=loss, acc=acc))\\n        return loss\\n\\n    def validation_step(self, batch: Any, batch_idx: int):\\n        x, y = batch\\n        y_hat = self(x)\\n        loss = self.loss_fn(y_hat, y)\\n        acc = self.valid_metric(torch.nn.functional.softmax(y_hat), y)\\n        self.log_dict(dict(val_loss=loss, val_acc=acc))\\n\\n    def configure_optimizers(self):\\n        paramters = self.model.build_param_dicts()\\n        opt = optim.AdamW(paramters)\\n        sch = WarmupStepLR(\\n            opt,\\n            num_decays=2,\\n            warmup_epochs=1,\\n            decay_rate=0.1,\\n            epochs=self.trainer.max_epochs,\\n        )\\n        return [opt], [sch]\";\n",
       "                var nbb_formatted_code = \"# hide\\n# cuda\\nclass Learner(pl.LightningModule):\\n    def __init__(self, model: GeneralizedImageClassifier):\\n        super().__init__()\\n        self.model = model\\n        self.train_metric = torchmetrics.Accuracy()\\n        self.valid_metric = torchmetrics.Accuracy()\\n        self.loss_fn = torch.nn.CrossEntropyLoss()\\n\\n    def forward(self, xb):\\n        return self.model(xb)\\n\\n    def training_step(self, batch: Any, batch_idx: int):\\n        x, y = batch\\n        y_hat = self(x)\\n        loss = self.loss_fn(y_hat, y)\\n        acc = self.train_metric(torch.nn.functional.softmax(y_hat), y)\\n        self.log_dict(dict(loss=loss, acc=acc))\\n        return loss\\n\\n    def validation_step(self, batch: Any, batch_idx: int):\\n        x, y = batch\\n        y_hat = self(x)\\n        loss = self.loss_fn(y_hat, y)\\n        acc = self.valid_metric(torch.nn.functional.softmax(y_hat), y)\\n        self.log_dict(dict(val_loss=loss, val_acc=acc))\\n\\n    def configure_optimizers(self):\\n        paramters = self.model.build_param_dicts()\\n        opt = optim.AdamW(paramters)\\n        sch = WarmupStepLR(\\n            opt,\\n            num_decays=2,\\n            warmup_epochs=1,\\n            decay_rate=0.1,\\n            epochs=self.trainer.max_epochs,\\n        )\\n        return [opt], [sch]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "# cuda\n",
    "class Learner(pl.LightningModule):\n",
    "    def __init__(self, model: GeneralizedImageClassifier):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.train_metric = torchmetrics.Accuracy()\n",
    "        self.valid_metric = torchmetrics.Accuracy()\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.model(xb)\n",
    "\n",
    "    def training_step(self, batch: Any, batch_idx: int):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        acc = self.train_metric(torch.nn.functional.softmax(y_hat), y)\n",
    "        self.log_dict(dict(loss=loss, acc=acc))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: Any, batch_idx: int):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        acc = self.valid_metric(torch.nn.functional.softmax(y_hat), y)\n",
    "        self.log_dict(dict(val_loss=loss, val_acc=acc))\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        paramters = self.model.build_param_dicts()\n",
    "        opt = optim.AdamW(paramters)\n",
    "        sch = WarmupStepLR(\n",
    "            opt,\n",
    "            num_decays=2,\n",
    "            warmup_epochs=1,\n",
    "            decay_rate=0.1,\n",
    "            epochs=self.trainer.max_epochs,\n",
    "        )\n",
    "        return [opt], [sch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Inputs: ShapeSpec(channels=3, height=224, width=224)\n",
      "Loading pretrained weights from url (https://download.pytorch.org/models/resnet18-5c106cde.pth)\n",
      "Backbone ResNetBackbone created, param count: 11.2 M.\n",
      "Head FastaiHead created, param count: 528 K.\n",
      "Model created, param count: 11.7 M.\n",
      "\n",
      "  | Name         | Type                       | Params\n",
      "------------------------------------------------------------\n",
      "0 | model        | GeneralizedImageClassifier | 11.7 M\n",
      "1 | train_metric | Accuracy                   | 0     \n",
      "2 | valid_metric | Accuracy                   | 0     \n",
      "3 | loss_fn      | CrossEntropyLoss           | 0     \n",
      "------------------------------------------------------------\n",
      "11.5 M    Trainable params\n",
      "157 K     Non-trainable params\n",
      "11.7 M    Total params\n",
      "46.820    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            progress {\n",
       "                border: none;\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      Training\n",
       "      <progress value='8' max='56' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8/56 00:43 < 04:55, 0.16 it/s, Epoch 0 {'loss': '0.822', 'v_num': 4}]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>time</th>\n",
       "      <th>samples/s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.731146</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.743832</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>45.057200</td>\n",
       "      <td>0.288500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"# hide\\n# cuda\\ncbs = [\\n    NotebookProgressCallback(),\\n    pl.callbacks.LearningRateMonitor(logging_interval=\\\"epoch\\\", log_momentum=True),\\n]\\n\\nlogger = pl.loggers.TensorBoardLogger(save_dir=\\\"lightning_logs/\\\", name=\\\"my_model\\\")\\n\\ntrainer = pl.Trainer(max_epochs=7, callbacks=cbs, log_every_n_steps=1, logger=logger)\\n\\nmodel = GeneralizedImageClassifier.from_config_dict(conf)\\nlearn = Learner(model)\\n\\ntrainer.fit(learn, train_dataloader=train_dl, val_dataloaders=valid_dl)\";\n",
       "                var nbb_formatted_code = \"# hide\\n# cuda\\ncbs = [\\n    NotebookProgressCallback(),\\n    pl.callbacks.LearningRateMonitor(logging_interval=\\\"epoch\\\", log_momentum=True),\\n]\\n\\nlogger = pl.loggers.TensorBoardLogger(save_dir=\\\"lightning_logs/\\\", name=\\\"my_model\\\")\\n\\ntrainer = pl.Trainer(max_epochs=7, callbacks=cbs, log_every_n_steps=1, logger=logger)\\n\\nmodel = GeneralizedImageClassifier.from_config_dict(conf)\\nlearn = Learner(model)\\n\\ntrainer.fit(learn, train_dataloader=train_dl, val_dataloaders=valid_dl)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "# cuda\n",
    "cbs = [\n",
    "    NotebookProgressCallback(),\n",
    "    pl.callbacks.LearningRateMonitor(logging_interval=\"epoch\", log_momentum=True),\n",
    "]\n",
    "\n",
    "logger = pl.loggers.TensorBoardLogger(save_dir=\"lightning_logs/\", name=\"my_model\")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=7, callbacks=cbs, log_every_n_steps=1, logger=logger)\n",
    "\n",
    "model = GeneralizedImageClassifier.from_config_dict(conf)\n",
    "learn = Learner(model)\n",
    "\n",
    "trainer.fit(learn, train_dataloader=train_dl, val_dataloaders=valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 04b_classification.model.meta_arch.common.ipynb.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"# hide\\nnotebook2script(\\\"04b_classification.model.meta_arch.common.ipynb\\\")\";\n",
       "                var nbb_formatted_code = \"# hide\\nnotebook2script(\\\"04b_classification.model.meta_arch.common.ipynb\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "notebook2script(\"04b_classification.model.meta_arch.common.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gale_dev",
   "language": "python",
   "name": "gale_dev"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
