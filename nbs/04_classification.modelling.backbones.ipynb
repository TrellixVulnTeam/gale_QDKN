{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp classification.modelling.backbones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# hide\\n%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\";\n",
       "                var nbb_formatted_code = \"# hide\\n%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# hide\\nimport warnings\\n\\nfrom nbdev.export import *\\nfrom nbdev.showdoc import *\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_formatted_code = \"# hide\\nimport warnings\\n\\nfrom nbdev.export import *\\nfrom nbdev.showdoc import *\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "import warnings\n",
    "\n",
    "from nbdev.export import *\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backbones \n",
    "> Backbones/feature extractors for use in Image Classification Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# export\\n# @TODO: Add support for VisionTransformer Backbone\";\n",
       "                var nbb_formatted_code = \"# export\\n# @TODO: Add support for VisionTransformer Backbone\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "# @TODO: Add support for VisionTransformer Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# export\\nimport abc\\nimport logging\\nimport re\\nfrom typing import *\\n\\nimport torch\\nfrom fastcore.all import store_attr, use_kwargs_dict\\nfrom timm import create_model\\nfrom timm.models import ResNet\\nfrom torch import nn\\n\\nfrom gale.core.classes import GaleModule\\nfrom gale.core.nn import ACTIVATION_REGISTRY\\nfrom gale.core.nn.shape_spec import ShapeSpec\\nfrom gale.core.nn.utils import set_bn_eval, trainable_params\\nfrom gale.core.utils.structures import IMAGE_CLASSIFIER_BACKBONES\\n\\n_logger = logging.getLogger(__name__)\";\n",
       "                var nbb_formatted_code = \"# export\\nimport abc\\nimport logging\\nimport re\\nfrom typing import *\\n\\nimport torch\\nfrom fastcore.all import store_attr, use_kwargs_dict\\nfrom timm import create_model\\nfrom timm.models import ResNet\\nfrom torch import nn\\n\\nfrom gale.core.classes import GaleModule\\nfrom gale.core.nn import ACTIVATION_REGISTRY\\nfrom gale.core.nn.shape_spec import ShapeSpec\\nfrom gale.core.nn.utils import set_bn_eval, trainable_params\\nfrom gale.core.utils.structures import IMAGE_CLASSIFIER_BACKBONES\\n\\n_logger = logging.getLogger(__name__)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "import abc\n",
    "import logging\n",
    "import re\n",
    "from typing import *\n",
    "\n",
    "import torch\n",
    "from fastcore.all import store_attr, use_kwargs_dict\n",
    "from timm import create_model\n",
    "from timm.models import ResNet\n",
    "from torch import nn\n",
    "\n",
    "from gale.core.classes import GaleModule\n",
    "from gale.core.nn import ACTIVATION_REGISTRY\n",
    "from gale.core.nn.shape_spec import ShapeSpec\n",
    "from gale.core.nn.utils import set_bn_eval, trainable_params\n",
    "from gale.core.utils.structures import IMAGE_CLASSIFIER_BACKBONES\n",
    "\n",
    "_logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"# export\\n_all_ = [\\\"IMAGE_CLASSIFIER_BACKBONES\\\"]\";\n",
       "                var nbb_formatted_code = \"# export\\n_all_ = [\\\"IMAGE_CLASSIFIER_BACKBONES\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "_all_ = [\"IMAGE_CLASSIFIER_BACKBONES\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"import copy\\nfrom dataclasses import dataclass, field\\n\\nfrom fastcore.test import *\\nfrom omegaconf import MISSING, DictConfig, OmegaConf\";\n",
       "                var nbb_formatted_code = \"import copy\\nfrom dataclasses import dataclass, field\\n\\nfrom fastcore.test import *\\nfrom omegaconf import MISSING, DictConfig, OmegaConf\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import copy\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "from fastcore.test import *\n",
    "from omegaconf import MISSING, DictConfig, OmegaConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# export\\n# funtions taken from: https://github.com/fastai/fastai/blob/master/fastai/vision/learner.py#L76\\ndef _is_pool_type(l: nn.Module):\\n    return re.search(r\\\"Pool[123]d$\\\", l.__class__.__name__)\\n\\n\\ndef has_pool_type(m: nn.Module):\\n    \\\"Return `True` if `m` is a pooling layer or has one in its children\\\"\\n    if _is_pool_type(m):\\n        return True\\n    for l in m.children():\\n        if has_pool_type(l):\\n            return True\\n    return False\";\n",
       "                var nbb_formatted_code = \"# export\\n# funtions taken from: https://github.com/fastai/fastai/blob/master/fastai/vision/learner.py#L76\\ndef _is_pool_type(l: nn.Module):\\n    return re.search(r\\\"Pool[123]d$\\\", l.__class__.__name__)\\n\\n\\ndef has_pool_type(m: nn.Module):\\n    \\\"Return `True` if `m` is a pooling layer or has one in its children\\\"\\n    if _is_pool_type(m):\\n        return True\\n    for l in m.children():\\n        if has_pool_type(l):\\n            return True\\n    return False\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "# funtions taken from: https://github.com/fastai/fastai/blob/master/fastai/vision/learner.py#L76\n",
    "def _is_pool_type(l: nn.Module):\n",
    "    return re.search(r\"Pool[123]d$\", l.__class__.__name__)\n",
    "\n",
    "\n",
    "def has_pool_type(m: nn.Module):\n",
    "    \"Return `True` if `m` is a pooling layer or has one in its children\"\n",
    "    if _is_pool_type(m):\n",
    "        return True\n",
    "    for l in m.children():\n",
    "        if has_pool_type(l):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# export\\ndef prepare_backbone(model: nn.Module, cut=None):\\n    \\\"Cut off the body of a typically pretrained `model` as determined by `cut`\\\"\\n    if cut is None:\\n        ll = list(enumerate(model.children()))\\n        cut = next(i for i, o in reversed(ll) if has_pool_type(o))\\n    if isinstance(cut, int):\\n        return nn.Sequential(*list(model.children())[:cut])\\n    elif callable(cut):\\n        return cut(model)\\n    else:\\n        raise NamedError(\\\"cut must be either integer or a function\\\")\";\n",
       "                var nbb_formatted_code = \"# export\\ndef prepare_backbone(model: nn.Module, cut=None):\\n    \\\"Cut off the body of a typically pretrained `model` as determined by `cut`\\\"\\n    if cut is None:\\n        ll = list(enumerate(model.children()))\\n        cut = next(i for i, o in reversed(ll) if has_pool_type(o))\\n    if isinstance(cut, int):\\n        return nn.Sequential(*list(model.children())[:cut])\\n    elif callable(cut):\\n        return cut(model)\\n    else:\\n        raise NamedError(\\\"cut must be either integer or a function\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "def prepare_backbone(model: nn.Module, cut=None):\n",
    "    \"Cut off the body of a typically pretrained `model` as determined by `cut`\"\n",
    "    if cut is None:\n",
    "        ll = list(enumerate(model.children()))\n",
    "        cut = next(i for i, o in reversed(ll) if has_pool_type(o))\n",
    "    if isinstance(cut, int):\n",
    "        return nn.Sequential(*list(model.children())[:cut])\n",
    "    elif callable(cut):\n",
    "        return cut(model)\n",
    "    else:\n",
    "        raise NamedError(\"cut must be either integer or a function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"# fmt: off\\ntst = nn.Sequential(nn.Conv2d(3, 5, 3), nn.BatchNorm2d(5), nn.AvgPool2d(1), nn.Linear(3, 4))\\n# fmt: on\\n\\nm = prepare_backbone(tst)\\ntest_eq(len(m), 2)\\n\\nm = prepare_backbone(tst, cut=3)\\ntest_eq(len(m), 3)\\n\\nm = prepare_backbone(tst, cut=-1)\\ntest_eq(len(m), 3)\";\n",
       "                var nbb_formatted_code = \"# fmt: off\\ntst = nn.Sequential(nn.Conv2d(3, 5, 3), nn.BatchNorm2d(5), nn.AvgPool2d(1), nn.Linear(3, 4))\\n# fmt: on\\n\\nm = prepare_backbone(tst)\\ntest_eq(len(m), 2)\\n\\nm = prepare_backbone(tst, cut=3)\\ntest_eq(len(m), 3)\\n\\nm = prepare_backbone(tst, cut=-1)\\ntest_eq(len(m), 3)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fmt: off\n",
    "tst = nn.Sequential(nn.Conv2d(3, 5, 3), nn.BatchNorm2d(5), nn.AvgPool2d(1), nn.Linear(3, 4))\n",
    "# fmt: on\n",
    "\n",
    "m = prepare_backbone(tst)\n",
    "test_eq(len(m), 2)\n",
    "\n",
    "m = prepare_backbone(tst, cut=3)\n",
    "test_eq(len(m), 3)\n",
    "\n",
    "m = prepare_backbone(tst, cut=-1)\n",
    "test_eq(len(m), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# export\\ndef filter_weight_decay(\\n    model: nn.Module,\\n    lr: float,\\n    weight_decay: float = 1e-5,\\n    skip_list=(),\\n) -> List[Dict]:\\n    \\\"\\\"\\\"\\n    Filter out bias, bn and other 1d params from weight decay.\\n    Modified from: [timm](https://github.com/rwightman/pytorch-image-models/blob/e8a64fb88108b592da192e98054095b1ee25e96e/timm/optim/optim_factory.py)\\n    \\\"\\\"\\\"\\n    decay = []\\n    no_decay = []\\n    for name, param in model.named_parameters():\\n        if not param.requires_grad:\\n            continue  # frozen weights\\n        if len(param.shape) == 1 or name.endswith(\\\".bias\\\") or name in skip_list:\\n            no_decay.append(param)\\n        else:\\n            decay.append(param)\\n    return [\\n        {\\\"params\\\": no_decay, \\\"weight_decay\\\": 0.0, \\\"lr\\\": lr},\\n        {\\\"params\\\": decay, \\\"weight_decay\\\": weight_decay, \\\"lr\\\": lr},\\n    ]\";\n",
       "                var nbb_formatted_code = \"# export\\ndef filter_weight_decay(\\n    model: nn.Module,\\n    lr: float,\\n    weight_decay: float = 1e-5,\\n    skip_list=(),\\n) -> List[Dict]:\\n    \\\"\\\"\\\"\\n    Filter out bias, bn and other 1d params from weight decay.\\n    Modified from: [timm](https://github.com/rwightman/pytorch-image-models/blob/e8a64fb88108b592da192e98054095b1ee25e96e/timm/optim/optim_factory.py)\\n    \\\"\\\"\\\"\\n    decay = []\\n    no_decay = []\\n    for name, param in model.named_parameters():\\n        if not param.requires_grad:\\n            continue  # frozen weights\\n        if len(param.shape) == 1 or name.endswith(\\\".bias\\\") or name in skip_list:\\n            no_decay.append(param)\\n        else:\\n            decay.append(param)\\n    return [\\n        {\\\"params\\\": no_decay, \\\"weight_decay\\\": 0.0, \\\"lr\\\": lr},\\n        {\\\"params\\\": decay, \\\"weight_decay\\\": weight_decay, \\\"lr\\\": lr},\\n    ]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "def filter_weight_decay(\n",
    "    model: nn.Module,\n",
    "    lr: float,\n",
    "    weight_decay: float = 1e-5,\n",
    "    skip_list=(),\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Filter out bias, bn and other 1d params from weight decay.\n",
    "    Modified from: [timm](https://github.com/rwightman/pytorch-image-models/blob/e8a64fb88108b592da192e98054095b1ee25e96e/timm/optim/optim_factory.py)\n",
    "    \"\"\"\n",
    "    decay = []\n",
    "    no_decay = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if not param.requires_grad:\n",
    "            continue  # frozen weights\n",
    "        if len(param.shape) == 1 or name.endswith(\".bias\") or name in skip_list:\n",
    "            no_decay.append(param)\n",
    "        else:\n",
    "            decay.append(param)\n",
    "    return [\n",
    "        {\"params\": no_decay, \"weight_decay\": 0.0, \"lr\": lr},\n",
    "        {\"params\": decay, \"weight_decay\": weight_decay, \"lr\": lr},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"# export\\nclass ImageClassificationBackbone(GaleModule, metaclass=abc.ABCMeta):\\n    \\\"\\\"\\\"\\n    Abstract class for ImageClassification BackBones\\n    \\\"\\\"\\\"\\n\\n    def __init__(self):\\n        \\\"\\\"\\\"\\n        The `__init__` method of any subclass can specify its own set of arguments.\\n        \\\"\\\"\\\"\\n        super().__init__()\\n\\n    def get_lrs(self) -> List:\\n        \\\"\\\"\\\"\\n        Returns a List containining the Lrs' for\\n        each parameter group. This is required to build schedulers\\n        like `torch.optim.lr_scheduler.OneCycleScheduler` which needs\\n        the max lrs' for all the Param Groups.\\n        \\\"\\\"\\\"\\n        lrs = []\\n\\n        for p in self.build_param_dicts():\\n            lrs.append(p[\\\"lr\\\"])\\n        return lrs\\n\\n    @abc.abstractmethod\\n    def output_shape(self) -> ShapeSpec:\\n        \\\"\\\"\\\"\\n        Returns the output shape. For most backbones\\n        this means it will contain the channels in the\\n        output layer.\\n        \\\"\\\"\\\"\\n        pass\";\n",
       "                var nbb_formatted_code = \"# export\\nclass ImageClassificationBackbone(GaleModule, metaclass=abc.ABCMeta):\\n    \\\"\\\"\\\"\\n    Abstract class for ImageClassification BackBones\\n    \\\"\\\"\\\"\\n\\n    def __init__(self):\\n        \\\"\\\"\\\"\\n        The `__init__` method of any subclass can specify its own set of arguments.\\n        \\\"\\\"\\\"\\n        super().__init__()\\n\\n    def get_lrs(self) -> List:\\n        \\\"\\\"\\\"\\n        Returns a List containining the Lrs' for\\n        each parameter group. This is required to build schedulers\\n        like `torch.optim.lr_scheduler.OneCycleScheduler` which needs\\n        the max lrs' for all the Param Groups.\\n        \\\"\\\"\\\"\\n        lrs = []\\n\\n        for p in self.build_param_dicts():\\n            lrs.append(p[\\\"lr\\\"])\\n        return lrs\\n\\n    @abc.abstractmethod\\n    def output_shape(self) -> ShapeSpec:\\n        \\\"\\\"\\\"\\n        Returns the output shape. For most backbones\\n        this means it will contain the channels in the\\n        output layer.\\n        \\\"\\\"\\\"\\n        pass\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class ImageClassificationBackbone(GaleModule, metaclass=abc.ABCMeta):\n",
    "    \"\"\"\n",
    "    Abstract class for ImageClassification BackBones\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        The `__init__` method of any subclass can specify its own set of arguments.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "    def get_lrs(self) -> List:\n",
    "        \"\"\"\n",
    "        Returns a List containining the Lrs' for\n",
    "        each parameter group. This is required to build schedulers\n",
    "        like `torch.optim.lr_scheduler.OneCycleScheduler` which needs\n",
    "        the max lrs' for all the Param Groups.\n",
    "        \"\"\"\n",
    "        lrs = []\n",
    "\n",
    "        for p in self.build_param_dicts():\n",
    "            lrs.append(p[\"lr\"])\n",
    "        return lrs\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def output_shape(self) -> ShapeSpec:\n",
    "        \"\"\"\n",
    "        Returns the output shape. For most backbones\n",
    "        this means it will contain the channels in the\n",
    "        output layer.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"ImageClassificationBackbone\" class=\"doc_header\"><code>class</code> <code>ImageClassificationBackbone</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>ImageClassificationBackbone</code>() :: [`GaleModule`](/gale/core.classes.html#GaleModule)\n",
       "\n",
       "Abstract class for ImageClassification BackBones"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ImageClassificationBackbone.__init__\" class=\"doc_header\"><code>ImageClassificationBackbone.__init__</code><a href=\"__main__.py#L7\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ImageClassificationBackbone.__init__</code>()\n",
       "\n",
       "The `__init__` method of any subclass can specify its own set of arguments."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"show_doc(ImageClassificationBackbone)\\nshow_doc(ImageClassificationBackbone.__init__)\";\n",
       "                var nbb_formatted_code = \"show_doc(ImageClassificationBackbone)\\nshow_doc(ImageClassificationBackbone.__init__)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ImageClassificationBackbone)\n",
    "show_doc(ImageClassificationBackbone.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ImageClassificationBackbone.get_lrs\" class=\"doc_header\"><code>ImageClassificationBackbone.get_lrs</code><a href=\"__main__.py#L13\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ImageClassificationBackbone.get_lrs</code>()\n",
       "\n",
       "Returns a List containining the Lrs' for\n",
       "each parameter group. This is required to build schedulers\n",
       "like `torch.optim.lr_scheduler.OneCycleScheduler` which needs\n",
       "the max lrs' for all the Param Groups."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ImageClassificationBackbone.output_shape\" class=\"doc_header\"><code>ImageClassificationBackbone.output_shape</code><a href=\"__main__.py#L26\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ImageClassificationBackbone.output_shape</code>()\n",
       "\n",
       "Returns the output shape. For most backbones\n",
       "this means it will contain the channels in the\n",
       "output layer."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"show_doc(ImageClassificationBackbone.get_lrs)\\nshow_doc(ImageClassificationBackbone.output_shape)\";\n",
       "                var nbb_formatted_code = \"show_doc(ImageClassificationBackbone.get_lrs)\\nshow_doc(ImageClassificationBackbone.output_shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ImageClassificationBackbone.get_lrs)\n",
    "show_doc(ImageClassificationBackbone.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"# export\\n# @IMAGE_CLASSIFIER_BACKBONES.register()\\nclass TimmBackboneBase(ImageClassificationBackbone):\\n    \\\"Create a model from `timm` and converts it into a Image Classification Backbone\\\"\\n\\n    @use_kwargs_dict(\\n        keep=True,\\n        pretrained=True,\\n        drop_block_rate=None,\\n        drop_path_rate=None,\\n        bn_tf=False,\\n    )\\n    def __init__(\\n        self,\\n        model_name: str,\\n        input_shape: ShapeSpec,\\n        act: str = None,\\n        lr: float = 1e-03,\\n        wd: float = 0,\\n        freeze_bn: bool = False,\\n        freeze_at: int = False,\\n        filter_wd: bool = False,\\n        **kwargs,\\n    ):\\n        super(TimmBackboneBase, self).__init__()\\n\\n        store_attr(\\\"lr, wd, filter_wd, input_shape\\\")\\n\\n        if act is not None:\\n            act = ACTIVATION_REGISTRY.get(act)\\n\\n        # fmt: off\\n        model = create_model(model_name, act_layer=act, global_pool=\\\"\\\", num_classes=0, \\n                             in_chans=input_shape.channels, **kwargs)\\n        # fmt: on\\n\\n        # save some of the input information from timm models\\n        self.num_features = model.num_features\\n        self.timm_model_cfg = model.default_cfg\\n        self.model = prepare_backbone(model)\\n\\n        if not freeze_at:\\n            self.unfreeze()\\n        else:\\n            self.freeze_to(freeze_at)\\n\\n        if freeze_bn:\\n            set_bn_eval(self.model)\\n\\n    def forward(self, xb: torch.Tensor) -> torch.Tensor:\\n        return self.model(xb)\\n\\n    def build_param_dicts(self):\\n        if self.filter_wd:\\n            ps = filter_weight_decay(self.model, lr=self.lr, weight_decay=self.wd)\\n        else:\\n            # fmt: off\\n            ps = [{\\\"params\\\": trainable_params(self.model),\\\"lr\\\": self.lr,\\\"weight_decay\\\": self.wd}]\\n            # fmt: on\\n        return ps\\n\\n    def output_shape(self) -> ShapeSpec:\\n        return ShapeSpec(self.num_features, None, None)\";\n",
       "                var nbb_formatted_code = \"# export\\n# @IMAGE_CLASSIFIER_BACKBONES.register()\\nclass TimmBackboneBase(ImageClassificationBackbone):\\n    \\\"Create a model from `timm` and converts it into a Image Classification Backbone\\\"\\n\\n    @use_kwargs_dict(\\n        keep=True,\\n        pretrained=True,\\n        drop_block_rate=None,\\n        drop_path_rate=None,\\n        bn_tf=False,\\n    )\\n    def __init__(\\n        self,\\n        model_name: str,\\n        input_shape: ShapeSpec,\\n        act: str = None,\\n        lr: float = 1e-03,\\n        wd: float = 0,\\n        freeze_bn: bool = False,\\n        freeze_at: int = False,\\n        filter_wd: bool = False,\\n        **kwargs,\\n    ):\\n        super(TimmBackboneBase, self).__init__()\\n\\n        store_attr(\\\"lr, wd, filter_wd, input_shape\\\")\\n\\n        if act is not None:\\n            act = ACTIVATION_REGISTRY.get(act)\\n\\n        # fmt: off\\n        model = create_model(model_name, act_layer=act, global_pool=\\\"\\\", num_classes=0, \\n                             in_chans=input_shape.channels, **kwargs)\\n        # fmt: on\\n\\n        # save some of the input information from timm models\\n        self.num_features = model.num_features\\n        self.timm_model_cfg = model.default_cfg\\n        self.model = prepare_backbone(model)\\n\\n        if not freeze_at:\\n            self.unfreeze()\\n        else:\\n            self.freeze_to(freeze_at)\\n\\n        if freeze_bn:\\n            set_bn_eval(self.model)\\n\\n    def forward(self, xb: torch.Tensor) -> torch.Tensor:\\n        return self.model(xb)\\n\\n    def build_param_dicts(self):\\n        if self.filter_wd:\\n            ps = filter_weight_decay(self.model, lr=self.lr, weight_decay=self.wd)\\n        else:\\n            # fmt: off\\n            ps = [{\\\"params\\\": trainable_params(self.model),\\\"lr\\\": self.lr,\\\"weight_decay\\\": self.wd}]\\n            # fmt: on\\n        return ps\\n\\n    def output_shape(self) -> ShapeSpec:\\n        return ShapeSpec(self.num_features, None, None)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "# @IMAGE_CLASSIFIER_BACKBONES.register()\n",
    "class TimmBackboneBase(ImageClassificationBackbone):\n",
    "    \"Create a model from `timm` and converts it into a Image Classification Backbone\"\n",
    "\n",
    "    @use_kwargs_dict(\n",
    "        keep=True,\n",
    "        pretrained=True,\n",
    "        drop_block_rate=None,\n",
    "        drop_path_rate=None,\n",
    "        bn_tf=False,\n",
    "    )\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        input_shape: ShapeSpec,\n",
    "        act: str = None,\n",
    "        lr: float = 1e-03,\n",
    "        wd: float = 0,\n",
    "        freeze_bn: bool = False,\n",
    "        freeze_at: int = False,\n",
    "        filter_wd: bool = False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(TimmBackboneBase, self).__init__()\n",
    "\n",
    "        store_attr(\"lr, wd, filter_wd, input_shape\")\n",
    "\n",
    "        if act is not None:\n",
    "            act = ACTIVATION_REGISTRY.get(act)\n",
    "\n",
    "        # fmt: off\n",
    "        model = create_model(model_name, act_layer=act, global_pool=\"\", num_classes=0, \n",
    "                             in_chans=input_shape.channels, **kwargs)\n",
    "        # fmt: on\n",
    "\n",
    "        # save some of the input information from timm models\n",
    "        self.num_features = model.num_features\n",
    "        self.timm_model_cfg = model.default_cfg\n",
    "        self.model = prepare_backbone(model)\n",
    "\n",
    "        if not freeze_at:\n",
    "            self.unfreeze()\n",
    "        else:\n",
    "            self.freeze_to(freeze_at)\n",
    "\n",
    "        if freeze_bn:\n",
    "            set_bn_eval(self.model)\n",
    "\n",
    "    def forward(self, xb: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(xb)\n",
    "\n",
    "    def build_param_dicts(self):\n",
    "        if self.filter_wd:\n",
    "            ps = filter_weight_decay(self.model, lr=self.lr, weight_decay=self.wd)\n",
    "        else:\n",
    "            # fmt: off\n",
    "            ps = [{\"params\": trainable_params(self.model),\"lr\": self.lr,\"weight_decay\": self.wd}]\n",
    "            # fmt: on\n",
    "        return ps\n",
    "\n",
    "    def output_shape(self) -> ShapeSpec:\n",
    "        return ShapeSpec(self.num_features, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"TimmBackboneBase\" class=\"doc_header\"><code>class</code> <code>TimmBackboneBase</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>TimmBackboneBase</code>(**`model_name`**:`str`, **`input_shape`**:`ShapeSpec`, **`act`**:`str`=*`None`*, **`lr`**:`float`=*`0.001`*, **`wd`**:`float`=*`0`*, **`freeze_bn`**:`bool`=*`False`*, **`freeze_at`**:`int`=*`False`*, **`filter_wd`**:`bool`=*`False`*, **`pretrained`**=*`True`*, **`drop_block_rate`**=*`None`*, **`drop_path_rate`**=*`None`*, **`bn_tf`**=*`False`*, **\\*\\*`kwargs`**) :: [`ImageClassificationBackbone`](/gale/classification.modelling.backbones.html#ImageClassificationBackbone)\n",
       "\n",
       "Create a model from `timm` and converts it into a Image Classification Backbone"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"show_doc(TimmBackboneBase)\";\n",
       "                var nbb_formatted_code = \"show_doc(TimmBackboneBase)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TimmBackboneBase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguments to `TimmBackboneBase`:\n",
    "- `input_shape` (ShapeSpec): Shape of the Inputs\n",
    "- `model_name` (str): name of model to instantiate.\n",
    "- `act` (str): name of the activation function to use. If None uses the default activations else the name must be in `ACTIVATION_REGISTRY`.\n",
    "- `lr` (float): learning rate for the modules.\n",
    "- `wd` (float): weight decay for the modules.\n",
    "- `freeze_bn` (bool): freeze the batch normalization layers of the model.\n",
    "- `freeze_at` (int): freeze the layers of the backbone upto `freeze_at`, false means train all.\n",
    "- `filter_wd` (bool): Filter out bias, bn from weight_decay.\n",
    "- `pretrained` (bool): load pretrained ImageNet-1k weights if true.\n",
    "- `drop_block_rate` (float): Drop block rate\n",
    "- `drop_path_rate` (float): Drop_path_rate\n",
    "- `bn_tf` (bool): Use Tensorflow BatchNorm defaults for models that support it.\n",
    "- `kwargs` (optional): Optional kwargs passed onto `timm.create_model()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"input_shape = ShapeSpec(channels=3, height=255, width=255)\\nbk = TimmBackboneBase(model_name=\\\"resnet18\\\", pretrained=True, input_shape=input_shape)\\nm = create_model(\\\"resnet18\\\")\\n\\ni = torch.randn(2, 3, 224, 224)\\no1 = bk(i)\\ntest_eq(o1.shape, torch.Size([2, 512, 7, 7]))\\ntest_eq(bk.output_shape().channels, m.num_features)\";\n",
       "                var nbb_formatted_code = \"input_shape = ShapeSpec(channels=3, height=255, width=255)\\nbk = TimmBackboneBase(model_name=\\\"resnet18\\\", pretrained=True, input_shape=input_shape)\\nm = create_model(\\\"resnet18\\\")\\n\\ni = torch.randn(2, 3, 224, 224)\\no1 = bk(i)\\ntest_eq(o1.shape, torch.Size([2, 512, 7, 7]))\\ntest_eq(bk.output_shape().channels, m.num_features)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_shape = ShapeSpec(channels=3, height=255, width=255)\n",
    "bk = TimmBackboneBase(model_name=\"resnet18\", pretrained=True, input_shape=input_shape)\n",
    "m = create_model(\"resnet18\")\n",
    "\n",
    "i = torch.randn(2, 3, 224, 224)\n",
    "o1 = bk(i)\n",
    "test_eq(o1.shape, torch.Size([2, 512, 7, 7]))\n",
    "test_eq(bk.output_shape().channels, m.num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiation using config\n",
    "\n",
    "The config for `TimmBackboneBaseConfig` is going to look like this. We need to convert the dataclass to the Omegaconf config file and then we can use `from_config_dict` method to instantiate our class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"@dataclass\\nclass TimmBackboneBaseConfig:\\n    \\\"\\\"\\\"\\n    Base config file for `TimmBackboneBase`\\n    \\\"\\\"\\\"\\n\\n    model_name: str = MISSING\\n    act: Optional[str] = None\\n    lr: Any = 1e-03\\n    wd: Any = 0.0\\n    freeze_bn: bool = False\\n    freeze_at: Any = False\\n    filter_wd: bool = False\\n    pretrained: bool = True\\n    drop_block_rate: Optional[float] = None\\n    drop_path_rate: Optional[float] = None\\n    bn_tf: bool = False\\n\\n\\n# create a config to instantiate the same backbone as above\\nconf = TimmBackboneBaseConfig(model_name=\\\"resnet18\\\", pretrained=True)\\nconf = OmegaConf.structured(conf)\\n\\n# we need to explicitely pass in the input_shape argument\\nm = TimmBackboneBase.from_config_dict(conf, input_shape=input_shape)\\n\\no2 = m(i)\\ntest_eq(o2.shape, torch.Size([2, 512, 7, 7]))\\n\\ntest_eq(o1.data, o2.data)\";\n",
       "                var nbb_formatted_code = \"@dataclass\\nclass TimmBackboneBaseConfig:\\n    \\\"\\\"\\\"\\n    Base config file for `TimmBackboneBase`\\n    \\\"\\\"\\\"\\n\\n    model_name: str = MISSING\\n    act: Optional[str] = None\\n    lr: Any = 1e-03\\n    wd: Any = 0.0\\n    freeze_bn: bool = False\\n    freeze_at: Any = False\\n    filter_wd: bool = False\\n    pretrained: bool = True\\n    drop_block_rate: Optional[float] = None\\n    drop_path_rate: Optional[float] = None\\n    bn_tf: bool = False\\n\\n\\n# create a config to instantiate the same backbone as above\\nconf = TimmBackboneBaseConfig(model_name=\\\"resnet18\\\", pretrained=True)\\nconf = OmegaConf.structured(conf)\\n\\n# we need to explicitely pass in the input_shape argument\\nm = TimmBackboneBase.from_config_dict(conf, input_shape=input_shape)\\n\\no2 = m(i)\\ntest_eq(o2.shape, torch.Size([2, 512, 7, 7]))\\n\\ntest_eq(o1.data, o2.data)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@dataclass\n",
    "class TimmBackboneBaseConfig:\n",
    "    \"\"\"\n",
    "    Base config file for `TimmBackboneBase`\n",
    "    \"\"\"\n",
    "\n",
    "    model_name: str = MISSING\n",
    "    act: Optional[str] = None\n",
    "    lr: Any = 1e-03\n",
    "    wd: Any = 0.0\n",
    "    freeze_bn: bool = False\n",
    "    freeze_at: Any = False\n",
    "    filter_wd: bool = False\n",
    "    pretrained: bool = True\n",
    "    drop_block_rate: Optional[float] = None\n",
    "    drop_path_rate: Optional[float] = None\n",
    "    bn_tf: bool = False\n",
    "\n",
    "\n",
    "# create a config to instantiate the same backbone as above\n",
    "conf = TimmBackboneBaseConfig(model_name=\"resnet18\", pretrained=True)\n",
    "conf = OmegaConf.structured(conf)\n",
    "\n",
    "# we need to explicitely pass in the input_shape argument\n",
    "m = TimmBackboneBase.from_config_dict(conf, input_shape=input_shape)\n",
    "\n",
    "o2 = m(i)\n",
    "test_eq(o2.shape, torch.Size([2, 512, 7, 7]))\n",
    "\n",
    "test_eq(o1.data, o2.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"# export\\n# fmt: off\\n# @IMAGE_CLASSIFIER_BACKBONES.register()\\nclass ResNetBackbone(ImageClassificationBackbone):\\n    \\\"\\\"\\\"\\n    A Backbone for ResNet based models from timm. Note: this class\\n    does supports all the models listed [here](https://github.com/rwightman/pytorch-image-models/blob/e8a64fb88108b592da192e98054095b1ee25e96e/timm/models/resnet.py)\\n    \\\"\\\"\\\"\\n\\n    @use_kwargs_dict(\\n        keep=True,\\n        pretrained=True,  \\n        drop_block_rate=None,  \\n        drop_path_rate=None,  \\n        bn_tf=False,  \\n    )\\n    \\n    def __init__(\\n        self,\\n        model_name: str,\\n        input_shape: ShapeSpec,\\n        act: str = None,\\n        lr: float = 1e-03,\\n        lr_div: float = 10,\\n        wd: float = 0,\\n        freeze_at: int = 0,\\n        **kwargs\\n    ):  \\n        super(ResNetBackbone, self).__init__()\\n        store_attr(\\\"freeze_at, wd, lr, lr_div, input_shape\\\", self)\\n        \\n        if act is not None:\\n            act = ACTIVATION_REGISTRY.get(act)\\n\\n        model = create_model(model_name, act_layer=act, global_pool=\\\"\\\", num_classes=0, \\n                             in_chans=input_shape.channels, **kwargs)\\n        \\n        assert isinstance(model, ResNet), \\\"ResNetBackbone supports only ResNet models\\\"\\n        # save some of the input information from timm models\\n        self.num_features = model.num_features\\n        self.timm_model_cfg = model.default_cfg\\n        \\n        # break up the model\\n        self.stem = nn.Sequential(model.conv1, model.bn1, model.act1, model.maxpool)\\n        self.stages = nn.Sequential(model.layer1, model.layer2, model.layer3, model.layer4)\\n        \\n        self.prepare_model()\\n\\n        \\n    def forward(self, xb: torch.Tensor) -> torch.Tensor:\\n        out = self.stem(xb)\\n        return self.stages(out)\\n        \\n    def build_param_dicts(self) -> Any:\\n        p0 = {\\\"params\\\": trainable_params(self.stem), \\\"lr\\\": self.lr/self.lr_div, \\\"weight_decay\\\": self.wd}\\n        p1 = {\\\"params\\\": trainable_params(self.stages[0:2]), \\\"lr\\\": self.lr/self.lr_div, \\\"weight_decay\\\": self.wd}\\n        p2 = {\\\"params\\\": trainable_params(self.stages[2:]), \\\"lr\\\": self.lr, \\\"weight_decay\\\": self.wd}\\n        return [p0, p1, p2]\\n        \\n    \\n    def freeze_block(self, m: nn.Module):\\n        \\\"\\\"\\\"\\n        Make this block `m` not trainable.\\n        This method sets all parameters to `requires_grad=False`,\\n        and convert all BatchNorm Layers in eval mode\\n        \\\"\\\"\\\"\\n        for p in m.parameters():\\n            p.requires_grad = False\\n        set_bn_eval(m)\\n        \\n    def prepare_model(self):\\n        \\\"\\\"\\\"\\n        Freeze the first several stages of the ResNet. Commonly used in fine-tuning.\\n        \\\"\\\"\\\"\\n        if self.freeze_at >= 1:\\n            self.freeze_block(self.stem)\\n        for idx, stage in enumerate(self.stages, start=2):\\n            if self.freeze_at >= idx:\\n                for block in stage.children():\\n                    self.freeze_block(block)\\n    \\n    def output_shape(self) -> ShapeSpec:\\n        return ShapeSpec(self.num_features, None, None)\\n# fmt: on\";\n",
       "                var nbb_formatted_code = \"# export\\n# fmt: off\\n# @IMAGE_CLASSIFIER_BACKBONES.register()\\nclass ResNetBackbone(ImageClassificationBackbone):\\n    \\\"\\\"\\\"\\n    A Backbone for ResNet based models from timm. Note: this class\\n    does supports all the models listed [here](https://github.com/rwightman/pytorch-image-models/blob/e8a64fb88108b592da192e98054095b1ee25e96e/timm/models/resnet.py)\\n    \\\"\\\"\\\"\\n\\n    @use_kwargs_dict(\\n        keep=True,\\n        pretrained=True,  \\n        drop_block_rate=None,  \\n        drop_path_rate=None,  \\n        bn_tf=False,  \\n    )\\n    \\n    def __init__(\\n        self,\\n        model_name: str,\\n        input_shape: ShapeSpec,\\n        act: str = None,\\n        lr: float = 1e-03,\\n        lr_div: float = 10,\\n        wd: float = 0,\\n        freeze_at: int = 0,\\n        **kwargs\\n    ):  \\n        super(ResNetBackbone, self).__init__()\\n        store_attr(\\\"freeze_at, wd, lr, lr_div, input_shape\\\", self)\\n        \\n        if act is not None:\\n            act = ACTIVATION_REGISTRY.get(act)\\n\\n        model = create_model(model_name, act_layer=act, global_pool=\\\"\\\", num_classes=0, \\n                             in_chans=input_shape.channels, **kwargs)\\n        \\n        assert isinstance(model, ResNet), \\\"ResNetBackbone supports only ResNet models\\\"\\n        # save some of the input information from timm models\\n        self.num_features = model.num_features\\n        self.timm_model_cfg = model.default_cfg\\n        \\n        # break up the model\\n        self.stem = nn.Sequential(model.conv1, model.bn1, model.act1, model.maxpool)\\n        self.stages = nn.Sequential(model.layer1, model.layer2, model.layer3, model.layer4)\\n        \\n        self.prepare_model()\\n\\n        \\n    def forward(self, xb: torch.Tensor) -> torch.Tensor:\\n        out = self.stem(xb)\\n        return self.stages(out)\\n        \\n    def build_param_dicts(self) -> Any:\\n        p0 = {\\\"params\\\": trainable_params(self.stem), \\\"lr\\\": self.lr/self.lr_div, \\\"weight_decay\\\": self.wd}\\n        p1 = {\\\"params\\\": trainable_params(self.stages[0:2]), \\\"lr\\\": self.lr/self.lr_div, \\\"weight_decay\\\": self.wd}\\n        p2 = {\\\"params\\\": trainable_params(self.stages[2:]), \\\"lr\\\": self.lr, \\\"weight_decay\\\": self.wd}\\n        return [p0, p1, p2]\\n        \\n    \\n    def freeze_block(self, m: nn.Module):\\n        \\\"\\\"\\\"\\n        Make this block `m` not trainable.\\n        This method sets all parameters to `requires_grad=False`,\\n        and convert all BatchNorm Layers in eval mode\\n        \\\"\\\"\\\"\\n        for p in m.parameters():\\n            p.requires_grad = False\\n        set_bn_eval(m)\\n        \\n    def prepare_model(self):\\n        \\\"\\\"\\\"\\n        Freeze the first several stages of the ResNet. Commonly used in fine-tuning.\\n        \\\"\\\"\\\"\\n        if self.freeze_at >= 1:\\n            self.freeze_block(self.stem)\\n        for idx, stage in enumerate(self.stages, start=2):\\n            if self.freeze_at >= idx:\\n                for block in stage.children():\\n                    self.freeze_block(block)\\n    \\n    def output_shape(self) -> ShapeSpec:\\n        return ShapeSpec(self.num_features, None, None)\\n# fmt: on\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "# fmt: off\n",
    "# @IMAGE_CLASSIFIER_BACKBONES.register()\n",
    "class ResNetBackbone(ImageClassificationBackbone):\n",
    "    \"\"\"\n",
    "    A Backbone for ResNet based models from timm. Note: this class\n",
    "    does supports all the models listed [here](https://github.com/rwightman/pytorch-image-models/blob/e8a64fb88108b592da192e98054095b1ee25e96e/timm/models/resnet.py)\n",
    "    \"\"\"\n",
    "\n",
    "    @use_kwargs_dict(\n",
    "        keep=True,\n",
    "        pretrained=True,  \n",
    "        drop_block_rate=None,  \n",
    "        drop_path_rate=None,  \n",
    "        bn_tf=False,  \n",
    "    )\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        input_shape: ShapeSpec,\n",
    "        act: str = None,\n",
    "        lr: float = 1e-03,\n",
    "        lr_div: float = 10,\n",
    "        wd: float = 0,\n",
    "        freeze_at: int = 0,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        super(ResNetBackbone, self).__init__()\n",
    "        store_attr(\"freeze_at, wd, lr, lr_div, input_shape\", self)\n",
    "        \n",
    "        if act is not None:\n",
    "            act = ACTIVATION_REGISTRY.get(act)\n",
    "\n",
    "        model = create_model(model_name, act_layer=act, global_pool=\"\", num_classes=0, \n",
    "                             in_chans=input_shape.channels, **kwargs)\n",
    "        \n",
    "        assert isinstance(model, ResNet), \"ResNetBackbone supports only ResNet models\"\n",
    "        # save some of the input information from timm models\n",
    "        self.num_features = model.num_features\n",
    "        self.timm_model_cfg = model.default_cfg\n",
    "        \n",
    "        # break up the model\n",
    "        self.stem = nn.Sequential(model.conv1, model.bn1, model.act1, model.maxpool)\n",
    "        self.stages = nn.Sequential(model.layer1, model.layer2, model.layer3, model.layer4)\n",
    "        \n",
    "        self.prepare_model()\n",
    "\n",
    "        \n",
    "    def forward(self, xb: torch.Tensor) -> torch.Tensor:\n",
    "        out = self.stem(xb)\n",
    "        return self.stages(out)\n",
    "        \n",
    "    def build_param_dicts(self) -> Any:\n",
    "        p0 = {\"params\": trainable_params(self.stem), \"lr\": self.lr/self.lr_div, \"weight_decay\": self.wd}\n",
    "        p1 = {\"params\": trainable_params(self.stages[0:2]), \"lr\": self.lr/self.lr_div, \"weight_decay\": self.wd}\n",
    "        p2 = {\"params\": trainable_params(self.stages[2:]), \"lr\": self.lr, \"weight_decay\": self.wd}\n",
    "        return [p0, p1, p2]\n",
    "        \n",
    "    \n",
    "    def freeze_block(self, m: nn.Module):\n",
    "        \"\"\"\n",
    "        Make this block `m` not trainable.\n",
    "        This method sets all parameters to `requires_grad=False`,\n",
    "        and convert all BatchNorm Layers in eval mode\n",
    "        \"\"\"\n",
    "        for p in m.parameters():\n",
    "            p.requires_grad = False\n",
    "        set_bn_eval(m)\n",
    "        \n",
    "    def prepare_model(self):\n",
    "        \"\"\"\n",
    "        Freeze the first several stages of the ResNet. Commonly used in fine-tuning.\n",
    "        \"\"\"\n",
    "        if self.freeze_at >= 1:\n",
    "            self.freeze_block(self.stem)\n",
    "        for idx, stage in enumerate(self.stages, start=2):\n",
    "            if self.freeze_at >= idx:\n",
    "                for block in stage.children():\n",
    "                    self.freeze_block(block)\n",
    "    \n",
    "    def output_shape(self) -> ShapeSpec:\n",
    "        return ShapeSpec(self.num_features, None, None)\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"ResNetBackbone\" class=\"doc_header\"><code>class</code> <code>ResNetBackbone</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>ResNetBackbone</code>(**`model_name`**:`str`, **`input_shape`**:`ShapeSpec`, **`act`**:`str`=*`None`*, **`lr`**:`float`=*`0.001`*, **`lr_div`**:`float`=*`10`*, **`wd`**:`float`=*`0`*, **`freeze_at`**:`int`=*`0`*, **`pretrained`**=*`True`*, **`drop_block_rate`**=*`None`*, **`drop_path_rate`**=*`None`*, **`bn_tf`**=*`False`*, **\\*\\*`kwargs`**) :: [`ImageClassificationBackbone`](/gale/classification.modelling.backbones.html#ImageClassificationBackbone)\n",
       "\n",
       "A Backbone for ResNet based models from timm. Note: this class\n",
       "does supports all the models listed [here](https://github.com/rwightman/pytorch-image-models/blob/e8a64fb88108b592da192e98054095b1ee25e96e/timm/models/resnet.py)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ResNetBackbone.prepare_model\" class=\"doc_header\"><code>ResNetBackbone.prepare_model</code><a href=\"__main__.py#L71\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ResNetBackbone.prepare_model</code>()\n",
       "\n",
       "Freeze the first several stages of the ResNet. Commonly used in fine-tuning."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ResNetBackbone.freeze_block\" class=\"doc_header\"><code>ResNetBackbone.freeze_block</code><a href=\"__main__.py#L61\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ResNetBackbone.freeze_block</code>(**`m`**:`Module`)\n",
       "\n",
       "Make this block `m` not trainable.\n",
       "This method sets all parameters to `requires_grad=False`,\n",
       "and convert all BatchNorm Layers in eval mode"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"show_doc(ResNetBackbone)\\nshow_doc(ResNetBackbone.prepare_model)\\nshow_doc(ResNetBackbone.freeze_block)\";\n",
       "                var nbb_formatted_code = \"show_doc(ResNetBackbone)\\nshow_doc(ResNetBackbone.prepare_model)\\nshow_doc(ResNetBackbone.freeze_block)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ResNetBackbone)\n",
    "show_doc(ResNetBackbone.prepare_model)\n",
    "show_doc(ResNetBackbone.freeze_block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguments to `ResNetBackbone`:\n",
    "- `input_shape` (ShapeSpec): Shape of the Inputs\n",
    "- `model_name` (str): name of model to instantiate.\n",
    "- `act` (str): name of the activation function to use. If None uses the default activations else the name must be in `ACTIVATION_REGISTRY`.\n",
    "- `lr` (float): learning rate for the modules.\n",
    "- `lr_div` (int, float): factor for discriminative lrs.   \n",
    "- `wd` (float): weight decay for the modules.\n",
    "- `freeze_at` (int): Freeze the first several stages of the ResNet. Commonly used in fine-tuning. `1` means freezing the stem. `2` means freezing the stem and one residual stage, etc.\n",
    "- `pretrained` (bool): load pretrained ImageNet-1k weights if true.\n",
    "- `drop_block_rate` (float): Drop block rate.\n",
    "- `drop_path_rate` (float): Drop path rate.\n",
    "- `bn_tf` (bool): Use Tensorflow BatchNorm defaults for models that support it.\n",
    "- `kwargs` (optional): Optional kwargs passed onto `timm.create_model()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiation using config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"@dataclass\\nclass ResNetBackboneConfig:\\n    \\\"\\\"\\\"\\n    Base config file for `ResNetBackbone`\\n    \\\"\\\"\\\"\\n\\n    model_name: str = MISSING\\n    act: Optional[str] = None\\n    lr: Any = 1e-03\\n    lr_div: Any = 10\\n    wd: Any = 0.0\\n    freeze_at: int = 0\\n    pretrained: bool = True\\n    drop_block_rate: Optional[float] = None\\n    drop_path_rate: Optional[float] = None\\n    bn_tf: bool = False\\n\\n\\n# create config from OmegaConf using `ResNetBackboneConfig` dataclass\\nconf = OmegaConf.structured(ResNetBackboneConfig(model_name=\\\"resnet34\\\"))\\n# instantiate cls from config\\nm = ResNetBackbone.from_config_dict(conf, input_shape=input_shape)\";\n",
       "                var nbb_formatted_code = \"@dataclass\\nclass ResNetBackboneConfig:\\n    \\\"\\\"\\\"\\n    Base config file for `ResNetBackbone`\\n    \\\"\\\"\\\"\\n\\n    model_name: str = MISSING\\n    act: Optional[str] = None\\n    lr: Any = 1e-03\\n    lr_div: Any = 10\\n    wd: Any = 0.0\\n    freeze_at: int = 0\\n    pretrained: bool = True\\n    drop_block_rate: Optional[float] = None\\n    drop_path_rate: Optional[float] = None\\n    bn_tf: bool = False\\n\\n\\n# create config from OmegaConf using `ResNetBackboneConfig` dataclass\\nconf = OmegaConf.structured(ResNetBackboneConfig(model_name=\\\"resnet34\\\"))\\n# instantiate cls from config\\nm = ResNetBackbone.from_config_dict(conf, input_shape=input_shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@dataclass\n",
    "class ResNetBackboneConfig:\n",
    "    \"\"\"\n",
    "    Base config file for `ResNetBackbone`\n",
    "    \"\"\"\n",
    "\n",
    "    model_name: str = MISSING\n",
    "    act: Optional[str] = None\n",
    "    lr: Any = 1e-03\n",
    "    lr_div: Any = 10\n",
    "    wd: Any = 0.0\n",
    "    freeze_at: int = 0\n",
    "    pretrained: bool = True\n",
    "    drop_block_rate: Optional[float] = None\n",
    "    drop_path_rate: Optional[float] = None\n",
    "    bn_tf: bool = False\n",
    "\n",
    "\n",
    "# create config from OmegaConf using `ResNetBackboneConfig` dataclass\n",
    "conf = OmegaConf.structured(ResNetBackboneConfig(model_name=\"resnet34\"))\n",
    "# instantiate cls from config\n",
    "m = ResNetBackbone.from_config_dict(conf, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.utils.logger.ipynb.\n",
      "Converted 00a_core.utils.visualize.ipynb.\n",
      "Converted 00b_core.utils.structures.ipynb.\n",
      "Converted 01_core.nn.utils.ipynb.\n",
      "Converted 01a_core.nn.losses.ipynb.\n",
      "Converted 02_core.nn.optim.optimizers.ipynb.\n",
      "Converted 02a_core.nn.optim.lr_schedulers.ipynb.\n",
      "Converted 03_core.config.ipynb.\n",
      "Converted 03a_core.classes.ipynb.\n",
      "Converted 04_classification.modelling.backbones.ipynb.\n",
      "Converted 04a_classification.modelling.heads.ipynb.\n",
      "Converted 04b_classification.modelling.meta_arch.general.ipynb.\n",
      "Converted 04b_classification.modelling.meta_arch.vit.ipynb.\n",
      "Converted 05_collections.pandas.ipynb.\n",
      "Converted 06a_collections.callbacks.notebook.ipynb.\n",
      "Converted 06b_collections.callbacks.ema.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"# hide\\nnotebook2script()\";\n",
       "                var nbb_formatted_code = \"# hide\\nnotebook2script()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gale",
   "language": "python",
   "name": "gale"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
