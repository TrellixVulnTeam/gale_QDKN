{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp classification.modelling.backbones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# hide\\n%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\";\n",
       "                var nbb_formatted_code = \"# hide\\n%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# hide\\nimport warnings\\n\\nfrom nbdev.export import *\\nfrom nbdev.showdoc import *\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_formatted_code = \"# hide\\nimport warnings\\n\\nfrom nbdev.export import *\\nfrom nbdev.showdoc import *\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "import warnings\n",
    "\n",
    "from nbdev.export import *\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backbones \n",
    "> Backbones/feature extractors for use in Image Classification Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 61;\n",
       "                var nbb_unformatted_code = \"# export\\nimport re\\nfrom dataclasses import dataclass, field\\nfrom typing import *\\n\\nimport torch\\nfrom fastcore.all import L, delegates, ifnone, use_kwargs_dict, store_attr\\nfrom omegaconf import MISSING, DictConfig, OmegaConf\\nfrom timm import create_model, list_models\\nfrom timm.models import ResNet\\nfrom torch import nn\\n\\nfrom gale.core.classes import GaleModule\\nfrom gale.core.nn import ACTIVATION_REGISTRY\\nfrom gale.core.nn.utils import params, set_bn_eval, trainable_params\\nfrom gale.core.structures import IMAGE_CLASSIFIER_BACKBONES\";\n",
       "                var nbb_formatted_code = \"# export\\nimport re\\nfrom dataclasses import dataclass, field\\nfrom typing import *\\n\\nimport torch\\nfrom fastcore.all import L, delegates, ifnone, use_kwargs_dict, store_attr\\nfrom omegaconf import MISSING, DictConfig, OmegaConf\\nfrom timm import create_model, list_models\\nfrom timm.models import ResNet\\nfrom torch import nn\\n\\nfrom gale.core.classes import GaleModule\\nfrom gale.core.nn import ACTIVATION_REGISTRY\\nfrom gale.core.nn.utils import params, set_bn_eval, trainable_params\\nfrom gale.core.structures import IMAGE_CLASSIFIER_BACKBONES\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "import re\n",
    "from dataclasses import dataclass, field\n",
    "from typing import *\n",
    "\n",
    "import torch\n",
    "from fastcore.all import L, delegates, ifnone, use_kwargs_dict, store_attr\n",
    "from omegaconf import MISSING, DictConfig, OmegaConf\n",
    "from timm import create_model, list_models\n",
    "from timm.models import ResNet\n",
    "from torch import nn\n",
    "\n",
    "from gale.core.classes import GaleModule\n",
    "from gale.core.nn import ACTIVATION_REGISTRY\n",
    "from gale.core.nn.utils import params, set_bn_eval, trainable_params\n",
    "from gale.core.structures import IMAGE_CLASSIFIER_BACKBONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"from fastcore.test import *\\nimport copy\";\n",
       "                var nbb_formatted_code = \"from fastcore.test import *\\nimport copy\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastcore.test import *\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# export\\n# funtions taken from: https://github.com/fastai/fastai/blob/master/fastai/vision/learner.py#L76\\ndef _is_pool_type(l: nn.Module):\\n    return re.search(r\\\"Pool[123]d$\\\", l.__class__.__name__)\\n\\n\\ndef has_pool_type(m: nn.Module):\\n    \\\"Return `True` if `m` is a pooling layer or has one in its children\\\"\\n    if _is_pool_type(m):\\n        return True\\n    for l in m.children():\\n        if has_pool_type(l):\\n            return True\\n    return False\";\n",
       "                var nbb_formatted_code = \"# export\\n# funtions taken from: https://github.com/fastai/fastai/blob/master/fastai/vision/learner.py#L76\\ndef _is_pool_type(l: nn.Module):\\n    return re.search(r\\\"Pool[123]d$\\\", l.__class__.__name__)\\n\\n\\ndef has_pool_type(m: nn.Module):\\n    \\\"Return `True` if `m` is a pooling layer or has one in its children\\\"\\n    if _is_pool_type(m):\\n        return True\\n    for l in m.children():\\n        if has_pool_type(l):\\n            return True\\n    return False\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "# funtions taken from: https://github.com/fastai/fastai/blob/master/fastai/vision/learner.py#L76\n",
    "def _is_pool_type(l: nn.Module):\n",
    "    return re.search(r\"Pool[123]d$\", l.__class__.__name__)\n",
    "\n",
    "\n",
    "def has_pool_type(m: nn.Module):\n",
    "    \"Return `True` if `m` is a pooling layer or has one in its children\"\n",
    "    if _is_pool_type(m):\n",
    "        return True\n",
    "    for l in m.children():\n",
    "        if has_pool_type(l):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# export\\ndef prepare_backbone(model: nn.Module, cut=None):\\n    \\\"Cut off the body of a typically pretrained `model` as determined by `cut`\\\"\\n    if cut is None:\\n        ll = list(enumerate(model.children()))\\n        cut = next(i for i, o in reversed(ll) if has_pool_type(o))\\n    if isinstance(cut, int):\\n        return nn.Sequential(*list(model.children())[:cut])\\n    elif callable(cut):\\n        return cut(model)\\n    else:\\n        raise NamedError(\\\"cut must be either integer or a function\\\")\";\n",
       "                var nbb_formatted_code = \"# export\\ndef prepare_backbone(model: nn.Module, cut=None):\\n    \\\"Cut off the body of a typically pretrained `model` as determined by `cut`\\\"\\n    if cut is None:\\n        ll = list(enumerate(model.children()))\\n        cut = next(i for i, o in reversed(ll) if has_pool_type(o))\\n    if isinstance(cut, int):\\n        return nn.Sequential(*list(model.children())[:cut])\\n    elif callable(cut):\\n        return cut(model)\\n    else:\\n        raise NamedError(\\\"cut must be either integer or a function\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "def prepare_backbone(model: nn.Module, cut=None):\n",
    "    \"Cut off the body of a typically pretrained `model` as determined by `cut`\"\n",
    "    if cut is None:\n",
    "        ll = list(enumerate(model.children()))\n",
    "        cut = next(i for i, o in reversed(ll) if has_pool_type(o))\n",
    "    if isinstance(cut, int):\n",
    "        return nn.Sequential(*list(model.children())[:cut])\n",
    "    elif callable(cut):\n",
    "        return cut(model)\n",
    "    else:\n",
    "        raise NamedError(\"cut must be either integer or a function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# fmt: off\\ntst = nn.Sequential(nn.Conv2d(3, 5, 3), nn.BatchNorm2d(5), nn.AvgPool2d(1), nn.Linear(3, 4))\\n# fmt: on\\n\\nm = prepare_backbone(tst)\\ntest_eq(len(m), 2)\\n\\nm = prepare_backbone(tst, cut=3)\\ntest_eq(len(m), 3)\\n\\nm = prepare_backbone(tst, cut=-1)\\ntest_eq(len(m), 3)\";\n",
       "                var nbb_formatted_code = \"# fmt: off\\ntst = nn.Sequential(nn.Conv2d(3, 5, 3), nn.BatchNorm2d(5), nn.AvgPool2d(1), nn.Linear(3, 4))\\n# fmt: on\\n\\nm = prepare_backbone(tst)\\ntest_eq(len(m), 2)\\n\\nm = prepare_backbone(tst, cut=3)\\ntest_eq(len(m), 3)\\n\\nm = prepare_backbone(tst, cut=-1)\\ntest_eq(len(m), 3)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fmt: off\n",
    "tst = nn.Sequential(nn.Conv2d(3, 5, 3), nn.BatchNorm2d(5), nn.AvgPool2d(1), nn.Linear(3, 4))\n",
    "# fmt: on\n",
    "\n",
    "m = prepare_backbone(tst)\n",
    "test_eq(len(m), 2)\n",
    "\n",
    "m = prepare_backbone(tst, cut=3)\n",
    "test_eq(len(m), 3)\n",
    "\n",
    "m = prepare_backbone(tst, cut=-1)\n",
    "test_eq(len(m), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# export\\ndef filter_weight_decay(\\n    model: nn.Module, lr: float, weight_decay: float = 1e-5, skip_list=()\\n):\\n    \\\"\\\"\\\"\\n    Filter out bias, bn and other 1d params from weight decay.\\n    Modified from: [timm](https://github.com/rwightman/pytorch-image-models/blob/e8a64fb88108b592da192e98054095b1ee25e96e/timm/optim/optim_factory.py)\\n    \\\"\\\"\\\"\\n    decay = []\\n    no_decay = []\\n    for name, param in model.named_parameters():\\n        if not param.requires_grad:\\n            continue  # frozen weights\\n        if len(param.shape) == 1 or name.endswith(\\\".bias\\\") or name in skip_list:\\n            no_decay.append(param)\\n        else:\\n            decay.append(param)\\n    return [\\n        {\\\"params\\\": no_decay, \\\"weight_decay\\\": 0.0, \\\"lr\\\": lr},\\n        {\\\"params\\\": decay, \\\"weight_decay\\\": weight_decay, \\\"lr\\\": lr},\\n    ]\";\n",
       "                var nbb_formatted_code = \"# export\\ndef filter_weight_decay(\\n    model: nn.Module, lr: float, weight_decay: float = 1e-5, skip_list=()\\n):\\n    \\\"\\\"\\\"\\n    Filter out bias, bn and other 1d params from weight decay.\\n    Modified from: [timm](https://github.com/rwightman/pytorch-image-models/blob/e8a64fb88108b592da192e98054095b1ee25e96e/timm/optim/optim_factory.py)\\n    \\\"\\\"\\\"\\n    decay = []\\n    no_decay = []\\n    for name, param in model.named_parameters():\\n        if not param.requires_grad:\\n            continue  # frozen weights\\n        if len(param.shape) == 1 or name.endswith(\\\".bias\\\") or name in skip_list:\\n            no_decay.append(param)\\n        else:\\n            decay.append(param)\\n    return [\\n        {\\\"params\\\": no_decay, \\\"weight_decay\\\": 0.0, \\\"lr\\\": lr},\\n        {\\\"params\\\": decay, \\\"weight_decay\\\": weight_decay, \\\"lr\\\": lr},\\n    ]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "def filter_weight_decay(\n",
    "    model: nn.Module, lr: float, weight_decay: float = 1e-5, skip_list=()\n",
    "):\n",
    "    \"\"\"\n",
    "    Filter out bias, bn and other 1d params from weight decay.\n",
    "    Modified from: [timm](https://github.com/rwightman/pytorch-image-models/blob/e8a64fb88108b592da192e98054095b1ee25e96e/timm/optim/optim_factory.py)\n",
    "    \"\"\"\n",
    "    decay = []\n",
    "    no_decay = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if not param.requires_grad:\n",
    "            continue  # frozen weights\n",
    "        if len(param.shape) == 1 or name.endswith(\".bias\") or name in skip_list:\n",
    "            no_decay.append(param)\n",
    "        else:\n",
    "            decay.append(param)\n",
    "    return [\n",
    "        {\"params\": no_decay, \"weight_decay\": 0.0, \"lr\": lr},\n",
    "        {\"params\": decay, \"weight_decay\": weight_decay, \"lr\": lr},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"# export\\n@IMAGE_CLASSIFIER_BACKBONES.register()\\nclass TimmBackboneBase(GaleModule):\\n    \\\"Create a model from `timm` and converts it into a Image Classification Backbone\\\"\\n\\n    @use_kwargs_dict(\\n        keep=True,\\n        pretrained=True,  # pretrained model\\n        in_chans=3,  # number of channels for the first layer\\n        drop_block_rate=None,  # Drop block rate\\n        drop_path_rate=None,  # Drop path rate\\n        bn_tf=False,  # Use Tensorflow BatchNorm defaults for models that support it\\n    )\\n    def __init__(\\n        self,\\n        model_name: str,\\n        act: str = None,  # name of the activation layer\\n        lr: float = 1e-03,  # learning rate for the backbone\\n        wd: float = 0,  # weight decay for the backbone paramters\\n        freeze_bn: bool = False,  # wether to freeze the batchnorm layers of the model\\n        freeze_at: int = False,  # freeze the layers of the backbone, false means train all\\n        filter_wd: bool = False,  # Filter out bias, bn from weight_decay\\n        **kwargs\\n    ):\\n        super(TimmBackboneBase, self).__init__()\\n        if act is not None:\\n            act = ACTIVATION_REGISTRY.get(act)\\n\\n        # fmt: off\\n        model = create_model(model_name, act_layer=act, global_pool=\\\"\\\", num_classes=0, **kwargs)\\n        # fmt: on\\n\\n        self._default_cfg = model.default_cfg\\n        self._model = prepare_backbone(model)\\n\\n        if not freeze_at:\\n            self.unfreeze()\\n        else:\\n            self.freeze_to(freeze_at)\\n\\n        if freeze_bn:\\n            set_bn_eval(self._model)\\n\\n        self.lr, self.wd = lr, wd\\n        self.filter_wd = filter_wd\\n\\n    def forward(self, xb: torch.Tensor) -> torch.Tensor:\\n        return self._model(xb)\\n\\n    def build_param_dicts(self):\\n        if self.filter_wd:\\n            ps = filter_weight_decay(self._model, lr=self.lr, weight_decay=self.wd)\\n        else:\\n            # fmt: off\\n            ps = [{\\\"params\\\": trainable_params(self._model),\\\"lr\\\": self._lr,\\\"weight_decay\\\": self._wd}]\\n            # fmt: on\\n        return ps\";\n",
       "                var nbb_formatted_code = \"# export\\n@IMAGE_CLASSIFIER_BACKBONES.register()\\nclass TimmBackboneBase(GaleModule):\\n    \\\"Create a model from `timm` and converts it into a Image Classification Backbone\\\"\\n\\n    @use_kwargs_dict(\\n        keep=True,\\n        pretrained=True,  # pretrained model\\n        in_chans=3,  # number of channels for the first layer\\n        drop_block_rate=None,  # Drop block rate\\n        drop_path_rate=None,  # Drop path rate\\n        bn_tf=False,  # Use Tensorflow BatchNorm defaults for models that support it\\n    )\\n    def __init__(\\n        self,\\n        model_name: str,\\n        act: str = None,  # name of the activation layer\\n        lr: float = 1e-03,  # learning rate for the backbone\\n        wd: float = 0,  # weight decay for the backbone paramters\\n        freeze_bn: bool = False,  # wether to freeze the batchnorm layers of the model\\n        freeze_at: int = False,  # freeze the layers of the backbone, false means train all\\n        filter_wd: bool = False,  # Filter out bias, bn from weight_decay\\n        **kwargs\\n    ):\\n        super(TimmBackboneBase, self).__init__()\\n        if act is not None:\\n            act = ACTIVATION_REGISTRY.get(act)\\n\\n        # fmt: off\\n        model = create_model(model_name, act_layer=act, global_pool=\\\"\\\", num_classes=0, **kwargs)\\n        # fmt: on\\n\\n        self._default_cfg = model.default_cfg\\n        self._model = prepare_backbone(model)\\n\\n        if not freeze_at:\\n            self.unfreeze()\\n        else:\\n            self.freeze_to(freeze_at)\\n\\n        if freeze_bn:\\n            set_bn_eval(self._model)\\n\\n        self.lr, self.wd = lr, wd\\n        self.filter_wd = filter_wd\\n\\n    def forward(self, xb: torch.Tensor) -> torch.Tensor:\\n        return self._model(xb)\\n\\n    def build_param_dicts(self):\\n        if self.filter_wd:\\n            ps = filter_weight_decay(self._model, lr=self.lr, weight_decay=self.wd)\\n        else:\\n            # fmt: off\\n            ps = [{\\\"params\\\": trainable_params(self._model),\\\"lr\\\": self._lr,\\\"weight_decay\\\": self._wd}]\\n            # fmt: on\\n        return ps\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "@IMAGE_CLASSIFIER_BACKBONES.register()\n",
    "class TimmBackboneBase(GaleModule):\n",
    "    \"Create a model from `timm` and converts it into a Image Classification Backbone\"\n",
    "\n",
    "    @use_kwargs_dict(\n",
    "        keep=True,\n",
    "        pretrained=True,  # pretrained model\n",
    "        in_chans=3,  # number of channels for the first layer\n",
    "        drop_block_rate=None,  # Drop block rate\n",
    "        drop_path_rate=None,  # Drop path rate\n",
    "        bn_tf=False,  # Use Tensorflow BatchNorm defaults for models that support it\n",
    "    )\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        act: str = None,  # name of the activation layer\n",
    "        lr: float = 1e-03,  # learning rate for the backbone\n",
    "        wd: float = 0,  # weight decay for the backbone paramters\n",
    "        freeze_bn: bool = False,  # wether to freeze the batchnorm layers of the model\n",
    "        freeze_at: int = False,  # freeze the layers of the backbone, false means train all\n",
    "        filter_wd: bool = False,  # Filter out bias, bn from weight_decay\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(TimmBackboneBase, self).__init__()\n",
    "        if act is not None:\n",
    "            act = ACTIVATION_REGISTRY.get(act)\n",
    "\n",
    "        # fmt: off\n",
    "        model = create_model(model_name, act_layer=act, global_pool=\"\", num_classes=0, **kwargs)\n",
    "        # fmt: on\n",
    "\n",
    "        self._default_cfg = model.default_cfg\n",
    "        self._model = prepare_backbone(model)\n",
    "\n",
    "        if not freeze_at:\n",
    "            self.unfreeze()\n",
    "        else:\n",
    "            self.freeze_to(freeze_at)\n",
    "\n",
    "        if freeze_bn:\n",
    "            set_bn_eval(self._model)\n",
    "\n",
    "        self.lr, self.wd = lr, wd\n",
    "        self.filter_wd = filter_wd\n",
    "\n",
    "    def forward(self, xb: torch.Tensor) -> torch.Tensor:\n",
    "        return self._model(xb)\n",
    "\n",
    "    def build_param_dicts(self):\n",
    "        if self.filter_wd:\n",
    "            ps = filter_weight_decay(self._model, lr=self.lr, weight_decay=self.wd)\n",
    "        else:\n",
    "            # fmt: off\n",
    "            ps = [{\"params\": trainable_params(self._model),\"lr\": self._lr,\"weight_decay\": self._wd}]\n",
    "            # fmt: on\n",
    "        return ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguments to `TimmBackboneBase`:\n",
    "- `model_name` (str): name of model to instantiate.\n",
    "- `act` (str): name of the activation function to use. If None uses the default activations else the name must be in `ACTIVATION_REGISTRY`.\n",
    "- `lr` (float): learning rate for the modules.\n",
    "- `wd` (float): weight decay for the modules.\n",
    "- `freeze_bn` (bool): freeze the batch normalization layers of the model.\n",
    "- `freeze_at` (int): freeze the layers of the backbone upto `freeze_at`, false means train all.\n",
    "- `filter_wd` (bool): Filter out bias, bn from weight_decay.\n",
    "- `pretrained` (bool): load pretrained ImageNet-1k weights if true.\n",
    "- `in_chans` (int): number of channels for the first layer.\n",
    "- `drop_block_rate` (float): Drop block rate\n",
    "- `drop_path_rate` (float): Drop_path_rate\n",
    "- `bn_tf` (bool): Use Tensorflow BatchNorm defaults for models that support it.\n",
    "- `kwargs` (optional): Optional kwargs passed onto `timm.create_model()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"bk = TimmBackboneBase(\\\"resnet18\\\", pretrained=True)\\n\\ni = torch.randn(2, 3, 224, 224)\\no1 = bk(i)\\ntest_eq(o1.shape, torch.Size([2, 512, 7, 7]))\";\n",
       "                var nbb_formatted_code = \"bk = TimmBackboneBase(\\\"resnet18\\\", pretrained=True)\\n\\ni = torch.randn(2, 3, 224, 224)\\no1 = bk(i)\\ntest_eq(o1.shape, torch.Size([2, 512, 7, 7]))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bk = TimmBackboneBase(\"resnet18\", pretrained=True)\n",
    "\n",
    "i = torch.randn(2, 3, 224, 224)\n",
    "o1 = bk(i)\n",
    "test_eq(o1.shape, torch.Size([2, 512, 7, 7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"# export\\n@dataclass\\nclass TimmBackboneBaseConfig:\\n    \\\"\\\"\\\"\\n    Base config file for `TimmBackboneBase`\\n    \\\"\\\"\\\"\\n\\n    model_name: str = MISSING\\n    act: Optional[str] = None\\n    lr: Any = 1e-03\\n    wd: Any = 0.0\\n    freeze_bn: bool = False\\n    freeze_at: Any = False\\n    filter_wd: bool = False\\n    pretrained: bool = True\\n    in_chans: int = 3\\n    drop_block_rate: Optional[float] = None\\n    drop_path_rate: Optional[float] = None\\n    bn_tf: bool = False\";\n",
       "                var nbb_formatted_code = \"# export\\n@dataclass\\nclass TimmBackboneBaseConfig:\\n    \\\"\\\"\\\"\\n    Base config file for `TimmBackboneBase`\\n    \\\"\\\"\\\"\\n\\n    model_name: str = MISSING\\n    act: Optional[str] = None\\n    lr: Any = 1e-03\\n    wd: Any = 0.0\\n    freeze_bn: bool = False\\n    freeze_at: Any = False\\n    filter_wd: bool = False\\n    pretrained: bool = True\\n    in_chans: int = 3\\n    drop_block_rate: Optional[float] = None\\n    drop_path_rate: Optional[float] = None\\n    bn_tf: bool = False\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "@dataclass\n",
    "class TimmBackboneBaseConfig:\n",
    "    \"\"\"\n",
    "    Base config file for `TimmBackboneBase`\n",
    "    \"\"\"\n",
    "\n",
    "    model_name: str = MISSING\n",
    "    act: Optional[str] = None\n",
    "    lr: Any = 1e-03\n",
    "    wd: Any = 0.0\n",
    "    freeze_bn: bool = False\n",
    "    freeze_at: Any = False\n",
    "    filter_wd: bool = False\n",
    "    pretrained: bool = True\n",
    "    in_chans: int = 3\n",
    "    drop_block_rate: Optional[float] = None\n",
    "    drop_path_rate: Optional[float] = None\n",
    "    bn_tf: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also instantiate `TimmBackboneBaseConfig` from a config -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# create a config to instantiate the same backbone as above\\nconf = TimmBackboneBaseConfig(model_name=\\\"resnet18\\\", pretrained=True)\\nconf = OmegaConf.structured(conf)\\n\\nm = TimmBackboneBase.from_config_dict(conf)\\n\\no2 = m(i)\\ntest_eq(o2.shape, torch.Size([2, 512, 7, 7]))\\n\\ntest_eq(o1.data, o2.data)\";\n",
       "                var nbb_formatted_code = \"# create a config to instantiate the same backbone as above\\nconf = TimmBackboneBaseConfig(model_name=\\\"resnet18\\\", pretrained=True)\\nconf = OmegaConf.structured(conf)\\n\\nm = TimmBackboneBase.from_config_dict(conf)\\n\\no2 = m(i)\\ntest_eq(o2.shape, torch.Size([2, 512, 7, 7]))\\n\\ntest_eq(o1.data, o2.data)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a config to instantiate the same backbone as above\n",
    "conf = TimmBackboneBaseConfig(model_name=\"resnet18\", pretrained=True)\n",
    "conf = OmegaConf.structured(conf)\n",
    "\n",
    "m = TimmBackboneBase.from_config_dict(conf)\n",
    "\n",
    "o2 = m(i)\n",
    "test_eq(o2.shape, torch.Size([2, 512, 7, 7]))\n",
    "\n",
    "test_eq(o1.data, o2.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 107;\n",
       "                var nbb_unformatted_code = \"# export\\n# fmt: off\\n@IMAGE_CLASSIFIER_BACKBONES.register()\\nclass ResNetBackbone(GaleModule):\\n    \\\"\\\"\\\"\\n    A Backbone for ResNet based models from timm. Note: this class\\n    does supports all the models listed [here](https://github.com/rwightman/pytorch-image-models/blob/e8a64fb88108b592da192e98054095b1ee25e96e/timm/models/resnet.py)\\n    \\\"\\\"\\\"\\n\\n    @use_kwargs_dict(\\n        keep=True,\\n        pretrained=True, \\n        in_chans=3,  \\n        drop_block_rate=None,  \\n        drop_path_rate=None,  \\n        bn_tf=False,  \\n    )\\n    \\n    def __init__(\\n        self,\\n        model_name: str,\\n        act: str = None,\\n        lr: float = 1e-03,\\n        lr_div: float = 10,\\n        wd: float = 0,\\n        freeze_at: int = 0,\\n        **kwargs\\n    ):  \\n        super(ResNetBackbone, self).__init__()\\n        store_attr(\\\"freeze_at, wd, lr, lr_div\\\", self)\\n        \\n        if act is not None:\\n            act = ACTIVATION_REGISTRY.get(act)\\n\\n        model = create_model(model_name, act_layer=act, global_pool=\\\"\\\", num_classes=0, **kwargs)\\n        assert isinstance(model, ResNet), \\\"ResNetBackbone supports on ResNet models\\\" \\n        \\n        # break up the model\\n        self.stem = nn.Sequential(model.conv1, model.bn1, model.act1, model.maxpool)\\n        self.stages = nn.Sequential(model.layer1, model.layer2, model.layer3, model.layer4)\\n        \\n        self.prepare_model()\\n\\n        \\n    def forward(self, xb: torch.Tensor) -> torch.Tensor:\\n        out = self.stem(xb)\\n        return self.stages(out)\\n        \\n    def build_param_dicts(self) -> Any:\\n        p0 = {\\\"params\\\": trainable_params(self.stem), \\\"lr\\\": self.lr/self.lr_div, \\\"weight_decay\\\": self.wd}\\n        p1 = {\\\"params\\\": trainable_params(self.stages[0:2]), \\\"lr\\\": self.lr/self.lr_div, \\\"weight_decay\\\": self.wd}\\n        p2 = {\\\"params\\\": trainable_params(self.stages[2:]), \\\"lr\\\": self.lr, \\\"weight_decay\\\": self.wd}\\n        return [p0, p1, p2]\\n        \\n    \\n    def freeze_block(self, m):\\n        \\\"\\\"\\\"\\n        Make this block `m` not trainable.\\n        This method sets all parameters to `requires_grad=False`,\\n        and convert all BatchNorm Layers in eval mode\\n        \\\"\\\"\\\"\\n        for p in m.parameters():\\n            p.requires_grad = False\\n        set_bn_eval(m)\\n        \\n    def prepare_model(self):\\n        \\\"\\\"\\\"\\n        Freeze the first several stages of the ResNet. Commonly used in fine-tuning.\\n        \\\"\\\"\\\"\\n        if self.freeze_at >= 1:\\n            self.freeze_block(self.stem)\\n        for idx, stage in enumerate(self.stages, start=2):\\n            if self.freeze_at >= idx:\\n                for block in stage.children():\\n                    self.freeze_block(block)\\n# fmt: on\";\n",
       "                var nbb_formatted_code = \"# export\\n# fmt: off\\n@IMAGE_CLASSIFIER_BACKBONES.register()\\nclass ResNetBackbone(GaleModule):\\n    \\\"\\\"\\\"\\n    A Backbone for ResNet based models from timm. Note: this class\\n    does supports all the models listed [here](https://github.com/rwightman/pytorch-image-models/blob/e8a64fb88108b592da192e98054095b1ee25e96e/timm/models/resnet.py)\\n    \\\"\\\"\\\"\\n\\n    @use_kwargs_dict(\\n        keep=True,\\n        pretrained=True, \\n        in_chans=3,  \\n        drop_block_rate=None,  \\n        drop_path_rate=None,  \\n        bn_tf=False,  \\n    )\\n    \\n    def __init__(\\n        self,\\n        model_name: str,\\n        act: str = None,\\n        lr: float = 1e-03,\\n        lr_div: float = 10,\\n        wd: float = 0,\\n        freeze_at: int = 0,\\n        **kwargs\\n    ):  \\n        super(ResNetBackbone, self).__init__()\\n        store_attr(\\\"freeze_at, wd, lr, lr_div\\\", self)\\n        \\n        if act is not None:\\n            act = ACTIVATION_REGISTRY.get(act)\\n\\n        model = create_model(model_name, act_layer=act, global_pool=\\\"\\\", num_classes=0, **kwargs)\\n        assert isinstance(model, ResNet), \\\"ResNetBackbone supports on ResNet models\\\" \\n        \\n        # break up the model\\n        self.stem = nn.Sequential(model.conv1, model.bn1, model.act1, model.maxpool)\\n        self.stages = nn.Sequential(model.layer1, model.layer2, model.layer3, model.layer4)\\n        \\n        self.prepare_model()\\n\\n        \\n    def forward(self, xb: torch.Tensor) -> torch.Tensor:\\n        out = self.stem(xb)\\n        return self.stages(out)\\n        \\n    def build_param_dicts(self) -> Any:\\n        p0 = {\\\"params\\\": trainable_params(self.stem), \\\"lr\\\": self.lr/self.lr_div, \\\"weight_decay\\\": self.wd}\\n        p1 = {\\\"params\\\": trainable_params(self.stages[0:2]), \\\"lr\\\": self.lr/self.lr_div, \\\"weight_decay\\\": self.wd}\\n        p2 = {\\\"params\\\": trainable_params(self.stages[2:]), \\\"lr\\\": self.lr, \\\"weight_decay\\\": self.wd}\\n        return [p0, p1, p2]\\n        \\n    \\n    def freeze_block(self, m):\\n        \\\"\\\"\\\"\\n        Make this block `m` not trainable.\\n        This method sets all parameters to `requires_grad=False`,\\n        and convert all BatchNorm Layers in eval mode\\n        \\\"\\\"\\\"\\n        for p in m.parameters():\\n            p.requires_grad = False\\n        set_bn_eval(m)\\n        \\n    def prepare_model(self):\\n        \\\"\\\"\\\"\\n        Freeze the first several stages of the ResNet. Commonly used in fine-tuning.\\n        \\\"\\\"\\\"\\n        if self.freeze_at >= 1:\\n            self.freeze_block(self.stem)\\n        for idx, stage in enumerate(self.stages, start=2):\\n            if self.freeze_at >= idx:\\n                for block in stage.children():\\n                    self.freeze_block(block)\\n# fmt: on\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "# fmt: off\n",
    "@IMAGE_CLASSIFIER_BACKBONES.register()\n",
    "class ResNetBackbone(GaleModule):\n",
    "    \"\"\"\n",
    "    A Backbone for ResNet based models from timm. Note: this class\n",
    "    does supports all the models listed [here](https://github.com/rwightman/pytorch-image-models/blob/e8a64fb88108b592da192e98054095b1ee25e96e/timm/models/resnet.py)\n",
    "    \"\"\"\n",
    "\n",
    "    @use_kwargs_dict(\n",
    "        keep=True,\n",
    "        pretrained=True, \n",
    "        in_chans=3,  \n",
    "        drop_block_rate=None,  \n",
    "        drop_path_rate=None,  \n",
    "        bn_tf=False,  \n",
    "    )\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        act: str = None,\n",
    "        lr: float = 1e-03,\n",
    "        lr_div: float = 10,\n",
    "        wd: float = 0,\n",
    "        freeze_at: int = 0,\n",
    "        **kwargs\n",
    "    ):  \n",
    "        super(ResNetBackbone, self).__init__()\n",
    "        store_attr(\"freeze_at, wd, lr, lr_div\", self)\n",
    "        \n",
    "        if act is not None:\n",
    "            act = ACTIVATION_REGISTRY.get(act)\n",
    "\n",
    "        model = create_model(model_name, act_layer=act, global_pool=\"\", num_classes=0, **kwargs)\n",
    "        assert isinstance(model, ResNet), \"ResNetBackbone supports on ResNet models\" \n",
    "        \n",
    "        # break up the model\n",
    "        self.stem = nn.Sequential(model.conv1, model.bn1, model.act1, model.maxpool)\n",
    "        self.stages = nn.Sequential(model.layer1, model.layer2, model.layer3, model.layer4)\n",
    "        \n",
    "        self.prepare_model()\n",
    "\n",
    "        \n",
    "    def forward(self, xb: torch.Tensor) -> torch.Tensor:\n",
    "        out = self.stem(xb)\n",
    "        return self.stages(out)\n",
    "        \n",
    "    def build_param_dicts(self) -> Any:\n",
    "        p0 = {\"params\": trainable_params(self.stem), \"lr\": self.lr/self.lr_div, \"weight_decay\": self.wd}\n",
    "        p1 = {\"params\": trainable_params(self.stages[0:2]), \"lr\": self.lr/self.lr_div, \"weight_decay\": self.wd}\n",
    "        p2 = {\"params\": trainable_params(self.stages[2:]), \"lr\": self.lr, \"weight_decay\": self.wd}\n",
    "        return [p0, p1, p2]\n",
    "        \n",
    "    \n",
    "    def freeze_block(self, m):\n",
    "        \"\"\"\n",
    "        Make this block `m` not trainable.\n",
    "        This method sets all parameters to `requires_grad=False`,\n",
    "        and convert all BatchNorm Layers in eval mode\n",
    "        \"\"\"\n",
    "        for p in m.parameters():\n",
    "            p.requires_grad = False\n",
    "        set_bn_eval(m)\n",
    "        \n",
    "    def prepare_model(self):\n",
    "        \"\"\"\n",
    "        Freeze the first several stages of the ResNet. Commonly used in fine-tuning.\n",
    "        \"\"\"\n",
    "        if self.freeze_at >= 1:\n",
    "            self.freeze_block(self.stem)\n",
    "        for idx, stage in enumerate(self.stages, start=2):\n",
    "            if self.freeze_at >= idx:\n",
    "                for block in stage.children():\n",
    "                    self.freeze_block(block)\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguments to `ResNetBackbone`:\n",
    "- `model_name` (str): name of model to instantiate.\n",
    "- `act` (str): name of the activation function to use. If None uses the default activations else the name must be in `ACTIVATION_REGISTRY`.\n",
    "- `lr` (float): learning rate for the modules.\n",
    "- `lr_div` (int, float): factor for discriminative lrs.   \n",
    "- `wd` (float): weight decay for the modules.\n",
    "- `freeze_at` (int): Freeze the first several stages of the ResNet. Commonly used in fine-tuning. `1` means freezing the stem. `2` means freezing the stem and one residual stage, etc.\n",
    "- `pretrained` (bool): load pretrained ImageNet-1k weights if true.\n",
    "- `in_chans` (int): number of channels for the first layer.\n",
    "- `drop_block_rate` (float): Drop block rate\n",
    "- `drop_path_rate` (float): Drop_path_rate\n",
    "- `bn_tf` (bool): Use Tensorflow BatchNorm defaults for models that support it.\n",
    "- `kwargs` (optional): Optional kwargs passed onto `timm.create_model()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 108;\n",
       "                var nbb_unformatted_code = \"# export\\n@dataclass\\nclass ResNetBackboneConfig:\\n    \\\"\\\"\\\"\\n    Base config file for `ResNetBackbone`\\n    \\\"\\\"\\\"\\n\\n    model_name: str = MISSING\\n    act: Optional[str] = None\\n    lr: Any = 1e-03\\n    lr_div: Any = 10\\n    wd: Any = 0.0\\n    freeze_at: int = 0\\n    pretrained: bool = True\\n    in_chans: int = 3\\n    drop_block_rate: Optional[float] = None\\n    drop_path_rate: Optional[float] = None\\n    bn_tf: bool = False\";\n",
       "                var nbb_formatted_code = \"# export\\n@dataclass\\nclass ResNetBackboneConfig:\\n    \\\"\\\"\\\"\\n    Base config file for `ResNetBackbone`\\n    \\\"\\\"\\\"\\n\\n    model_name: str = MISSING\\n    act: Optional[str] = None\\n    lr: Any = 1e-03\\n    lr_div: Any = 10\\n    wd: Any = 0.0\\n    freeze_at: int = 0\\n    pretrained: bool = True\\n    in_chans: int = 3\\n    drop_block_rate: Optional[float] = None\\n    drop_path_rate: Optional[float] = None\\n    bn_tf: bool = False\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "@dataclass\n",
    "class ResNetBackboneConfig:\n",
    "    \"\"\"\n",
    "    Base config file for `ResNetBackbone`\n",
    "    \"\"\"\n",
    "\n",
    "    model_name: str = MISSING\n",
    "    act: Optional[str] = None\n",
    "    lr: Any = 1e-03\n",
    "    lr_div: Any = 10\n",
    "    wd: Any = 0.0\n",
    "    freeze_at: int = 0\n",
    "    pretrained: bool = True\n",
    "    in_chans: int = 3\n",
    "    drop_block_rate: Optional[float] = None\n",
    "    drop_path_rate: Optional[float] = None\n",
    "    bn_tf: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 115;\n",
       "                var nbb_unformatted_code = \"# create config from OmegaConf using `ResNetBackboneConfig` dataclass \\nconf = OmegaConf.structured(ResNetBackboneConfig(model_name=\\\"resnet34\\\"))\\n# instantiate cls from config\\nm = ResNetBackbone.from_config_dict(conf)\";\n",
       "                var nbb_formatted_code = \"# create config from OmegaConf using `ResNetBackboneConfig` dataclass\\nconf = OmegaConf.structured(ResNetBackboneConfig(model_name=\\\"resnet34\\\"))\\n# instantiate cls from config\\nm = ResNetBackbone.from_config_dict(conf)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create config from OmegaConf using `ResNetBackboneConfig` dataclass\n",
    "conf = OmegaConf.structured(ResNetBackboneConfig(model_name=\"resnet34\"))\n",
    "# instantiate cls from config\n",
    "m = ResNetBackbone.from_config_dict(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.logging.ipynb.\n",
      "Converted 00a_core.structures.ipynb.\n",
      "Converted 00b_core.visualize.ipynb.\n",
      "Converted 01_core.nn.utils.ipynb.\n",
      "Converted 01a_core.nn.losses.ipynb.\n",
      "Converted 01b_core.nn.optim.optimizers.ipynb.\n",
      "Converted 01c_core.nn.optim.lr_schedulers.ipynb.\n",
      "Converted 02_config.optimizers.ipynb.\n",
      "Converted 02a_config.schedulers.ipynb.\n",
      "Converted 02b_config.common.ipynb.\n",
      "Converted 03_core.classes.ipynb.\n",
      "Converted 04_classification.modelling.backbones.ipynb.\n",
      "Converted 05_collections.pandas.ipynb.\n",
      "Converted 06a_collections.callbacks.notebook.ipynb.\n",
      "Converted 06b_collections.callbacks.ema.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 117;\n",
       "                var nbb_unformatted_code = \"# hide\\nnotebook2script()\";\n",
       "                var nbb_formatted_code = \"# hide\\nnotebook2script()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gale",
   "language": "python",
   "name": "gale"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
