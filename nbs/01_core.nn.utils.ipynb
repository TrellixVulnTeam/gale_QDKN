{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core.nn.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# hide\\nimport warnings\\n\\nfrom nbdev.export import *\\nfrom nbdev.showdoc import *\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_formatted_code = \"# hide\\nimport warnings\\n\\nfrom nbdev.export import *\\nfrom nbdev.showdoc import *\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "import warnings\n",
    "\n",
    "from nbdev.export import *\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilitites\n",
    "> Custom `Torch` utilitities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# export\\nfrom functools import partial\\nfrom typing import *\\n\\nimport numpy as np\\nimport torch\\nfrom torch import nn\";\n",
       "                var nbb_formatted_code = \"# export\\nfrom functools import partial\\nfrom typing import *\\n\\nimport numpy as np\\nimport torch\\nfrom torch import nn\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "from functools import partial\n",
    "from typing import *\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"from fastcore.test import *\";\n",
       "                var nbb_formatted_code = \"from fastcore.test import *\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# export\\nnorm_types = (\\n    nn.BatchNorm1d,\\n    nn.BatchNorm2d,\\n    nn.BatchNorm3d,\\n    nn.InstanceNorm1d,\\n    nn.InstanceNorm2d,\\n    nn.InstanceNorm3d,\\n    nn.LayerNorm,\\n)\\n\\nbn_types = (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)\";\n",
       "                var nbb_formatted_code = \"# export\\nnorm_types = (\\n    nn.BatchNorm1d,\\n    nn.BatchNorm2d,\\n    nn.BatchNorm3d,\\n    nn.InstanceNorm1d,\\n    nn.InstanceNorm2d,\\n    nn.InstanceNorm3d,\\n    nn.LayerNorm,\\n)\\n\\nbn_types = (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "norm_types = (\n",
    "    nn.BatchNorm1d,\n",
    "    nn.BatchNorm2d,\n",
    "    nn.BatchNorm3d,\n",
    "    nn.InstanceNorm1d,\n",
    "    nn.InstanceNorm2d,\n",
    "    nn.InstanceNorm3d,\n",
    "    nn.LayerNorm,\n",
    ")\n",
    "\n",
    "bn_types = (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# export\\ndef init_default(m: nn.Module, func: Callable = nn.init.kaiming_normal_):\\n    \\\"\\\"\\\"\\n    Initialize `m` weights with `func` and set `bias` to 0.\\n    Source: https://github.com/fastai/fastai/blob/master/fastai/torch_core.py\\n    \\\"\\\"\\\"\\n    if func:\\n        if hasattr(m, \\\"weight\\\"):\\n            func(m.weight)\\n        if hasattr(m, \\\"bias\\\") and hasattr(m.bias, \\\"data\\\"):\\n            m.bias.data.fill_(0.0)\\n    return m\";\n",
       "                var nbb_formatted_code = \"# export\\ndef init_default(m: nn.Module, func: Callable = nn.init.kaiming_normal_):\\n    \\\"\\\"\\\"\\n    Initialize `m` weights with `func` and set `bias` to 0.\\n    Source: https://github.com/fastai/fastai/blob/master/fastai/torch_core.py\\n    \\\"\\\"\\\"\\n    if func:\\n        if hasattr(m, \\\"weight\\\"):\\n            func(m.weight)\\n        if hasattr(m, \\\"bias\\\") and hasattr(m.bias, \\\"data\\\"):\\n            m.bias.data.fill_(0.0)\\n    return m\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "def init_default(m: nn.Module, func: Callable = nn.init.kaiming_normal_):\n",
    "    \"\"\"\n",
    "    Initialize `m` weights with `func` and set `bias` to 0.\n",
    "    Source: https://github.com/fastai/fastai/blob/master/fastai/torch_core.py\n",
    "    \"\"\"\n",
    "    if func:\n",
    "        if hasattr(m, \"weight\"):\n",
    "            func(m.weight)\n",
    "        if hasattr(m, \"bias\") and hasattr(m.bias, \"data\"):\n",
    "            m.bias.data.fill_(0.0)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"with torch.no_grad():\\n    tst = nn.Linear(4, 5)\\n    tst.weight.data.uniform_(-1, 1)\\n    tst.bias.data.uniform_(-1, 1)\\n    tst = init_default(tst, func=lambda x: x.data.fill_(1.0))\\n    test_eq(tst.weight, torch.ones(5, 4))\\n    test_eq(tst.bias, torch.zeros(5))\";\n",
       "                var nbb_formatted_code = \"with torch.no_grad():\\n    tst = nn.Linear(4, 5)\\n    tst.weight.data.uniform_(-1, 1)\\n    tst.bias.data.uniform_(-1, 1)\\n    tst = init_default(tst, func=lambda x: x.data.fill_(1.0))\\n    test_eq(tst.weight, torch.ones(5, 4))\\n    test_eq(tst.bias, torch.zeros(5))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    tst = nn.Linear(4, 5)\n",
    "    tst.weight.data.uniform_(-1, 1)\n",
    "    tst.bias.data.uniform_(-1, 1)\n",
    "    tst = init_default(tst, func=lambda x: x.data.fill_(1.0))\n",
    "    test_eq(tst.weight, torch.ones(5, 4))\n",
    "    test_eq(tst.bias, torch.zeros(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# export\\ndef cond_init(m: nn.Module, func: Callable):\\n    \\\"\\\"\\\"\\n    Apply `init_default` to `m` unless it's a batchnorm module.\\n    Source: https://github.com/fastai/fastai/blob/master/fastai/torch_core.py\\n    \\\"\\\"\\\"\\n    if not isinstance(m, norm_types):\\n        init_default(m, func)\";\n",
       "                var nbb_formatted_code = \"# export\\ndef cond_init(m: nn.Module, func: Callable):\\n    \\\"\\\"\\\"\\n    Apply `init_default` to `m` unless it's a batchnorm module.\\n    Source: https://github.com/fastai/fastai/blob/master/fastai/torch_core.py\\n    \\\"\\\"\\\"\\n    if not isinstance(m, norm_types):\\n        init_default(m, func)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "def cond_init(m: nn.Module, func: Callable):\n",
    "    \"\"\"\n",
    "    Apply `init_default` to `m` unless it's a batchnorm module.\n",
    "    Source: https://github.com/fastai/fastai/blob/master/fastai/torch_core.py\n",
    "    \"\"\"\n",
    "    if not isinstance(m, norm_types):\n",
    "        init_default(m, func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"with torch.no_grad():\\n    tst = nn.Linear(4, 5)\\n    tst.weight.data.uniform_(-1, 1)\\n    tst.bias.data.uniform_(-1, 1)\\n    cond_init(tst, func=lambda x: x.data.fill_(1.0))\\n    test_eq(tst.weight, torch.ones(5, 4))\\n    test_eq(tst.bias, torch.zeros(5))\\n\\n    tst = nn.BatchNorm2d(5)\\n    init = [tst.weight.clone(), tst.bias.clone()]\\n    cond_init(tst, func=lambda x: x.data.fill_(1.0))\\n    test_eq(tst.weight, init[0])\\n    test_eq(tst.bias, init[1])\";\n",
       "                var nbb_formatted_code = \"with torch.no_grad():\\n    tst = nn.Linear(4, 5)\\n    tst.weight.data.uniform_(-1, 1)\\n    tst.bias.data.uniform_(-1, 1)\\n    cond_init(tst, func=lambda x: x.data.fill_(1.0))\\n    test_eq(tst.weight, torch.ones(5, 4))\\n    test_eq(tst.bias, torch.zeros(5))\\n\\n    tst = nn.BatchNorm2d(5)\\n    init = [tst.weight.clone(), tst.bias.clone()]\\n    cond_init(tst, func=lambda x: x.data.fill_(1.0))\\n    test_eq(tst.weight, init[0])\\n    test_eq(tst.bias, init[1])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    tst = nn.Linear(4, 5)\n",
    "    tst.weight.data.uniform_(-1, 1)\n",
    "    tst.bias.data.uniform_(-1, 1)\n",
    "    cond_init(tst, func=lambda x: x.data.fill_(1.0))\n",
    "    test_eq(tst.weight, torch.ones(5, 4))\n",
    "    test_eq(tst.bias, torch.zeros(5))\n",
    "\n",
    "    tst = nn.BatchNorm2d(5)\n",
    "    init = [tst.weight.clone(), tst.bias.clone()]\n",
    "    cond_init(tst, func=lambda x: x.data.fill_(1.0))\n",
    "    test_eq(tst.weight, init[0])\n",
    "    test_eq(tst.bias, init[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# export\\ndef apply_leaf(m: nn.Module, f: Callable):\\n    \\\"\\\"\\\"\\n    Apply `f` to children of `m`.\\n    Source: https://github.com/fastai/fastai/blob/master/fastai/torch_core.py\\n    \\\"\\\"\\\"\\n    c = m.children()\\n    if isinstance(m, nn.Module):\\n        f(m)\\n    for l in c:\\n        apply_leaf(l, f)\";\n",
       "                var nbb_formatted_code = \"# export\\ndef apply_leaf(m: nn.Module, f: Callable):\\n    \\\"\\\"\\\"\\n    Apply `f` to children of `m`.\\n    Source: https://github.com/fastai/fastai/blob/master/fastai/torch_core.py\\n    \\\"\\\"\\\"\\n    c = m.children()\\n    if isinstance(m, nn.Module):\\n        f(m)\\n    for l in c:\\n        apply_leaf(l, f)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "def apply_leaf(m: nn.Module, f: Callable):\n",
    "    \"\"\"\n",
    "    Apply `f` to children of `m`.\n",
    "    Source: https://github.com/fastai/fastai/blob/master/fastai/torch_core.py\n",
    "    \"\"\"\n",
    "    c = m.children()\n",
    "    if isinstance(m, nn.Module):\n",
    "        f(m)\n",
    "    for l in c:\n",
    "        apply_leaf(l, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"tst = nn.Sequential(nn.Linear(4, 5), nn.Sequential(nn.Linear(4, 5), nn.Linear(4, 5)))\\napply_leaf(tst, partial(init_default, func=lambda x: x.data.fill_(1.0)))\\n\\n\\nwith torch.no_grad():\\n    for l in [tst[0], *tst[1]]:\\n        test_eq(l.weight, torch.ones(5, 4))\\n\\n    for l in [tst[0], *tst[1]]:\\n        test_eq(l.bias, torch.zeros(5))\";\n",
       "                var nbb_formatted_code = \"tst = nn.Sequential(nn.Linear(4, 5), nn.Sequential(nn.Linear(4, 5), nn.Linear(4, 5)))\\napply_leaf(tst, partial(init_default, func=lambda x: x.data.fill_(1.0)))\\n\\n\\nwith torch.no_grad():\\n    for l in [tst[0], *tst[1]]:\\n        test_eq(l.weight, torch.ones(5, 4))\\n\\n    for l in [tst[0], *tst[1]]:\\n        test_eq(l.bias, torch.zeros(5))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst = nn.Sequential(nn.Linear(4, 5), nn.Sequential(nn.Linear(4, 5), nn.Linear(4, 5)))\n",
    "apply_leaf(tst, partial(init_default, func=lambda x: x.data.fill_(1.0)))\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for l in [tst[0], *tst[1]]:\n",
    "        test_eq(l.weight, torch.ones(5, 4))\n",
    "\n",
    "    for l in [tst[0], *tst[1]]:\n",
    "        test_eq(l.bias, torch.zeros(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# export\\ndef apply_init(m: nn.Module, func: Callable = nn.init.kaiming_normal_):\\n    \\\"\\\"\\\"\\n    Initialize all non-batchnorm layers of `m` with `func`.\\n    Source: https://github.com/fastai/fastai/blob/master/fastai/torch_core.py\\n    \\\"\\\"\\\"\\n    apply_leaf(m, partial(cond_init, func=func))\";\n",
       "                var nbb_formatted_code = \"# export\\ndef apply_init(m: nn.Module, func: Callable = nn.init.kaiming_normal_):\\n    \\\"\\\"\\\"\\n    Initialize all non-batchnorm layers of `m` with `func`.\\n    Source: https://github.com/fastai/fastai/blob/master/fastai/torch_core.py\\n    \\\"\\\"\\\"\\n    apply_leaf(m, partial(cond_init, func=func))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "def apply_init(m: nn.Module, func: Callable = nn.init.kaiming_normal_):\n",
    "    \"\"\"\n",
    "    Initialize all non-batchnorm layers of `m` with `func`.\n",
    "    Source: https://github.com/fastai/fastai/blob/master/fastai/torch_core.py\n",
    "    \"\"\"\n",
    "    apply_leaf(m, partial(cond_init, func=func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"tst = nn.Sequential(nn.Linear(4, 5), nn.Sequential(nn.Linear(4, 5), nn.BatchNorm1d(5)))\\ninit = [tst[1][1].weight.clone(), tst[1][1].bias.clone()]\\napply_init(tst, func=lambda x: x.data.fill_(1.0))\\n\\nwith torch.no_grad():\\n    for l in [tst[0], tst[1][0]]:\\n        test_eq(l.weight, torch.ones(5, 4))\\n    for l in [tst[0], tst[1][0]]:\\n        test_eq(l.bias, torch.zeros(5))\\n        test_eq(tst[1][1].weight, init[0])\\n        test_eq(tst[1][1].bias, init[1])\";\n",
       "                var nbb_formatted_code = \"tst = nn.Sequential(nn.Linear(4, 5), nn.Sequential(nn.Linear(4, 5), nn.BatchNorm1d(5)))\\ninit = [tst[1][1].weight.clone(), tst[1][1].bias.clone()]\\napply_init(tst, func=lambda x: x.data.fill_(1.0))\\n\\nwith torch.no_grad():\\n    for l in [tst[0], tst[1][0]]:\\n        test_eq(l.weight, torch.ones(5, 4))\\n    for l in [tst[0], tst[1][0]]:\\n        test_eq(l.bias, torch.zeros(5))\\n        test_eq(tst[1][1].weight, init[0])\\n        test_eq(tst[1][1].bias, init[1])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst = nn.Sequential(nn.Linear(4, 5), nn.Sequential(nn.Linear(4, 5), nn.BatchNorm1d(5)))\n",
    "init = [tst[1][1].weight.clone(), tst[1][1].bias.clone()]\n",
    "apply_init(tst, func=lambda x: x.data.fill_(1.0))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for l in [tst[0], tst[1][0]]:\n",
    "        test_eq(l.weight, torch.ones(5, 4))\n",
    "    for l in [tst[0], tst[1][0]]:\n",
    "        test_eq(l.bias, torch.zeros(5))\n",
    "        test_eq(tst[1][1].weight, init[0])\n",
    "        test_eq(tst[1][1].bias, init[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous  Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"# export\\ndef set_bn_eval(m: nn.Module):\\n    \\\"\\\"\\\"\\n    Recursively Set bn layers in eval mode for all recursive children of `m`.\\n    Source: https://github.com/fastai/fastai/blob/master/fastai/callback/training.py#L43\\n    \\\"\\\"\\\"\\n    for l in m.children():\\n        if isinstance(l, bn_types):\\n            l.eval()\\n        set_bn_eval(l)\";\n",
       "                var nbb_formatted_code = \"# export\\ndef set_bn_eval(m: nn.Module):\\n    \\\"\\\"\\\"\\n    Recursively Set bn layers in eval mode for all recursive children of `m`.\\n    Source: https://github.com/fastai/fastai/blob/master/fastai/callback/training.py#L43\\n    \\\"\\\"\\\"\\n    for l in m.children():\\n        if isinstance(l, bn_types):\\n            l.eval()\\n        set_bn_eval(l)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "def set_bn_eval(m: nn.Module):\n",
    "    \"\"\"\n",
    "    Recursively Set bn layers in eval mode for all recursive children of `m`.\n",
    "    Source: https://github.com/fastai/fastai/blob/master/fastai/callback/training.py#L43\n",
    "    \"\"\"\n",
    "    for l in m.children():\n",
    "        if isinstance(l, bn_types):\n",
    "            l.eval()\n",
    "        set_bn_eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"model = nn.Sequential(nn.Linear(4, 5), nn.BatchNorm1d(5), nn.Linear(5, 1))\";\n",
       "                var nbb_formatted_code = \"model = nn.Sequential(nn.Linear(4, 5), nn.BatchNorm1d(5), nn.Linear(5, 1))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(4, 5), nn.BatchNorm1d(5), nn.Linear(5, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grab the first `BatchNorm` layer, and store its running mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"m = model[1].running_mean.clone()\";\n",
       "                var nbb_formatted_code = \"m = model[1].running_mean.clone()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = model[1].running_mean.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that now that running mean has changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"i = torch.randn(32, 4)\\no = model(i)\\ntest_ne(m, model[1].running_mean.detach())\";\n",
       "                var nbb_formatted_code = \"i = torch.randn(32, 4)\\no = model(i)\\ntest_ne(m, model[1].running_mean.detach())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = torch.randn(32, 4)\n",
    "o = model(i)\n",
    "test_ne(m, model[1].running_mean.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use the `set_bn_eval` function, the running statistics will not be changed during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"model = nn.Sequential(nn.Linear(4, 5), nn.BatchNorm1d(5))\\nmodel.train()\\nmodel.eval()\\nm = model[1].running_mean.clone()\\n\\nset_bn_eval(model)\\n\\ni = torch.randn(32, 4)\\no = model(i)\\n\\ntest_eq(m, model[1].running_mean.detach())\";\n",
       "                var nbb_formatted_code = \"model = nn.Sequential(nn.Linear(4, 5), nn.BatchNorm1d(5))\\nmodel.train()\\nmodel.eval()\\nm = model[1].running_mean.clone()\\n\\nset_bn_eval(model)\\n\\ni = torch.randn(32, 4)\\no = model(i)\\n\\ntest_eq(m, model[1].running_mean.detach())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(4, 5), nn.BatchNorm1d(5))\n",
    "model.train()\n",
    "model.eval()\n",
    "m = model[1].running_mean.clone()\n",
    "\n",
    "set_bn_eval(model)\n",
    "\n",
    "i = torch.randn(32, 4)\n",
    "o = model(i)\n",
    "\n",
    "test_eq(m, model[1].running_mean.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"# export\\ndef trainable_params(m: nn.Module):\\n    \\\"Return all trainable parameters of `m`\\\"\\n    return [p for p in m.parameters() if p.requires_grad]\";\n",
       "                var nbb_formatted_code = \"# export\\ndef trainable_params(m: nn.Module):\\n    \\\"Return all trainable parameters of `m`\\\"\\n    return [p for p in m.parameters() if p.requires_grad]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "def trainable_params(m: nn.Module):\n",
    "    \"Return all trainable parameters of `m`\"\n",
    "    return [p for p in m.parameters() if p.requires_grad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"# export\\ndef params(m):\\n    \\\"Return all parameters of `m`\\\"\\n    return [p for p in m.parameters()]\";\n",
       "                var nbb_formatted_code = \"# export\\ndef params(m):\\n    \\\"Return all parameters of `m`\\\"\\n    return [p for p in m.parameters()]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "def params(m):\n",
    "    \"Return all parameters of `m`\"\n",
    "    return [p for p in m.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"with torch.no_grad():\\n    m = nn.Linear(4, 5)\\n    test_eq(trainable_params(m), [m.weight, m.bias])\\n\\n    m.weight.requires_grad_(False)\\n    test_eq(trainable_params(m), [m.bias])\\n    test_eq(params(m), [m.weight, m.bias])\";\n",
       "                var nbb_formatted_code = \"with torch.no_grad():\\n    m = nn.Linear(4, 5)\\n    test_eq(trainable_params(m), [m.weight, m.bias])\\n\\n    m.weight.requires_grad_(False)\\n    test_eq(trainable_params(m), [m.bias])\\n    test_eq(params(m), [m.weight, m.bias])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    m = nn.Linear(4, 5)\n",
    "    test_eq(trainable_params(m), [m.weight, m.bias])\n",
    "\n",
    "    m.weight.requires_grad_(False)\n",
    "    test_eq(trainable_params(m), [m.bias])\n",
    "    test_eq(params(m), [m.weight, m.bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"# export\\ndef maybe_convert_to_onehot(\\n    target: torch.Tensor, output: torch.Tensor\\n) -> torch.LongTensor:\\n    \\\"\\\"\\\"\\n    This function infers whether `target` is `one_hot` encoded\\n    and converts it to `one_hot` encoding if necessary.\\n\\n    Returns a `one_hot` encoded `torch.LongTensor` with same shape as output.\\n\\n    Shape:\\n    - Output : $(N, C)$ where N is the mini-batch size and $C$ is the total number of classes.\\n    - Returns: $(N, C)$\\n    \\\"\\\"\\\"\\n    target_shape_list = list(target.size())\\n    if len(target_shape_list) == 1 or (\\n        len(target_shape_list) == 2 and target_shape_list[1] == 1\\n    ):\\n        target = torch.nn.functional.one_hot(target, output.shape[1])\\n    return target\";\n",
       "                var nbb_formatted_code = \"# export\\ndef maybe_convert_to_onehot(\\n    target: torch.Tensor, output: torch.Tensor\\n) -> torch.LongTensor:\\n    \\\"\\\"\\\"\\n    This function infers whether `target` is `one_hot` encoded\\n    and converts it to `one_hot` encoding if necessary.\\n\\n    Returns a `one_hot` encoded `torch.LongTensor` with same shape as output.\\n\\n    Shape:\\n    - Output : $(N, C)$ where N is the mini-batch size and $C$ is the total number of classes.\\n    - Returns: $(N, C)$\\n    \\\"\\\"\\\"\\n    target_shape_list = list(target.size())\\n    if len(target_shape_list) == 1 or (\\n        len(target_shape_list) == 2 and target_shape_list[1] == 1\\n    ):\\n        target = torch.nn.functional.one_hot(target, output.shape[1])\\n    return target\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "def maybe_convert_to_onehot(\n",
    "    target: torch.Tensor, output: torch.Tensor\n",
    ") -> torch.LongTensor:\n",
    "    \"\"\"\n",
    "    This function infers whether `target` is `one_hot` encoded\n",
    "    and converts it to `one_hot` encoding if necessary.\n",
    "\n",
    "    Returns a `one_hot` encoded `torch.LongTensor` with same shape as output.\n",
    "\n",
    "    Shape:\n",
    "    - Output : $(N, C)$ where N is the mini-batch size and $C$ is the total number of classes.\n",
    "    - Returns: $(N, C)$\n",
    "    \"\"\"\n",
    "    target_shape_list = list(target.size())\n",
    "    if len(target_shape_list) == 1 or (\n",
    "        len(target_shape_list) == 2 and target_shape_list[1] == 1\n",
    "    ):\n",
    "        target = torch.nn.functional.one_hot(target, output.shape[1])\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"output = torch.randn(10, 10)\\n\\nt0 = torch.nn.functional.one_hot(torch.arange(0, 10) % 3, num_classes=10)\\nt1 = torch.arange(0, 10) % 3\\n\\no0 = maybe_convert_to_onehot(t0, output)\\no1 = maybe_convert_to_onehot(t1, output)\\n\\ntest_eq(o0.shape, output.shape)\\ntest_eq(o1.shape, output.shape)\\ntest_eq(t0, o0)\";\n",
       "                var nbb_formatted_code = \"output = torch.randn(10, 10)\\n\\nt0 = torch.nn.functional.one_hot(torch.arange(0, 10) % 3, num_classes=10)\\nt1 = torch.arange(0, 10) % 3\\n\\no0 = maybe_convert_to_onehot(t0, output)\\no1 = maybe_convert_to_onehot(t1, output)\\n\\ntest_eq(o0.shape, output.shape)\\ntest_eq(o1.shape, output.shape)\\ntest_eq(t0, o0)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = torch.randn(10, 10)\n",
    "\n",
    "t0 = torch.nn.functional.one_hot(torch.arange(0, 10) % 3, num_classes=10)\n",
    "t1 = torch.arange(0, 10) % 3\n",
    "\n",
    "o0 = maybe_convert_to_onehot(t0, output)\n",
    "o1 = maybe_convert_to_onehot(t1, output)\n",
    "\n",
    "test_eq(o0.shape, output.shape)\n",
    "test_eq(o1.shape, output.shape)\n",
    "test_eq(t0, o0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... We can see that `maybe_convert_to_onehot` converted `t1` to a `one_hot` encoded tensor but did not change `t0` because it was already `one_hot` in encoded `form`/`shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# export\\ndef worker_init_fn(worker_id):\\n    \\\"\\\"\\\"\\n    You can set the seed for `NumPy` in the `worker_init_fn`\\n    \\n    \\n    For more information see: \\n    https://tanelp.github.io/posts/a-bug-that-plagues-thousands-of-open-source-ml-projects/\\n    \\\"\\\"\\\"\\n    np.random.seed(np.random.get_state()[1][0] + worker_id)\";\n",
       "                var nbb_formatted_code = \"# export\\ndef worker_init_fn(worker_id):\\n    \\\"\\\"\\\"\\n    You can set the seed for `NumPy` in the `worker_init_fn`\\n\\n\\n    For more information see:\\n    https://tanelp.github.io/posts/a-bug-that-plagues-thousands-of-open-source-ml-projects/\\n    \\\"\\\"\\\"\\n    np.random.seed(np.random.get_state()[1][0] + worker_id)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "def worker_init_fn(worker_id):\n",
    "    \"\"\"\n",
    "    You can set the seed for `NumPy` in the `worker_init_fn`\n",
    "\n",
    "\n",
    "    For more information see:\n",
    "    https://tanelp.github.io/posts/a-bug-that-plagues-thousands-of-open-source-ml-projects/\n",
    "    \"\"\"\n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.logging.ipynb.\n",
      "Converted 00a_core.structures.ipynb.\n",
      "Converted 00b_core.visualize.ipynb.\n",
      "Converted 01_core.nn.utils.ipynb.\n",
      "Converted 01a_core.nn.losses.ipynb.\n",
      "Converted 01b_core.nn.optim.optimizers.ipynb.\n",
      "Converted 01c_core.nn.optim.lr_schedulers.ipynb.\n",
      "Converted 02_core.classes.ipynb.\n",
      "Converted 03_config.optimizers.ipynb.\n",
      "Converted 03a_config.schedulers.ipynb.\n",
      "Converted 03b_config.common.ipynb.\n",
      "Converted 04_classification.modelling.backbones.ipynb.\n",
      "Converted 05_collections.pandas.ipynb.\n",
      "Converted 06a_collections.callbacks.notebook.ipynb.\n",
      "Converted 06b_collections.callbacks.ema.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"notebook2script()\";\n",
       "                var nbb_formatted_code = \"notebook2script()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gale",
   "language": "python",
   "name": "gale"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
