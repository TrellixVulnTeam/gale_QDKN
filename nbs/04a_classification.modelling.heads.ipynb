{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp classification.modelling.heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"# hide\\n%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\";\n",
       "                var nbb_formatted_code = \"# hide\\n%load_ext nb_black\\n%load_ext autoreload\\n%autoreload 2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "%load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# hide\\nimport warnings\\n\\nfrom nbdev.export import *\\nfrom nbdev.showdoc import *\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_formatted_code = \"# hide\\nimport warnings\\n\\nfrom nbdev.export import *\\nfrom nbdev.showdoc import *\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "import warnings\n",
    "\n",
    "from nbdev.export import *\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heads\n",
    "> A head is a regular `torch.nn.Module` that can be attached to a backbone.\n",
    "\n",
    "\n",
    "> Note: For Image Classification a, `head` typically contains a pooling layer along with the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# export\\nfrom typing import *\\n\\nimport torch\\nfrom fastcore.all import L, ifnone, store_attr\\nfrom timm.models.layers.classifier import _create_fc, _create_pool\\nfrom torch import nn\\n\\nfrom gale.classification.modelling.backbones import filter_weight_decay\\nfrom gale.core.classes import GaleModule\\nfrom gale.core.logging import setup_logger\\nfrom gale.core.nn import ACTIVATION_REGISTRY\\nfrom gale.core.nn.shape_spec import ShapeSpec\\nfrom gale.core.nn.utils import trainable_params\\nfrom gale.core.structures import IMAGE_CLASSIFIER_HEADS\";\n",
       "                var nbb_formatted_code = \"# export\\nfrom typing import *\\n\\nimport torch\\nfrom fastcore.all import L, ifnone, store_attr\\nfrom timm.models.layers.classifier import _create_fc, _create_pool\\nfrom torch import nn\\n\\nfrom gale.classification.modelling.backbones import filter_weight_decay\\nfrom gale.core.classes import GaleModule\\nfrom gale.core.logging import setup_logger\\nfrom gale.core.nn import ACTIVATION_REGISTRY\\nfrom gale.core.nn.shape_spec import ShapeSpec\\nfrom gale.core.nn.utils import trainable_params\\nfrom gale.core.structures import IMAGE_CLASSIFIER_HEADS\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "from typing import *\n",
    "\n",
    "import torch\n",
    "from fastcore.all import L, ifnone, store_attr\n",
    "from timm.models.layers.classifier import _create_fc, _create_pool\n",
    "from torch import nn\n",
    "\n",
    "from gale.classification.modelling.backbones import filter_weight_decay\n",
    "from gale.core.classes import GaleModule\n",
    "from gale.core.logging import setup_logger\n",
    "from gale.core.nn import ACTIVATION_REGISTRY\n",
    "from gale.core.nn.shape_spec import ShapeSpec\n",
    "from gale.core.nn.utils import trainable_params\n",
    "from gale.core.structures import IMAGE_CLASSIFIER_HEADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# export\\n_logger = setup_logger()\";\n",
       "                var nbb_formatted_code = \"# export\\n_logger = setup_logger()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "_logger = setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# export\\nclass ImageClassificationHead(GaleModule):\\n    \\\"\\\"\\\"\\n    Abstract class for ImageClassification Heads\\n    \\\"\\\"\\\"\\n\\n    def __init__(self):\\n        \\\"\\\"\\\"\\n        The `__init__` method of any subclass can specify its own set of arguments.\\n        \\\"\\\"\\\"\\n        super().__init__()\\n\\n    def get_lrs(self) -> List:\\n        \\\"\\\"\\\"\\n        Returns a List containining the Lrs' for\\n        each parameter group. This is required to build schedulers\\n        like `torch.optim.lr_scheduler.OneCycleScheduler` which needs\\n        the max lrs' for all the Param Groups.\\n        \\\"\\\"\\\"\\n        lrs = []\\n\\n        for p in self.build_param_dicts():\\n            lrs.append(p[\\\"lr\\\"])\\n        return lrs\";\n",
       "                var nbb_formatted_code = \"# export\\nclass ImageClassificationHead(GaleModule):\\n    \\\"\\\"\\\"\\n    Abstract class for ImageClassification Heads\\n    \\\"\\\"\\\"\\n\\n    def __init__(self):\\n        \\\"\\\"\\\"\\n        The `__init__` method of any subclass can specify its own set of arguments.\\n        \\\"\\\"\\\"\\n        super().__init__()\\n\\n    def get_lrs(self) -> List:\\n        \\\"\\\"\\\"\\n        Returns a List containining the Lrs' for\\n        each parameter group. This is required to build schedulers\\n        like `torch.optim.lr_scheduler.OneCycleScheduler` which needs\\n        the max lrs' for all the Param Groups.\\n        \\\"\\\"\\\"\\n        lrs = []\\n\\n        for p in self.build_param_dicts():\\n            lrs.append(p[\\\"lr\\\"])\\n        return lrs\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class ImageClassificationHead(GaleModule):\n",
    "    \"\"\"\n",
    "    Abstract class for ImageClassification Heads\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        The `__init__` method of any subclass can specify its own set of arguments.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "    def get_lrs(self) -> List:\n",
    "        \"\"\"\n",
    "        Returns a List containining the Lrs' for\n",
    "        each parameter group. This is required to build schedulers\n",
    "        like `torch.optim.lr_scheduler.OneCycleScheduler` which needs\n",
    "        the max lrs' for all the Param Groups.\n",
    "        \"\"\"\n",
    "        lrs = []\n",
    "\n",
    "        for p in self.build_param_dicts():\n",
    "            lrs.append(p[\"lr\"])\n",
    "        return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ImageClassificationHead.get_lrs\" class=\"doc_header\"><code>ImageClassificationHead.get_lrs</code><a href=\"__main__.py#L13\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ImageClassificationHead.get_lrs</code>()\n",
       "\n",
       "Returns a List containining the Lrs' for\n",
       "each parameter group. This is required to build schedulers\n",
       "like `torch.optim.lr_scheduler.OneCycleScheduler` which needs\n",
       "the max lrs' for all the Param Groups."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"show_doc(ImageClassificationHead.get_lrs)\";\n",
       "                var nbb_formatted_code = \"show_doc(ImageClassificationHead.get_lrs)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ImageClassificationHead.get_lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# export\\n@IMAGE_CLASSIFIER_HEADS.register()\\nclass FullyConnectedHead(ImageClassificationHead):\\n    \\\"\\\"\\\"\\n    Classifier head w/ configurable global pooling and dropout.\\n    From - https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/layers/classifier.py\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        input_shape: ShapeSpec,\\n        num_classes: int,\\n        pool_type: str = \\\"avg\\\",\\n        drop_rate: float = 0.0,\\n        use_conv: bool = False,\\n        lr: float = 2e-03,\\n        wd: float = 0,\\n        filter_wd: bool = False,\\n    ):\\n        super(FullyConnectedHead, self).__init__()\\n        self.drop_rate = drop_rate\\n        in_planes = input_shape.channels\\n        # fmt: off\\n        self.global_pool, num_pooled_features = _create_pool(in_planes, num_classes, pool_type, use_conv=use_conv)\\n        # fmt: on\\n        self.fc = _create_fc(num_pooled_features, num_classes, use_conv=use_conv)\\n        self.flatten_after_fc = use_conv and pool_type\\n\\n        store_attr(\\\"lr, wd, filter_wd\\\")\\n\\n    def forward(self, x):\\n        x = self.global_pool(x)\\n        if self.drop_rate:\\n            x = F.dropout(x, p=float(self.drop_rate), training=self.training)\\n        x = self.fc(x)\\n        return x\\n\\n    def build_param_dicts(self) -> Any:\\n        if self.filter_wd:\\n            ps = filter_weight_decay(self, lr=self.lr, weight_decay=self.wd)\\n        else:\\n            # fmt: off\\n            ps = [{\\\"params\\\": trainable_params(self),\\\"lr\\\": self.lr,\\\"weight_decay\\\": self.wd}]\\n            # fmt: on\\n        return ps\";\n",
       "                var nbb_formatted_code = \"# export\\n@IMAGE_CLASSIFIER_HEADS.register()\\nclass FullyConnectedHead(ImageClassificationHead):\\n    \\\"\\\"\\\"\\n    Classifier head w/ configurable global pooling and dropout.\\n    From - https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/layers/classifier.py\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        input_shape: ShapeSpec,\\n        num_classes: int,\\n        pool_type: str = \\\"avg\\\",\\n        drop_rate: float = 0.0,\\n        use_conv: bool = False,\\n        lr: float = 2e-03,\\n        wd: float = 0,\\n        filter_wd: bool = False,\\n    ):\\n        super(FullyConnectedHead, self).__init__()\\n        self.drop_rate = drop_rate\\n        in_planes = input_shape.channels\\n        # fmt: off\\n        self.global_pool, num_pooled_features = _create_pool(in_planes, num_classes, pool_type, use_conv=use_conv)\\n        # fmt: on\\n        self.fc = _create_fc(num_pooled_features, num_classes, use_conv=use_conv)\\n        self.flatten_after_fc = use_conv and pool_type\\n\\n        store_attr(\\\"lr, wd, filter_wd\\\")\\n\\n    def forward(self, x):\\n        x = self.global_pool(x)\\n        if self.drop_rate:\\n            x = F.dropout(x, p=float(self.drop_rate), training=self.training)\\n        x = self.fc(x)\\n        return x\\n\\n    def build_param_dicts(self) -> Any:\\n        if self.filter_wd:\\n            ps = filter_weight_decay(self, lr=self.lr, weight_decay=self.wd)\\n        else:\\n            # fmt: off\\n            ps = [{\\\"params\\\": trainable_params(self),\\\"lr\\\": self.lr,\\\"weight_decay\\\": self.wd}]\\n            # fmt: on\\n        return ps\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "@IMAGE_CLASSIFIER_HEADS.register()\n",
    "class FullyConnectedHead(ImageClassificationHead):\n",
    "    \"\"\"\n",
    "    Classifier head w/ configurable global pooling and dropout.\n",
    "    From - https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/layers/classifier.py\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: ShapeSpec,\n",
    "        num_classes: int,\n",
    "        pool_type: str = \"avg\",\n",
    "        drop_rate: float = 0.0,\n",
    "        use_conv: bool = False,\n",
    "        lr: float = 2e-03,\n",
    "        wd: float = 0,\n",
    "        filter_wd: bool = False,\n",
    "    ):\n",
    "        super(FullyConnectedHead, self).__init__()\n",
    "        self.drop_rate = drop_rate\n",
    "        in_planes = input_shape.channels\n",
    "        # fmt: off\n",
    "        self.global_pool, num_pooled_features = _create_pool(in_planes, num_classes, pool_type, use_conv=use_conv)\n",
    "        # fmt: on\n",
    "        self.fc = _create_fc(num_pooled_features, num_classes, use_conv=use_conv)\n",
    "        self.flatten_after_fc = use_conv and pool_type\n",
    "\n",
    "        store_attr(\"lr, wd, filter_wd\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.global_pool(x)\n",
    "        if self.drop_rate:\n",
    "            x = F.dropout(x, p=float(self.drop_rate), training=self.training)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def build_param_dicts(self) -> Any:\n",
    "        if self.filter_wd:\n",
    "            ps = filter_weight_decay(self, lr=self.lr, weight_decay=self.wd)\n",
    "        else:\n",
    "            # fmt: off\n",
    "            ps = [{\"params\": trainable_params(self),\"lr\": self.lr,\"weight_decay\": self.wd}]\n",
    "            # fmt: on\n",
    "        return ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguments to `FullyConnectedHead`:\n",
    "- `input_shape` (ShapeSpec): input shape\n",
    "- `num_classes` (int): Number of classes for the head.\n",
    "- `pool_type` (str): The pooling layer to use. Check [here](https://github.com/rwightman/pytorch-image-models/blob/9a1bd358c7e998799eed88b29842e3c9e5483e34/timm/models/layers/adaptive_avgmax_pool.py#L79).\n",
    "-  `drop_rate` (float): If >0.0 then applies dropout between the pool_layer and the fc layer.\n",
    "- `use_conv` (bool): Use a convolutional layer as the final fc layer.\n",
    "- `lr` (float): Learning rate for the modules.\n",
    "- `wd` (float): Weight decay for the modules.\n",
    "- `filter_wd` (bool): Filter out `bias`, `bn` from `weight_decay`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FullyConnectedHead(\n",
       "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"input_shape = ShapeSpec(channels=512)\\ntst = FullyConnectedHead(input_shape, 10)\\ntst\";\n",
       "                var nbb_formatted_code = \"input_shape = ShapeSpec(channels=512)\\ntst = FullyConnectedHead(input_shape, 10)\\ntst\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_shape = ShapeSpec(channels=512)\n",
    "tst = FullyConnectedHead(input_shape, 10)\n",
    "tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"# hide\\no = tst(torch.randn(2, 512, 2, 2))\\no.shape\";\n",
       "                var nbb_formatted_code = \"# hide\\no = tst(torch.randn(2, 512, 2, 2))\\no.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "o = tst(torch.randn(2, 512, 2, 2))\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# export\\n@IMAGE_CLASSIFIER_HEADS.register()\\nclass FastaiHead(ImageClassificationHead):\\n    \\\"\\\"\\\"\\n    Model head that takes `in_planes` features, runs through `lin_ftrs`, and out `num_classes` classes.\\n\\n\\n    From -\\n    https://github.com/fastai/fastai/blob/8b1da8765fc07f1232c20fa8dc5e909d2835640c/fastai/vision/learner.py#L76\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        input_shape: ShapeSpec,\\n        num_classes: int,\\n        act: str = \\\"ReLU\\\",\\n        lin_ftrs: Optional[List] = None,\\n        ps: Union[List, int] = 0.5,\\n        concat_pool: bool = True,\\n        first_bn: bool = True,\\n        bn_final: bool = False,\\n        lr: float = 2e-03,\\n        wd: float = 0,\\n        filter_wd: bool = False,\\n    ):\\n        super(FastaiHead, self).__init__()\\n        in_planes = input_shape.channels\\n        pool = \\\"catavgmax\\\" if concat_pool else \\\"avg\\\"\\n        pool, nf = _create_pool(in_planes, num_classes, pool, use_conv=False)\\n\\n        # fmt: off\\n        lin_ftrs = [nf, 512, num_classes] if lin_ftrs is None else [nf] + lin_ftrs + [num_classes]\\n        # fmt: on\\n\\n        bns = [first_bn] + [True] * len(lin_ftrs[1:])\\n\\n        ps = L(ps)\\n\\n        if len(ps) == 1:\\n            ps = [ps[0] / 2] * (len(lin_ftrs) - 2) + ps\\n\\n        act = ifnone(act, \\\"ReLU\\\")\\n        # fmt: off\\n        actns = [ACTIVATION_REGISTRY.get(act)(inplace=True)] * (len(lin_ftrs) - 2) + [None]\\n        if bn_final:\\n            actns[-1] = ACTIVATION_REGISTRY.get(act)(inplace=True)\\n        # fmt: on\\n\\n        self.layers = [pool]\\n\\n        for ni, no, bn, p, actn in zip(lin_ftrs[:-1], lin_ftrs[1:], bns, ps, actns):\\n            self.layers += nn.Sequential(\\n                nn.BatchNorm1d(ni), nn.Dropout(p), nn.Linear(ni, no, bias=not bns), actn\\n            )\\n\\n        if bn_final:\\n            self.layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\\n        self.layers = nn.Sequential(*[l for l in self.layers if l is not None])\\n\\n        store_attr(\\\"lr, wd, filter_wd\\\")\\n\\n    def forward(self, xb: torch.Tensor) -> Any:\\n        return self.layers(xb)\\n\\n    def build_param_dicts(self) -> Any:\\n        if self.filter_wd:\\n            ps = filter_weight_decay(self.layers, lr=self.lr, weight_decay=self.wd)\\n        else:\\n            # fmt: off\\n            ps = [{\\\"params\\\": trainable_params(self.layers),\\\"lr\\\": self.lr,\\\"weight_decay\\\": self.wd}]\\n            # fmt: on\\n        return ps\";\n",
       "                var nbb_formatted_code = \"# export\\n@IMAGE_CLASSIFIER_HEADS.register()\\nclass FastaiHead(ImageClassificationHead):\\n    \\\"\\\"\\\"\\n    Model head that takes `in_planes` features, runs through `lin_ftrs`, and out `num_classes` classes.\\n\\n\\n    From -\\n    https://github.com/fastai/fastai/blob/8b1da8765fc07f1232c20fa8dc5e909d2835640c/fastai/vision/learner.py#L76\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        input_shape: ShapeSpec,\\n        num_classes: int,\\n        act: str = \\\"ReLU\\\",\\n        lin_ftrs: Optional[List] = None,\\n        ps: Union[List, int] = 0.5,\\n        concat_pool: bool = True,\\n        first_bn: bool = True,\\n        bn_final: bool = False,\\n        lr: float = 2e-03,\\n        wd: float = 0,\\n        filter_wd: bool = False,\\n    ):\\n        super(FastaiHead, self).__init__()\\n        in_planes = input_shape.channels\\n        pool = \\\"catavgmax\\\" if concat_pool else \\\"avg\\\"\\n        pool, nf = _create_pool(in_planes, num_classes, pool, use_conv=False)\\n\\n        # fmt: off\\n        lin_ftrs = [nf, 512, num_classes] if lin_ftrs is None else [nf] + lin_ftrs + [num_classes]\\n        # fmt: on\\n\\n        bns = [first_bn] + [True] * len(lin_ftrs[1:])\\n\\n        ps = L(ps)\\n\\n        if len(ps) == 1:\\n            ps = [ps[0] / 2] * (len(lin_ftrs) - 2) + ps\\n\\n        act = ifnone(act, \\\"ReLU\\\")\\n        # fmt: off\\n        actns = [ACTIVATION_REGISTRY.get(act)(inplace=True)] * (len(lin_ftrs) - 2) + [None]\\n        if bn_final:\\n            actns[-1] = ACTIVATION_REGISTRY.get(act)(inplace=True)\\n        # fmt: on\\n\\n        self.layers = [pool]\\n\\n        for ni, no, bn, p, actn in zip(lin_ftrs[:-1], lin_ftrs[1:], bns, ps, actns):\\n            self.layers += nn.Sequential(\\n                nn.BatchNorm1d(ni), nn.Dropout(p), nn.Linear(ni, no, bias=not bns), actn\\n            )\\n\\n        if bn_final:\\n            self.layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\\n        self.layers = nn.Sequential(*[l for l in self.layers if l is not None])\\n\\n        store_attr(\\\"lr, wd, filter_wd\\\")\\n\\n    def forward(self, xb: torch.Tensor) -> Any:\\n        return self.layers(xb)\\n\\n    def build_param_dicts(self) -> Any:\\n        if self.filter_wd:\\n            ps = filter_weight_decay(self.layers, lr=self.lr, weight_decay=self.wd)\\n        else:\\n            # fmt: off\\n            ps = [{\\\"params\\\": trainable_params(self.layers),\\\"lr\\\": self.lr,\\\"weight_decay\\\": self.wd}]\\n            # fmt: on\\n        return ps\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "@IMAGE_CLASSIFIER_HEADS.register()\n",
    "class FastaiHead(ImageClassificationHead):\n",
    "    \"\"\"\n",
    "    Model head that takes `in_planes` features, runs through `lin_ftrs`, and out `num_classes` classes.\n",
    "\n",
    "\n",
    "    From -\n",
    "    https://github.com/fastai/fastai/blob/8b1da8765fc07f1232c20fa8dc5e909d2835640c/fastai/vision/learner.py#L76\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: ShapeSpec,\n",
    "        num_classes: int,\n",
    "        act: str = \"ReLU\",\n",
    "        lin_ftrs: Optional[List] = None,\n",
    "        ps: Union[List, int] = 0.5,\n",
    "        concat_pool: bool = True,\n",
    "        first_bn: bool = True,\n",
    "        bn_final: bool = False,\n",
    "        lr: float = 2e-03,\n",
    "        wd: float = 0,\n",
    "        filter_wd: bool = False,\n",
    "    ):\n",
    "        super(FastaiHead, self).__init__()\n",
    "        in_planes = input_shape.channels\n",
    "        pool = \"catavgmax\" if concat_pool else \"avg\"\n",
    "        pool, nf = _create_pool(in_planes, num_classes, pool, use_conv=False)\n",
    "\n",
    "        # fmt: off\n",
    "        lin_ftrs = [nf, 512, num_classes] if lin_ftrs is None else [nf] + lin_ftrs + [num_classes]\n",
    "        # fmt: on\n",
    "\n",
    "        bns = [first_bn] + [True] * len(lin_ftrs[1:])\n",
    "\n",
    "        ps = L(ps)\n",
    "\n",
    "        if len(ps) == 1:\n",
    "            ps = [ps[0] / 2] * (len(lin_ftrs) - 2) + ps\n",
    "\n",
    "        act = ifnone(act, \"ReLU\")\n",
    "        # fmt: off\n",
    "        actns = [ACTIVATION_REGISTRY.get(act)(inplace=True)] * (len(lin_ftrs) - 2) + [None]\n",
    "        if bn_final:\n",
    "            actns[-1] = ACTIVATION_REGISTRY.get(act)(inplace=True)\n",
    "        # fmt: on\n",
    "\n",
    "        self.layers = [pool]\n",
    "\n",
    "        for ni, no, bn, p, actn in zip(lin_ftrs[:-1], lin_ftrs[1:], bns, ps, actns):\n",
    "            self.layers += nn.Sequential(\n",
    "                nn.BatchNorm1d(ni), nn.Dropout(p), nn.Linear(ni, no, bias=not bns), actn\n",
    "            )\n",
    "\n",
    "        if bn_final:\n",
    "            self.layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n",
    "        self.layers = nn.Sequential(*[l for l in self.layers if l is not None])\n",
    "\n",
    "        store_attr(\"lr, wd, filter_wd\")\n",
    "\n",
    "    def forward(self, xb: torch.Tensor) -> Any:\n",
    "        return self.layers(xb)\n",
    "\n",
    "    def build_param_dicts(self) -> Any:\n",
    "        if self.filter_wd:\n",
    "            ps = filter_weight_decay(self.layers, lr=self.lr, weight_decay=self.wd)\n",
    "        else:\n",
    "            # fmt: off\n",
    "            ps = [{\"params\": trainable_params(self.layers),\"lr\": self.lr,\"weight_decay\": self.wd}]\n",
    "            # fmt: on\n",
    "        return ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The head begins with `AdaptiveConcatPool2d` if `concat_pool=True` otherwise, it uses traditional average pooling. Then it uses a Flatten layer before going on blocks of `BatchNorm`, `Dropout` and `Linear` layers.\n",
    "\n",
    "Those blocks start at `in_planes`, then every element of `lin_ftrs` (defaults to [512]) and end at `num_classes`. `ps` is a list of probabilities used for the dropouts (if you only pass 1, it will use half the value then that value as many times as necessary).\n",
    "\n",
    "Arguments to `FastaiHead`:\n",
    "- `input_shape` (ShapeSpec): input shape\n",
    "- `num_classes` (int): Number of classes for the head.\n",
    "- `act` (str): name of the activation function to use. If None uses the default activations else the name must be in ACTIVATION_REGISTRY. Activation layers are used after every block (`BatchNorm`, `Dropout` and `Linear` layers) if it is not the last block.\n",
    "- `lin_ftrs` (List): Features of the Linear layers. (defaults to [512])\n",
    "- `ps` (List): list of probabilities used for the dropouts.\n",
    "- `concat_pool` (bool): Wether to use `AdaptiveConcatPool2d` or `AdaptiveAveragePool2d`.\n",
    "- `first_bn` (bool): BatchNorm Layer after pool.\n",
    "- `bn_final` (bool): Final Layer is BatchNorm.\n",
    "- `lr` (float): Learning rate for the modules.\n",
    "- `wd` (float): Weight decay for the modules.\n",
    "- `filter_wd` (bool): Filter out `bias`, `bn` from `weight_decay`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FastaiHead(\n",
       "  (layers): Sequential(\n",
       "    (0): SelectAdaptivePool2d (pool_type=catavgmax, flatten=True)\n",
       "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Dropout(p=0.25, inplace=False)\n",
       "    (3): Linear(in_features=1024, out_features=512, bias=False)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Dropout(p=0.5, inplace=False)\n",
       "    (7): Linear(in_features=512, out_features=10, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"input_shape = ShapeSpec(channels=512)\\ntst = FastaiHead(input_shape=input_shape, num_classes=10)\\ntst\";\n",
       "                var nbb_formatted_code = \"input_shape = ShapeSpec(channels=512)\\ntst = FastaiHead(input_shape=input_shape, num_classes=10)\\ntst\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_shape = ShapeSpec(channels=512)\n",
    "tst = FastaiHead(input_shape=input_shape, num_classes=10)\n",
    "tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# hide\\no = tst(torch.randn(2, 512, 2, 2))\\no.shape\";\n",
       "                var nbb_formatted_code = \"# hide\\no = tst(torch.randn(2, 512, 2, 2))\\no.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "o = tst(torch.randn(2, 512, 2, 2))\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiation using config :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"from dataclasses import dataclass, field\\nfrom omegaconf import OmegaConf, DictConfig, MISSING\";\n",
       "                var nbb_formatted_code = \"from dataclasses import dataclass, field\\nfrom omegaconf import OmegaConf, DictConfig, MISSING\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from omegaconf import OmegaConf, DictConfig, MISSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FastaiHead(\n",
       "  (layers): Sequential(\n",
       "    (0): SelectAdaptivePool2d (pool_type=catavgmax, flatten=True)\n",
       "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Dropout(p=0.25, inplace=False)\n",
       "    (3): Linear(in_features=1024, out_features=512, bias=False)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Dropout(p=0.5, inplace=False)\n",
       "    (7): Linear(in_features=512, out_features=10, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"@dataclass\\nclass HeadConf:\\n    num_classes: int = MISSING\\n    act: str = \\\"ReLU\\\"\\n    lin_ftrs: Optional[List] = None\\n    ps: Any = 0.5\\n    concat_pool: bool = True\\n    first_bn: bool = True\\n    bn_final: bool = False\\n    lr: float = 0.002\\n    wd: float = 0\\n    filter_wd: bool = False\\n\\n\\nconf = OmegaConf.structured(HeadConf(num_classes=10))\\n\\ntst = FastaiHead.from_config_dict(conf, input_shape=input_shape)\\ntst\";\n",
       "                var nbb_formatted_code = \"@dataclass\\nclass HeadConf:\\n    num_classes: int = MISSING\\n    act: str = \\\"ReLU\\\"\\n    lin_ftrs: Optional[List] = None\\n    ps: Any = 0.5\\n    concat_pool: bool = True\\n    first_bn: bool = True\\n    bn_final: bool = False\\n    lr: float = 0.002\\n    wd: float = 0\\n    filter_wd: bool = False\\n\\n\\nconf = OmegaConf.structured(HeadConf(num_classes=10))\\n\\ntst = FastaiHead.from_config_dict(conf, input_shape=input_shape)\\ntst\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@dataclass\n",
    "class HeadConf:\n",
    "    num_classes: int = MISSING\n",
    "    act: str = \"ReLU\"\n",
    "    lin_ftrs: Optional[List] = None\n",
    "    ps: Any = 0.5\n",
    "    concat_pool: bool = True\n",
    "    first_bn: bool = True\n",
    "    bn_final: bool = False\n",
    "    lr: float = 0.002\n",
    "    wd: float = 0\n",
    "    filter_wd: bool = False\n",
    "\n",
    "\n",
    "conf = OmegaConf.structured(HeadConf(num_classes=10))\n",
    "\n",
    "tst = FastaiHead.from_config_dict(conf, input_shape=input_shape)\n",
    "tst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.logging.ipynb.\n",
      "Converted 00a_core.structures.ipynb.\n",
      "Converted 00b_core.visualize.ipynb.\n",
      "Converted 01_core.nn.utils.ipynb.\n",
      "Converted 01a_core.nn.losses.ipynb.\n",
      "Converted 02_core.nn.optim.optimizers.ipynb.\n",
      "Converted 02a_core.nn.optim.lr_schedulers.ipynb.\n",
      "Converted 03_core.config.ipynb.\n",
      "Converted 03a_core.classes.ipynb.\n",
      "Converted 04_classification.modelling.backbones.ipynb.\n",
      "Converted 04a_classification.modelling.heads.ipynb.\n",
      "Converted 04b_classification.modelling.meta_arch.ipynb.\n",
      "Converted 05_collections.pandas.ipynb.\n",
      "Converted 06a_collections.callbacks.notebook.ipynb.\n",
      "Converted 06b_collections.callbacks.ema.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"# hide\\nnotebook2script()\";\n",
       "                var nbb_formatted_code = \"# hide\\nnotebook2script()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gale",
   "language": "python",
   "name": "gale"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
